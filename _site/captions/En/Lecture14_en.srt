1
00:00:00,000 --> 00:00:04,990
administrative I tell everyone should be
done with 73 now if you're not done I

2
00:00:04,990 --> 00:00:07,790
think you're late and you're in trouble

3
00:00:07,790 --> 00:00:11,280
Muslim graves will be out very soon
we're still going through them and there

4
00:00:11,279 --> 00:00:13,779
are basically I think done but we have
to double check a few things I will send

5
00:00:13,779 --> 00:00:14,199
them out

6
00:00:14,199 --> 00:00:18,820
ok so in terms of reminding you where we
are in the class I last looked very

7
00:00:18,820 --> 00:00:22,629
briefly at segmentation we looked at
some soft attention models substation

8
00:00:22,629 --> 00:00:25,829
models are away for selectively paying
attention to different parts of the

9
00:00:25,829 --> 00:00:28,028
image as your processing it was
something like a recurrent neural

10
00:00:28,028 --> 00:00:32,020
network so glad you selectively pay
attention to some parts of the scene and

11
00:00:32,020 --> 00:00:35,450
enhance those features and will start
about special transformer which is this

12
00:00:35,450 --> 00:00:38,929
very nice way of basically in a
different way cropping parts of an image

13
00:00:38,929 --> 00:00:43,769
or some features either in a hydrogen or
in any kind of warped shape aren't in

14
00:00:43,770 --> 00:00:48,579
like that so very interesting kind of PC
that you can slot internal network

15
00:00:48,579 --> 00:00:52,049
architectures so today we'll talk about
videos

16
00:00:52,049 --> 00:00:56,229
specifically now in image classification
you should be familiar by now whether

17
00:00:56,229 --> 00:00:59,390
the basic combat set up you have an
image that comes in a reprocessing it to

18
00:00:59,390 --> 00:01:03,239
for example classified in a case of
videos we won't have just a single image

19
00:01:03,238 --> 00:01:07,728
but will have multiple frames so this is
an image of 32 by 32 will actually have

20
00:01:07,728 --> 00:01:13,829
an entire video frames so 32 by 32
mighty purty a sometime extent ok so

21
00:01:13,829 --> 00:01:17,340
before I dive into how we approach these
problems with I'd like to talk about

22
00:01:17,340 --> 00:01:21,170
very briefly about how we used to
address them for calm asking about using

23
00:01:21,170 --> 00:01:25,629
pcr-based methods so some of the most
popular features right before coming to

24
00:01:25,629 --> 00:01:30,019
work today became very popular where
these dense trajectory features

25
00:01:30,019 --> 00:01:34,140
developed by hanging at all and I just
like to give you a brief taste of

26
00:01:34,140 --> 00:01:36,989
exactly how these features worked
because it's kind of interesting and

27
00:01:36,989 --> 00:01:39,609
they inspire some of the later
developments in terms of how come to

28
00:01:39,609 --> 00:01:43,429
show that works actually operating
videos so in this trajectory is what we

29
00:01:43,430 --> 00:01:47,140
do is we have this video the playing and
we're going to be detecting these key

30
00:01:47,140 --> 00:01:50,709
points that are good to track in a video
and then we're going to be tracking them

31
00:01:50,709 --> 00:01:54,679
and you end up with all these little
track let's that we actually track

32
00:01:54,680 --> 00:01:57,759
across the video and then lots of
features about those track let's and

33
00:01:57,759 --> 00:02:01,868
about the surrounding features that
accumulated just crimes so just to give

34
00:02:01,868 --> 00:02:06,549
you an idea about how this worked there
are basically three steps roughly we

35
00:02:06,549 --> 00:02:10,868
detect feature points at different
scales in the image I'll tell me briefly

36
00:02:10,868 --> 00:02:11,960
about how that's done

37
00:02:11,960 --> 00:02:16,810
then go to track those features over
time using optical flow methods optical

38
00:02:16,810 --> 00:02:20,270
flow method solved explain very briefly
they basically give you a motion field

39
00:02:20,270 --> 00:02:23,800
from one thing to another and they tell
you how the scene moved from one frame

40
00:02:23,800 --> 00:02:28,070
to an extent Xtreme and then we're going
to extract a whole bunch of features but

41
00:02:28,069 --> 00:02:30,609
importantly we're not just going to
extract those feature set fixed

42
00:02:30,610 --> 00:02:33,930
positions in the image but we're
actually going to be struck me

43
00:02:33,930 --> 00:02:37,700
speechless and the local coordinate
system every single track let and so

44
00:02:37,699 --> 00:02:41,869
these histogram of greedy insist gotta
flows and and be resource we're going to

45
00:02:41,870 --> 00:02:45,610
be extracted them in the coordinate
system off a track wit and so hard here

46
00:02:45,610 --> 00:02:49,200
we saw histograms gradients and
two-dimensional images are basically

47
00:02:49,199 --> 00:02:51,750
generalizations of that too

48
00:02:51,750 --> 00:02:54,780
videos and so that's the kind of things
that people used to encode the

49
00:02:54,780 --> 00:03:01,009
spatio-temporal bombings in terms of the
key point detection part there's been

50
00:03:01,009 --> 00:03:04,239
quite a lot of work on exactly how to
detect good features and videos to track

51
00:03:04,240 --> 00:03:07,930
and intuitively you don't want to track
a video that are too smooth because he

52
00:03:07,930 --> 00:03:11,580
can't log onto any visual feature as
there are ways for basically getting a

53
00:03:11,580 --> 00:03:16,620
set of points that are easy to track and
a video so there are some papers on this

54
00:03:16,620 --> 00:03:19,509
so you detect a bunch of features like
this

55
00:03:19,509 --> 00:03:23,039
optical flow algorithms on these videos

56
00:03:23,659 --> 00:03:28,060
take a frame and a second frame and it
will solve for a motion field

57
00:03:28,060 --> 00:03:32,409
displacement vector at every single
position in to where it traveled for how

58
00:03:32,409 --> 00:03:35,919
the free moved as I hear some examples
of optical flow results

59
00:03:36,439 --> 00:03:42,270
basically here every single pixel is
colored by a direction in which that

60
00:03:42,270 --> 00:03:46,260
part of the image is currently moving
into video so for example this girl has

61
00:03:46,259 --> 00:03:49,939
all yellow meaning that you probably
translating horizontally or something

62
00:03:49,939 --> 00:03:53,680
like that the two most common methods
for using optical flow for computing it

63
00:03:53,680 --> 00:03:58,069
at least me one of the most common ones
here as blocks from boxing Malik that's

64
00:03:58,069 --> 00:04:00,949
the one that is kind of like a
defaulting to use so if you are

65
00:04:00,949 --> 00:04:03,399
computing optical flow in your own
project I would encourage you to use

66
00:04:03,400 --> 00:04:08,950
this large displacement optical flow
method so using this optical flow we

67
00:04:08,949 --> 00:04:12,199
have all these key points using optical
flow we know also have the move as we

68
00:04:12,199 --> 00:04:15,859
end up tracking these lil truckloads of
may be roughly fifteen frames at a time

69
00:04:15,860 --> 00:04:20,509
so we end up with these half a second
roughly track lets through the video and

70
00:04:20,509 --> 00:04:21,519
then we encode

71
00:04:21,519 --> 00:04:26,129
regions around this track what's with
all these descriptors and then went to

72
00:04:26,129 --> 00:04:29,710
accumulate all these visual Peterson two
histograms and people used to play with

73
00:04:29,709 --> 00:04:34,668
different kinds of like how do you
exactly truncate video specially because

74
00:04:34,668 --> 00:04:37,359
we're going to have a histogram an
independent histogram and every one of

75
00:04:37,360 --> 00:04:40,389
these business and then we're going to
basically create all these histograms

76
00:04:40,389 --> 00:04:45,220
urban with all these visual features and
all of this thing goes into an SVM and

77
00:04:45,220 --> 00:04:48,050
what kind of the rock a layout in terms
of how people address these problems in

78
00:04:48,050 --> 00:04:55,720
the past your truck just think of it as
is going to be fifteen frames and it's

79
00:04:55,720 --> 00:05:01,639
just XY positions so a 15 X Y
coordinates the strangled and then we

80
00:05:01,639 --> 00:05:07,168
extract in the local coordinate system
now in terms of how we actually approach

81
00:05:07,168 --> 00:05:13,859
these problems with that works she never
called Alex net on the very first layer

82
00:05:13,860 --> 00:05:17,560
will receive an image thatís for
example 227 227 by three and

83
00:05:17,560 --> 00:05:22,310
reprocessing it with 96 filters that are
11 by 11 applied it's right for and so

84
00:05:22,310 --> 00:05:27,978
we saw that with Alex net this results
in the 5555 by ninety six volume in

85
00:05:27,978 --> 00:05:30,468
which we actually have all these
responses of all the filters at every

86
00:05:30,468 --> 00:05:34,788
single spatial position so now what
would be a reasonable approach if you

87
00:05:34,788 --> 00:05:38,158
wanted to generalize accomplish all that
work into a case we don't just have a

88
00:05:38,158 --> 00:05:42,579
220 somebody turns 23 but you may be
happening frames that you like to encode

89
00:05:42,579 --> 00:05:47,278
so you have an entire block of 227 227
battery by 15 that's coming in to

90
00:05:47,278 --> 00:05:50,180
accomplish all that work you're trying
to echo the both the spatial and

91
00:05:50,180 --> 00:05:54,209
temporal patterns and inside this little
block of volume so would be like one

92
00:05:54,209 --> 00:05:57,379
idea for how to change accomplish all
that work

93
00:05:57,379 --> 00:06:00,379
generalize it to this case

94
00:06:03,899 --> 00:06:27,609
and arrange them as like two blocks ok
that's interesting I would expect that

95
00:06:27,610 --> 00:06:33,870
do not work very very well so the
problem with that is kind of interesting

96
00:06:33,870 --> 00:06:36,850
basically all these neurons are looking
at only a single frame and then by the

97
00:06:36,850 --> 00:06:39,720
end of the comment that you end up with
you on that are looking at a larger and

98
00:06:39,720 --> 00:06:43,310
larger regions and your challenge so
eventually these neurons with see all of

99
00:06:43,310 --> 00:06:46,470
your input but they would not be able to
very easily relate

100
00:06:47,589 --> 00:06:52,589
like little special control patch in
this image so I'm not sure actually

101
00:06:52,589 --> 00:07:04,149
really good idea did you turn them into
it I think so we'll get to some of those

102
00:07:04,149 --> 00:07:07,149
that do something like that

103
00:07:09,930 --> 00:07:25,199
take 45 channels effectively and you
could put a comment on that so that's

104
00:07:25,199 --> 00:07:28,919
something that all get to I think you
could do that I don't think it's the

105
00:07:28,918 --> 00:07:44,049
best idea as a yes so you're saying that
things in one slice of this time are you

106
00:07:44,050 --> 00:07:48,379
want to extract similar kinds of
features in one time then a different

107
00:07:48,379 --> 00:07:48,990
time

108
00:07:48,990 --> 00:07:52,829
similar to the motivation of doing it
sharing with specially because peter is

109
00:07:52,829 --> 00:07:55,909
here are useful down there as well so
you have the same kind of property where

110
00:07:55,910 --> 00:07:58,910
you'd like to share weights and time not
only in space

111
00:07:59,689 --> 00:08:03,550
ok so building on top of that idea of
the basic thing that people usually do

112
00:08:03,550 --> 00:08:06,400
when they want to apply commercial
networks and videos as they extend these

113
00:08:06,399 --> 00:08:10,138
filters not only to don't only have
filters in space but you also have these

114
00:08:10,139 --> 00:08:14,840
filters and extend them small amounts in
time so before we have 11 Bielema

115
00:08:14,839 --> 00:08:15,750
filters

116
00:08:15,750 --> 00:08:21,709
1111 by tea filters where Tia some small
temporal extent so say for example we

117
00:08:21,709 --> 00:08:28,759
can use a to up to 15 in this particular
case he was 30 2011 by three filters and

118
00:08:28,759 --> 00:08:33,979
then by three because we have RGB and so
basically these filters are now you're

119
00:08:33,979 --> 00:08:36,969
thinking of sliding filters not only in
space and carving out an entire

120
00:08:36,969 --> 00:08:40,469
activation map but you're actually
sliding filters not only in space but

121
00:08:40,469 --> 00:08:44,450
also in time and they have a small
finite temporal extent in time and you

122
00:08:44,450 --> 00:08:48,379
end up carving out an entire activation
volume ok so you're introducing this

123
00:08:48,379 --> 00:08:51,909
time to mention into all your kernels
and to all the are dying stages have an

124
00:08:51,909 --> 00:08:55,899
additional time to mention along which
were performing the convolutions so

125
00:08:55,899 --> 00:08:59,659
that's usually how people extract the
features and then you get this property

126
00:08:59,659 --> 00:09:04,009
where safety is three here and so so
then when we do the spatial temporal

127
00:09:04,009 --> 00:09:07,230
competition we end up with this
parameter sharing scheme going in time

128
00:09:07,230 --> 00:09:11,639
as well as you mentioned so basically
what extent all the filters and time and

129
00:09:11,639 --> 00:09:14,360
then we do convolutions not only in
space but also in time

130
00:09:14,360 --> 00:09:18,800
wind up with activation volume
activation maps so some of these

131
00:09:18,799 --> 00:09:22,818
approaches were proposed quite early on
for example one of the earlier ones

132
00:09:22,818 --> 00:09:28,238
for activity recognition is maybe from
2010 so the idea here was that this is

133
00:09:28,239 --> 00:09:31,798
just a couple of work but instead of
getting a single input of sixty by 40

134
00:09:31,798 --> 00:09:36,108
pics also we are getting in fact seven
frames of sixty by forty and then their

135
00:09:36,109 --> 00:09:40,119
conclusions are three deconvolution as
we refer to them so these filters for

136
00:09:40,119 --> 00:09:44,220
example might be sold by seven but now
by three as well as we end up with a 3d

137
00:09:44,220 --> 00:09:49,499
calm and the three conditions are
applied at every single stage here

138
00:09:50,649 --> 00:09:55,208
similar paper also from 2011 but the
same idea we have a block of friends

139
00:09:55,208 --> 00:09:59,518
coming in and you promised them with 3d
completions three-dimensional filters at

140
00:09:59,519 --> 00:10:03,229
every single point in this commercial
network so this isn't 2011

141
00:10:04,948 --> 00:10:08,748
very similar idea also so these are from
before actually Alex next these

142
00:10:08,749 --> 00:10:12,889
approaches are kind of like smaller know
that work accomplished all that work so

143
00:10:12,889 --> 00:10:16,829
the first kind of large-scale
application of this was from this

144
00:10:16,828 --> 00:10:19,828
awesome paper in 2014 by capacity at all

145
00:10:20,830 --> 00:10:27,540
this is for processing videos so the
model here on the very right that week

146
00:10:27,539 --> 00:10:31,159
we called slow fusion that is the same
idea that I presented so far these are

147
00:10:31,159 --> 00:10:35,750
three-dimensional competitions happening
in both space and time and so that's

148
00:10:35,750 --> 00:10:38,879
slow fusion as we refer to it because
you're slowly using this temporal

149
00:10:38,879 --> 00:10:43,649
information just as before we were
slowly using the spatial information now

150
00:10:43,649 --> 00:10:47,100
there are other ways that you could also
why are up comedy show networks and just

151
00:10:47,100 --> 00:10:51,769
to give you some context historically
this is Google research and Alex let's

152
00:10:51,769 --> 00:10:55,039
just came out and everyone was super
excited because they work extremely well

153
00:10:55,039 --> 00:11:00,579
images and I was in the video analysis
team at Google and we wanted to run on

154
00:11:00,580 --> 00:11:04,060
the YouTube videos and but it was not
quite clear exactly how to generalize

155
00:11:04,059 --> 00:11:07,809
you know commercial networks and then
just to videos so we explored several

156
00:11:07,809 --> 00:11:11,389
kinds of architecture stuff how you can
actually wear this up so floats no

157
00:11:11,389 --> 00:11:17,889
fusion as a 3d called kind of approach
early fusion is this idea that someone

158
00:11:17,889 --> 00:11:21,230
described earlier where you take a chunk
of friends and just woke up need them

159
00:11:21,230 --> 00:11:25,430
long channels you might end up with a
227 227 by like 45

160
00:11:25,429 --> 00:11:29,500
everything is just stocked up and you do
a single column over it so it's kind of

161
00:11:29,500 --> 00:11:35,200
like your filters on the very first call
later have a large temporal extent but

162
00:11:35,200 --> 00:11:38,780
from then on everything else is
two-dimensional competition in fact we

163
00:11:38,779 --> 00:11:42,139
call it early because he refused the
temporal information very early on in

164
00:11:42,139 --> 00:11:45,879
the very first letter from then on
everything just to call you can imagine

165
00:11:45,879 --> 00:11:49,490
architecture is likely convolution so
here the ideas would take to Alex nets

166
00:11:49,490 --> 00:11:53,169
we place them say ten things apart so
they both computed independently on

167
00:11:53,169 --> 00:11:57,169
these 10 points apart and then we must
be much later in the fully connected

168
00:11:57,169 --> 00:12:00,620
layers and then we had a single claim
baseline that is only looking at a

169
00:12:00,620 --> 00:12:03,830
single frame of the video so you can
play with exactly how the white wire up

170
00:12:03,830 --> 00:12:08,440
these models look Asian model you can
imagine that they've had three

171
00:12:08,440 --> 00:12:13,130
dimensional colonels now the first layer
you can actually visualize them and

172
00:12:13,129 --> 00:12:16,210
these are the kinds of features you end
up learning on videos these are

173
00:12:16,210 --> 00:12:18,990
basically features that were familiar
with except they're moving because now

174
00:12:18,990 --> 00:12:22,680
these filters are also extended a small
amount and time to have these little

175
00:12:22,679 --> 00:12:26,049
moving blobs and some of them are static
and some of them are moving and they're

176
00:12:26,049 --> 00:12:30,729
basically detecting motion on the very
first layer and so you end up a nice

177
00:12:30,730 --> 00:12:31,960
moving bombings

178
00:12:31,960 --> 00:12:48,090
question is how much we'll get to that
and I think the answer is probably yes

179
00:12:48,090 --> 00:12:53,269
just as in spatial it works better if
smaller filters and you have more depth

180
00:12:53,269 --> 00:12:56,370
at the same applies I think in time and
we'll see an architecture that does that

181
00:12:56,370 --> 00:13:07,220
mean but expecting

182
00:13:08,190 --> 00:13:13,580
classifying so we have a video and were
still classifying number of categories

183
00:13:13,580 --> 00:13:17,970
at every single frame but now you're not
only function that single frame but also

184
00:13:17,970 --> 00:13:23,740
a small number of frames alot on both
sides so maybe your prediction is

185
00:13:23,740 --> 00:13:28,539
actually a function of safety drinks a
half a second video to end up with fun

186
00:13:28,539 --> 00:13:32,909
moving pictures in this paper also
released video they said over one

187
00:13:32,909 --> 00:13:36,639
million videos and 500 classes just a
given context for why this is actually

188
00:13:36,639 --> 00:13:41,759
it's kind of difficult to work with
videos and right now I think because

189
00:13:41,759 --> 00:13:45,480
problem right now i think is that
there's not too many very large-scale

190
00:13:45,480 --> 00:13:49,820
datasets like millions of very varied
images that you see an image that there

191
00:13:49,820 --> 00:13:53,230
are no really good equivalent of that in
the video domain and so we tried with

192
00:13:53,230 --> 00:13:56,730
this for status and back in 2013 but I
don't think it actually we fully achieve

193
00:13:56,730 --> 00:14:00,519
that and I think we're still not seeing
very good really lost the assassin

194
00:14:00,519 --> 00:14:03,579
videos and that's partly why we're also
slightly discouraging some of you from

195
00:14:03,580 --> 00:14:08,050
working on this on projects because you
can't retrain these very powerful

196
00:14:08,049 --> 00:14:12,969
features because the data sets are just
not quite there another kind of

197
00:14:12,970 --> 00:14:16,100
interesting things that you see and this
is why we also sometimes caution people

198
00:14:16,100 --> 00:14:21,490
from working on videos and getting very
elaborate very quickly with them because

199
00:14:21,490 --> 00:14:24,490
sometimes people think they have videos
and get very excited if they want to do

200
00:14:24,490 --> 00:14:27,810
3d color shows Alice teams and they just
think about all the possibilities that

201
00:14:27,809 --> 00:14:31,469
opened up for them but actually turns
out that single frame methods are a very

202
00:14:31,470 --> 00:14:34,820
strong baseline and I would always
encourage you to run that first so don't

203
00:14:34,820 --> 00:14:37,710
worry about the motion in your video and
just try single frame that works first

204
00:14:37,710 --> 00:14:40,990
so for example in this paper we found
that a single from baseline was about

205
00:14:40,990 --> 00:14:44,610
59.3% classification accuracy in our
dataset

206
00:14:44,610 --> 00:14:48,600
and then we tried our best to actually
take into account small local motion but

207
00:14:48,600 --> 00:14:54,440
we ended up bumping down by 11.6% so all
this extra work all the extra computer

208
00:14:54,440 --> 00:14:57,529
and then you ended up with relatively
small gains I'm going to try to tell you

209
00:14:57,528 --> 00:15:02,088
why that might be a basically video is
not always as useful as you might

210
00:15:02,089 --> 00:15:07,230
intuitively think and so here are some
examples of kind of predictions that we

211
00:15:07,230 --> 00:15:11,800
are different data sets of sports and
our predictions and I think this kind of

212
00:15:11,799 --> 00:15:15,528
highlight slightly why adding video
might not be as helpful in some settings

213
00:15:15,528 --> 00:15:19,740
in particular here if you're trying to
distinguish sports and think about it

214
00:15:19,740 --> 00:15:23,930
trying to distinguish say tennis from
swimming or something like that it turns

215
00:15:23,929 --> 00:15:26,729
out that you actually don't need very
fine local motion information if you're

216
00:15:26,730 --> 00:15:29,610
trying to distinguish tennis from
swimming right lots of blue stuff lots

217
00:15:29,610 --> 00:15:33,350
of red stuff like the images actually
have a huge amount of information and so

218
00:15:33,350 --> 00:15:36,240
you're putting in a lot of additional
parameters and trying to go after these

219
00:15:36,240 --> 00:15:40,959
local motions but and most in most
classes actually be local motions are

220
00:15:40,958 --> 00:15:44,289
not very important they're only
important if you have very fine-grained

221
00:15:44,289 --> 00:15:47,919
categories where the small motion
actually really matters a lot as a lot

222
00:15:47,919 --> 00:15:52,419
of you if you have videos you'll be
inclined to use spatial temporal crazy

223
00:15:52,419 --> 00:15:56,860
video networks but I think very hard
about is that locomotion extremely

224
00:15:56,860 --> 00:15:59,980
important and you're setting because if
it isn't you might end up with results

225
00:15:59,980 --> 00:16:04,070
like this where he put in a lot of work
and it may not work well let's look at

226
00:16:04,070 --> 00:16:10,180
some other video classification that
works so this is April 2015 its

227
00:16:10,179 --> 00:16:14,698
relatively popular it's called sea 3d
and the idea here was basically your

228
00:16:14,698 --> 00:16:18,528
network has this very nice architecture
its three-month recalled and two by two

229
00:16:18,528 --> 00:16:22,110
pool throughout the idea here is that
cool let's do the exact same thing but

230
00:16:22,110 --> 00:16:25,169
extend everything in time so going back
to your point you want very small

231
00:16:25,169 --> 00:16:29,069
filters so this is everything is three
my tree might recall to buy to buy to

232
00:16:29,070 --> 00:16:33,100
pool throughout the architecture so it's
a very simple kind of big united in 3d

233
00:16:33,100 --> 00:16:36,528
kind of approach and that works
reasonably well and you can look at this

234
00:16:36,528 --> 00:16:38,429
paper for reference

235
00:16:38,429 --> 00:16:42,389
another form of approaches actually that
works quite well as from Karen Simonian

236
00:16:42,389 --> 00:16:43,778
in 2014

237
00:16:43,778 --> 00:16:48,299
Simonian by the way as the same he's a
person who came up with the BG not he

238
00:16:48,299 --> 00:16:51,828
also has a very nice paper on video
classification and the idea here is that

239
00:16:51,828 --> 00:16:54,299
he didn't want to do three dimensional
competitions because it's kind of

240
00:16:54,299 --> 00:16:55,219
painful to have it

241
00:16:55,220 --> 00:17:00,360
98 or find it and so on so he only used
to measure compilations but the idea

242
00:17:00,360 --> 00:17:05,179
here is that we have to come that's
looking at an image and the other one is

243
00:17:05,179 --> 00:17:10,298
looking at optical flow of the video so
both of these are just images but the

244
00:17:10,298 --> 00:17:14,699
optical flow basically tells you how
things are moving in the in the image

245
00:17:14,699 --> 00:17:19,120
and so both of these are just kind of
like an avg net like or Alex not like

246
00:17:19,119 --> 00:17:23,139
that one of them another close one of
them on the image and you extract

247
00:17:23,140 --> 00:17:28,059
optical flow with say the Bronx method
before and then you let the UF use that

248
00:17:28,058 --> 00:17:31,720
information very late in the end so both
of these come up with some idea about

249
00:17:31,720 --> 00:17:34,850
what they are seeing in terms of the
classes in the video and then refused

250
00:17:34,849 --> 00:17:37,859
them and there are different ways of
using them so they found for example

251
00:17:37,859 --> 00:17:42,979
that if you just use a special comments
are only looking at images you get some

252
00:17:42,980 --> 00:17:47,120
performance if you use come on just the
optical flow it actually performs even

253
00:17:47,119 --> 00:17:49,558
slightly better than just looking at the
raw images

254
00:17:49,558 --> 00:17:54,178
optical flow actually here in this case
contains a lot of information and then

255
00:17:54,179 --> 00:17:58,538
if you actually end up even better now
an interesting point to make here by the

256
00:17:58,538 --> 00:18:01,879
way is that if you have this kind of
architecture especially here

257
00:18:01,880 --> 00:18:05,700
complex history much by three filters
you might imagine that actually would

258
00:18:05,700 --> 00:18:10,038
think that I mean why does it help to
actually put an optical flow you'd

259
00:18:10,038 --> 00:18:13,158
imagine that in the center and framework
we're hoping that these comments learn

260
00:18:13,159 --> 00:18:16,049
everything from scratch in particular
they should be able to learn something

261
00:18:16,048 --> 00:18:20,599
that simulates the computation of
computing optical flow and it turns out

262
00:18:20,599 --> 00:18:24,230
that that might not be the case because
sometimes when you compare video

263
00:18:24,230 --> 00:18:29,440
networks on only the hospital and then
it works better and so I think the

264
00:18:29,440 --> 00:18:34,169
reason for that is probably comes back
to actually data since we don't have

265
00:18:34,169 --> 00:18:37,900
enough data we have small amount of data
I think you actually probably don't have

266
00:18:37,900 --> 00:18:42,730
enough data to actually learn very good
optical flow like features and so that

267
00:18:42,730 --> 00:18:45,599
would be my particular answer why
actually hard getting up to go to the

268
00:18:45,599 --> 00:18:48,819
network is probably helping out in many
cases if you guys are working on your

269
00:18:48,819 --> 00:18:51,839
project with videos I would encourage
you to actually try to be this kind of

270
00:18:51,839 --> 00:18:52,779
architecture

271
00:18:52,779 --> 00:18:57,480
optical flow and then pretend that it's
an image and you could come to an end to

272
00:18:57,480 --> 00:19:01,808
that seems like a relatively reasonable
approach ok so so far we've only talked

273
00:19:01,808 --> 00:19:06,339
about the little local information in
time right so we have these little

274
00:19:06,339 --> 00:19:07,398
pieces

275
00:19:07,398 --> 00:19:10,069
black half a second ever tried to take
advantage of it should be better

276
00:19:10,069 --> 00:19:13,739
classification but what happens if you
have videos that actually have much

277
00:19:13,739 --> 00:19:14,489
longer

278
00:19:14,489 --> 00:19:19,700
temporal kind of dependencies that you
like to model so it's not only that the

279
00:19:19,700 --> 00:19:22,319
local motion is important but actually
there are some events throughout the

280
00:19:22,319 --> 00:19:25,548
video that are much larger in time
scales in your network and they actually

281
00:19:25,548 --> 00:19:29,618
matter so event to happening after event
one can be very indicative of some class

282
00:19:29,618 --> 00:19:33,999
and you'd like to actually model that
would work so are the kinds of

283
00:19:33,999 --> 00:19:39,659
approaches that you might think for
trying to actually you know how would

284
00:19:39,659 --> 00:19:42,659
you mind actually model these kinds of
much longer-term events

285
00:19:44,618 --> 00:19:54,009
ok so attention model perhaps so you may
be like to have any tension over you're

286
00:19:54,009 --> 00:19:56,729
trying to classify this entire video
maybe like to have a tension over

287
00:19:56,729 --> 00:19:58,129
different parts of the video

288
00:19:58,128 --> 00:20:12,689
yeah that's a good idea I see so you're
saying that we have these multiscale

289
00:20:12,690 --> 00:20:16,479
approach is where we process images on
very low detail level but also sometimes

290
00:20:16,479 --> 00:20:20,298
we resize the images and process them on
the global level as a maybe the frames

291
00:20:20,298 --> 00:20:23,710
we can actually like speed up the video
and put a comment on that I don't think

292
00:20:23,710 --> 00:20:28,048
that's a very common but it's senator
sensible idea I think yeah so the

293
00:20:28,048 --> 00:20:33,618
problem roughly is that basically this
extent is maybe ten times too short it

294
00:20:33,618 --> 00:20:37,019
doesn't spent our many seconds so how do
we make architectures that are

295
00:20:37,019 --> 00:20:40,179
functional much longer time scales and
their prediction

296
00:20:42,150 --> 00:20:48,300
yes the one idea here is we have this
video and we have different classes that

297
00:20:48,299 --> 00:20:50,599
would like to predict at every single
point in time but we want that

298
00:20:50,599 --> 00:20:54,849
prediction to be a function not only a
little choked up 15 seconds but actually

299
00:20:54,849 --> 00:20:59,149
a much longer time expense so the idea
that is sensible as you actually use

300
00:20:59,150 --> 00:21:01,769
record while at work somewhere in the
architecture because your current

301
00:21:01,769 --> 00:21:04,990
networks allow you to have infinite
context and principal over everything

302
00:21:04,990 --> 00:21:08,579
that has happened before you up till
that time especially if you go back to

303
00:21:08,579 --> 00:21:12,119
this paper that I've already showing you
in 2011 it turns out that they have an

304
00:21:12,119 --> 00:21:16,289
entire section where the cheek take this
and they actually have analyst team that

305
00:21:16,289 --> 00:21:21,109
does exactly that this is a peep from
2011 using 3d called NLST I'm so way

306
00:21:21,109 --> 00:21:25,899
before they will call in 2011 and so
this paper basically has it all

307
00:21:25,900 --> 00:21:29,920
the model little local motion with 3d
calm and they most model global motion

308
00:21:29,920 --> 00:21:34,860
with Ella stance and so they put a stamp
on the play the full connected layers so

309
00:21:34,859 --> 00:21:37,849
they strung together fully connected
layers with this recurrence and then

310
00:21:37,849 --> 00:21:40,939
when you're predicting classes every
single frame you have infinite context

311
00:21:40,940 --> 00:21:45,930
this paper is as I think quite ahead of
its time and it basically has it all

312
00:21:45,930 --> 00:21:49,900
except it's only set at 65 times I'm not
sure was not more popular I think people

313
00:21:49,900 --> 00:21:54,680
are basically this is way ahead of its
time paper that recognizes both of these

314
00:21:54,680 --> 00:21:59,380
national team sweat before I even knew
about them so since then and there are

315
00:21:59,380 --> 00:22:02,990
several more recently percent actually
kind of take a similar approach so in

316
00:22:02,990 --> 00:22:07,190
2015 by Jeff Donahue at all from
Berkeley the idea here is that you have

317
00:22:07,190 --> 00:22:08,610
video you like to again

318
00:22:08,609 --> 00:22:11,819
classify every single frame but they
have these comments that look at

319
00:22:11,819 --> 00:22:14,809
individual frames but then they have
also Alice team that string this

320
00:22:14,809 --> 00:22:19,389
together temporarily a similar idea also
from a paper from I think this is Google

321
00:22:19,390 --> 00:22:24,160
and so the idea here is that they have
optical flow and images are processed by

322
00:22:24,160 --> 00:22:28,930
complex and then again you have analyst
am that merges that over time so again

323
00:22:28,930 --> 00:22:34,680
this this combination of local and
global so so far we've looked at kind of

324
00:22:34,680 --> 00:22:37,789
two architectural patterns in
accomplishing your classification that

325
00:22:37,789 --> 00:22:43,170
actually takes into account important
information modeling locomotion which

326
00:22:43,170 --> 00:22:47,289
for example beast entry to call for use
optical flow or look more global motion

327
00:22:47,289 --> 00:22:51,059
where we have chemistry together
sequences morning time steps or fusion

328
00:22:51,059 --> 00:22:54,418
of the two now actually I like to make
the point that there's

329
00:22:54,419 --> 00:22:59,879
another cleaner very nice interesting
idea that I saw in a recent paper and

330
00:22:59,878 --> 00:23:03,689
then I like much more and so here's
basically the rock picture of what

331
00:23:03,690 --> 00:23:08,330
things look like right now we have some
video and we have a 3d come that say

332
00:23:08,329 --> 00:23:13,038
that is using optical flow may be
ordered using 3d column or both on the

333
00:23:13,038 --> 00:23:17,898
trunk of frame crank up your data and
then have are nestled atop unfortunately

334
00:23:17,898 --> 00:23:20,979
or something like that that are doing
the long-term modeling and so kind of

335
00:23:20,980 --> 00:23:24,950
kind of not very nice are unsettling
about this is that their son of this

336
00:23:24,950 --> 00:23:29,499
ugly asymmetry about these components to
have these parties neurons inside the 3d

337
00:23:29,499 --> 00:23:33,079
come that are only a fraction of some
small local chunk of video and then you

338
00:23:33,079 --> 00:23:35,849
have these neurons in the very top that
our function of everything in the video

339
00:23:35,849 --> 00:23:40,808
because their record units that are a
function of everything that's come

340
00:23:40,808 --> 00:23:45,288
before it and so it's kind of like an
unsettling asymmetry or something like

341
00:23:45,288 --> 00:23:48,720
that so there's a paper that has a very
clever any idea from a few weeks ago

342
00:23:48,720 --> 00:23:54,249
that is much more nice and homogeneous
lifestyle where everything is very nice

343
00:23:54,249 --> 00:23:58,118
and margins and simple and so I don't
know if anyone can think of how we could

344
00:23:58,118 --> 00:24:06,819
but we can do to make everything much
more cleaner and I couldn't because I

345
00:24:06,819 --> 00:24:09,019
don't come up with this idea but I
thought it was cool what I read it

346
00:24:09,019 --> 00:24:22,399
before the comment actually starts
processing the images not sure what that

347
00:24:22,398 --> 00:24:25,288
would give you see would have torn
asunder optical information and comments

348
00:24:25,288 --> 00:24:30,169
on top that somehow you would certainly
have neurons that are function of

349
00:24:30,169 --> 00:24:34,090
everything but it's not clear what the
US team will be doing in that case

350
00:24:34,089 --> 00:24:37,388
likely to be blurring the pixels it's
too low level probably processing at

351
00:24:37,388 --> 00:24:51,678
that point then there's a lot of media
like an intolerable that works

352
00:24:51,679 --> 00:24:56,389
differently temporal resolutions that
this problem is looking every bit you

353
00:24:56,388 --> 00:25:04,038
another time that is looking like every
trip every a friend and I say so your

354
00:25:04,038 --> 00:25:07,009
ideas that I think it's similar to what
someone pointed out where you take this

355
00:25:07,009 --> 00:25:10,179
video and you work on multiple scales on
that video to speed up the video when

356
00:25:10,179 --> 00:25:14,778
you slow down the video and then you
have 3d come that's on the front row

357
00:25:14,778 --> 00:25:23,989
like speeds or something like that it's
a sensible idea can you do background

358
00:25:23,989 --> 00:25:26,669
subtraction only look at things are
interesting to look at I think that's a

359
00:25:26,669 --> 00:25:30,639
reasonable idea I think it kind of goes
against this idea of having end-to-end

360
00:25:30,638 --> 00:25:33,868
learning because you're introducing like
this explicit computation that you think

361
00:25:33,868 --> 00:25:37,759
is useful as he got

362
00:25:42,288 --> 00:25:48,658
sharing between the 3d comes out and
they are and that's interesting I'm not

363
00:25:48,659 --> 00:25:52,139
a hundred percent sure because the Arnon
is just hittin state vector and matrix

364
00:25:52,138 --> 00:25:55,678
multiplies and things like that but in a
calm players we have disliked spatial

365
00:25:55,679 --> 00:26:05,369
structure I'm not actually sure how the
sharing would work but yeah ok so the

366
00:26:05,368 --> 00:26:11,319
idea is that we're going to see we're
going to get rid of the are now we're

367
00:26:11,319 --> 00:26:14,408
going to basically take on that and
we're going to make every single neuron

368
00:26:14,409 --> 00:26:17,379
and that comes out to be a small
recurrent neural network like every

369
00:26:17,378 --> 00:26:21,648
single neuron becomes recurrent in the
calm that ok so the way this will work

370
00:26:21,648 --> 00:26:27,178
and I think it's a beautiful but their
picture is kind of a kind of ugly so

371
00:26:27,179 --> 00:26:29,730
much for this makes no sense so let me
try to explain this in a slightly

372
00:26:29,730 --> 00:26:36,278
different way what we'll do instead is
that we have a caller somewhere in the

373
00:26:36,278 --> 00:26:40,278
neural network and it takes input from
below the operative a previous calmly or

374
00:26:40,278 --> 00:26:43,398
something that we're doing competitions
over this to compute the output at this

375
00:26:43,398 --> 00:26:47,528
layer right so the idea here is we're
going to make every single come a little

376
00:26:47,528 --> 00:26:53,058
later a kind of a recurrent player and
so the way we do that is we just as

377
00:26:53,058 --> 00:26:57,528
for we take the input from below us and
we do comes over it but we also take our

378
00:26:57,528 --> 00:27:00,778
previous output from the previous time
instead of this

379
00:27:00,778 --> 00:27:05,638
players out there so that's this caller
from previous time step in addition to

380
00:27:05,638 --> 00:27:09,408
the current input that this time stuff
and we do competitions over both this

381
00:27:09,409 --> 00:27:13,830
one and that one and then we kind of
have you know we don't call when we have

382
00:27:13,829 --> 00:27:19,490
these activations from current input and
activations from our previous outfit and

383
00:27:19,490 --> 00:27:24,649
we add them up or something like that we
do recurrent like that work like merge

384
00:27:24,648 --> 00:27:28,719
of those two to produce are up and so
we're a function of the current input

385
00:27:28,720 --> 00:27:34,730
but also a function of our previous
activations if that makes sense and so

386
00:27:34,730 --> 00:27:37,200
it's very nice about this is that were
in fact only using two-dimensional

387
00:27:37,200 --> 00:27:41,149
competitions here and there is no 3d
count anywhere because both of these are

388
00:27:41,148 --> 00:27:44,678
width by height by depth rights of the
previous convo liam is just with highly

389
00:27:44,679 --> 00:27:49,309
depth from the previous layer and we are
with high depth from previous time and

390
00:27:49,308 --> 00:27:52,408
some of these are two-dimensional
competitions but we end up with kind of

391
00:27:52,409 --> 00:27:57,710
like recurrent process in here and so
one way to see this also with recurrent

392
00:27:57,710 --> 00:28:00,659
neural networks which we looked at is
that you have this recurrence where

393
00:28:00,659 --> 00:28:03,980
you're trying to compete in state and
it's a function of your previous state

394
00:28:03,980 --> 00:28:07,878
and the current attacks and so we looked
at many different ways of actually

395
00:28:07,878 --> 00:28:14,058
wiring up that recurrence so there's a
velar por el esteem or the GRU which GRU

396
00:28:14,058 --> 00:28:17,950
is a simpler version of LSD and if you
recall but it almost always has similar

397
00:28:17,950 --> 00:28:21,548
performance to analyst team so GRU a
slightly different update formulas for

398
00:28:21,548 --> 00:28:24,499
actually performing that recurrence and
see what they do in this paper is

399
00:28:24,499 --> 00:28:27,950
basically they take the GRU because it's
a simpler version of an Austrian that

400
00:28:27,950 --> 00:28:31,899
works just as well but instead of every
single matrix multiply it's kind of like

401
00:28:31,898 --> 00:28:36,758
replaced with a calm if you can you can
imagine that every single matrix

402
00:28:36,759 --> 00:28:41,819
multiply here just becomes a call so we
can evolve over our input and become

403
00:28:41,819 --> 00:28:45,798
involved a large output and that's the
before and the below and then we combine

404
00:28:45,798 --> 00:28:50,329
them with the recurrence just us in the
GRU to actually get our activations and

405
00:28:50,329 --> 00:28:57,158
so before it looked like this and now it
just looks like that so we don't have

406
00:28:57,159 --> 00:29:01,179
some parts of the internet and extent of
some parts finite we just have this our

407
00:29:01,179 --> 00:29:05,679
income that where every single layer is
returned its computing but it before but

408
00:29:05,679 --> 00:29:06,410
also fun

409
00:29:06,410 --> 00:29:11,610
its previous efforts and so this link on
that as a function of everything and

410
00:29:11,609 --> 00:29:14,990
it's very kind of uniform and kinda like
a gene that you just 233 called too much

411
00:29:14,990 --> 00:29:19,799
in mexico india recurrent and that's a
maybe that's just the answer my simplest

412
00:29:19,799 --> 00:29:27,579
thing so somebody so if you'd like to
use spatial temporal commercial networks

413
00:29:27,579 --> 00:29:30,819
and your projects and your very excited
because your videos the first thing to

414
00:29:30,819 --> 00:29:34,359
do is stop and you should think about
whether or not you really need to

415
00:29:34,359 --> 00:29:37,740
process locomotion or global motion or
emotion is really important your

416
00:29:37,740 --> 00:29:41,839
classification task if you really think
motion is important to you then think

417
00:29:41,839 --> 00:29:44,829
about whether or not you need to model
local motions are those are important

418
00:29:44,829 --> 00:29:46,929
for all the global motion is very
important

419
00:29:46,930 --> 00:29:50,370
based on that you get a hint of what you
should try about you always have to

420
00:29:50,369 --> 00:29:54,069
compare that to a single from baseline I
would say and then you should try using

421
00:29:54,069 --> 00:29:57,539
optical flow because it seems that if
you especially smaller amount of data it

422
00:29:57,539 --> 00:30:02,039
actually is very important it's like a
very nice signal tax lien code that and

423
00:30:02,039 --> 00:30:06,099
explicitly specified that optical flow
is a useful feature to look at and you

424
00:30:06,099 --> 00:30:09,609
can try this Dr you are seeing that work
that afternoon just now but I think this

425
00:30:09,609 --> 00:30:12,599
is too recent experimental so I'm
actually not sure if I can fully

426
00:30:12,599 --> 00:30:16,589
endorses or if it works it seems like
it's a very nice idea but it hasn't been

427
00:30:16,589 --> 00:30:21,849
proven yet and so that's that's kind of
like the rock layout of happy process

428
00:30:21,849 --> 00:30:25,339
videos in the field so I know if there
is any questions because Justin is going

429
00:30:25,339 --> 00:30:28,339
to come next

430
00:30:33,980 --> 00:30:43,289
you are seeing this one hasn't been used
for it all P thats good question I don't

431
00:30:43,289 --> 00:30:46,879
think so I'm not super duper expert on
LLP but I haven't seen this idea before

432
00:30:46,880 --> 00:30:52,980
so i would i would guess that I haven't
seen her I don't think so good

433
00:31:18,880 --> 00:31:26,660
in on a side with a million I would say
that definitely something people would

434
00:31:26,660 --> 00:31:31,810
want to do you don't see too many papers
that do both of them just because people

435
00:31:31,809 --> 00:31:35,639
like the kind of guy sleeping problems
and tackle them maybe not jointly but

436
00:31:35,640 --> 00:31:38,620
certainly the company are trying to get
something working in a real system you

437
00:31:38,619 --> 00:31:42,869
would do something like that but I don't
think there's anything that you would do

438
00:31:42,869 --> 00:31:45,449
you probably do this with the late
fusion approach where you have a

439
00:31:45,450 --> 00:31:49,039
whatever works best on videos whatever
works best on audio and then emerged out

440
00:31:49,039 --> 00:31:55,029
somewhere later somehow but that's only
something I can do and with contend with

441
00:31:55,029 --> 00:31:57,639
the neural networks right very simple
because you just have a player that's

442
00:31:57,640 --> 00:32:00,410
looking at the output of both at some
point and then you're classifying as a

443
00:32:00,410 --> 00:32:09,860
function of both so we're going to
surprise them and I guess we have to get

444
00:32:09,859 --> 00:32:11,179
here

445
00:32:11,180 --> 00:32:14,180
hopefully it works

446
00:32:29,148 --> 00:32:34,108
ok so I guess we're gonna switch gears
completely and entirely and talk about

447
00:32:34,108 --> 00:32:38,199
unsupervised learning so I'd like to
make a little bit of a contrast here

448
00:32:38,200 --> 00:32:42,460
that first we're gonna talk about some
sort of basic definitions on

449
00:32:42,460 --> 00:32:46,009
unsupervised learning and we're going to
talk about two different sort of ways

450
00:32:46,009 --> 00:32:50,858
that unsupervised learning has recently
been attacked by deporting people so in

451
00:32:50,858 --> 00:32:53,408
particular we gonna talk about auto
encoders and then this idea of

452
00:32:53,409 --> 00:32:58,679
adversarial networks and I guess I need
my clicker right so pretty much

453
00:32:58,679 --> 00:33:03,259
everything we've seen in this class so
far is supervised learning so the basic

454
00:33:03,259 --> 00:33:07,128
setup behind pretty much all supervised
learning problems is that we assume that

455
00:33:07,128 --> 00:33:11,769
our dataset has sort of each data point
has sort of two distinct parts we have

456
00:33:11,769 --> 00:33:15,858
our data access and then we have some
label or output why that we want to have

457
00:33:15,858 --> 00:33:20,028
produced from that from that input and
our whole goal in supervised learning is

458
00:33:20,028 --> 00:33:24,888
to learn some function that takes in our
input tax and then produces this output

459
00:33:24,888 --> 00:33:29,538
or label why and if you really think
about it pretty much almost everything

460
00:33:29,538 --> 00:33:33,088
we've seen in this class is some
instances of this supervised learning

461
00:33:33,088 --> 00:33:37,358
set up so something like image
classification acts as an image and then

462
00:33:37,358 --> 00:33:41,960
why is a label for something like object
detection access an image and then why

463
00:33:41,960 --> 00:33:46,119
is maybe a set of objects in the image
that you won't find why could be a

464
00:33:46,118 --> 00:33:50,238
caption and then we look at capture name
could be a video and now why it could be

465
00:33:50,239 --> 00:33:55,838
either a label or a caption or pretty
much anything anything so I just want to

466
00:33:55,838 --> 00:33:59,450
make the point that supervised learning
is this very very very powerful powerful

467
00:33:59,450 --> 00:34:03,819
and generic framework that encompass
encompasses everything we've done in the

468
00:34:03,819 --> 00:34:08,960
class so far and the other point is that
supervised learning actually make system

469
00:34:08,960 --> 00:34:12,639
that works systems that work really well
in practice and is very useful for

470
00:34:12,639 --> 00:34:14,628
practical applications

471
00:34:14,628 --> 00:34:17,898
unsupervised learning i think is a
little bit more of an open research

472
00:34:17,898 --> 00:34:22,338
question at this point in time so it's
really cool I think it's really

473
00:34:22,338 --> 00:34:26,199
important for solving a guy in general
but at this point it's maybe a little

474
00:34:26,199 --> 00:34:30,028
bit more of a research focus to type of
area it's also a little bit less

475
00:34:30,028 --> 00:34:34,568
well-defined so it's an unsupervised
learning we generally assume that we

476
00:34:34,568 --> 00:34:37,579
have just data we only have pacs we
don't have any why

477
00:34:38,349 --> 00:34:44,009
and the goal of unsupervised learning is
to do something with that data acts and

478
00:34:44,009 --> 00:34:48,199
the something that we're trying to do
really depends on the problem so some so

479
00:34:48,199 --> 00:34:51,939
in general we hope that we can discover
some type of latent structure in the

480
00:34:51,940 --> 00:34:56,710
data acts without explicitly knowing
anything about the labels so some

481
00:34:56,710 --> 00:34:59,650
classical examples that you might have
seen in previous machine learning

482
00:34:59,650 --> 00:35:04,009
classes would be things like clustering
so something like a means we're just a

483
00:35:04,009 --> 00:35:07,728
bunch of points and we discover
structure by classifying them into

484
00:35:07,728 --> 00:35:13,268
clusters some other classical examples
of unsupervised learning would be

485
00:35:13,268 --> 00:35:18,248
something like principal component
analysis where X is just at this point

486
00:35:18,248 --> 00:35:22,098
of data and we want to discover some
low-dimensional representation of that

487
00:35:22,099 --> 00:35:27,170
input data so unsupervised learning is
this really is sort of cool area but a

488
00:35:27,170 --> 00:35:30,519
little bit more problems specific and a
little bit less well defined in

489
00:35:30,518 --> 00:35:37,228
supervised learning so two things that
to architecture is in particular that

490
00:35:37,228 --> 00:35:42,358
people in deep learning have done for
unsupervised learning these ideas as

491
00:35:42,358 --> 00:35:46,048
this idea of an audio encoder will talk
about sort of traditional Ottoman

492
00:35:46,048 --> 00:35:49,318
quarters that have a very very long
history will also talk about variational

493
00:35:49,318 --> 00:35:54,308
auto encoders which are this sort of
news cool Asian twist on them will also

494
00:35:54,309 --> 00:35:57,729
talk about some generative adversarial
networks that actually this really nice

495
00:35:57,728 --> 00:36:06,718
idea but let you generate images and
model sample from natural images so the

496
00:36:06,719 --> 00:36:09,548
idea with an audio encoder is is pretty
simple

497
00:36:09,548 --> 00:36:14,088
we have our input sacks which is some
data and we're gonna pass this input

498
00:36:14,088 --> 00:36:19,710
data through some kind of encoding
network to produce some features some

499
00:36:19,710 --> 00:36:24,440
latent features so this you could think
this stage you could think up a little

500
00:36:24,440 --> 00:36:28,219
bit like a learnable principal component
analysis we're going to take our input

501
00:36:28,219 --> 00:36:33,298
data and then converted into some other
feature representation so those many

502
00:36:33,298 --> 00:36:38,940
times these access will be images like
these are 10 images shown here so this

503
00:36:38,940 --> 00:36:42,989
this encoder network could be something
very complicated so for something like

504
00:36:42,989 --> 00:36:47,228
PCA it's just a simple linear transform
but in general this might be a fully

505
00:36:47,228 --> 00:36:51,799
connected network originally sort of
maybe five or 10 years ago this

506
00:36:51,800 --> 00:36:56,130
often a single they're fully connected
to network with sigmoid units now it's

507
00:36:56,130 --> 00:37:00,410
often a deep deep network with trailer
units and this could also be something

508
00:37:00,409 --> 00:37:09,230
like a convolutional not work right so
we also have this idea that Z

509
00:37:09,230 --> 00:37:13,820
the features that we are that we learn
are usually smaller in size than acts so

510
00:37:13,820 --> 00:37:18,789
we won't need to be some kind of useful
features about the data acts so we we

511
00:37:18,789 --> 00:37:22,610
don't want the network to just transform
the net transport the data into some

512
00:37:22,610 --> 00:37:26,370
useless representation we want to force
that actually crush the data down and

513
00:37:26,369 --> 00:37:29,900
summarize it statistics and some useful
way that could hopefully be useful

514
00:37:29,900 --> 00:37:34,720
person downstream processing but the
problem is that we don't really have any

515
00:37:34,719 --> 00:37:39,219
explicit labels to use for this
downstream processing so instead we need

516
00:37:39,219 --> 00:37:43,159
to invent some kind of a surrogate ask
that we can use using just just the data

517
00:37:43,159 --> 00:37:50,159
itself so the circuit asked that we
often use for auto encoders is this idea

518
00:37:50,159 --> 00:37:55,719
of reconstruction so since we don't have
any wise to learn a mapping instead

519
00:37:55,719 --> 00:38:00,119
we're just gonna try to reproduce the
data acts from those features Z and

520
00:38:00,119 --> 00:38:05,119
especially if those features are smaller
in size than hopefully that'll force the

521
00:38:05,119 --> 00:38:07,139
network to act to summarize

522
00:38:07,139 --> 00:38:11,420
to summarize the useful statistics of
the input data and hopefully discover

523
00:38:11,420 --> 00:38:16,289
some useful features that could be one
useful for reconstruction but more

524
00:38:16,289 --> 00:38:19,920
generally might be those features might
be useful for some other tasks if we

525
00:38:19,920 --> 00:38:26,340
later get some supervised data so again
this decoder network could be pretty

526
00:38:26,340 --> 00:38:30,050
complicated when auto in quarters so
first came about

527
00:38:30,050 --> 00:38:33,720
oftentimes these were just simply either
a simple linear network or a small

528
00:38:33,719 --> 00:38:37,459
signal network but now they can be
deeply networks and often times these

529
00:38:37,460 --> 00:38:43,220
will be up convolutional is a good time
so it's Mason small inflatable slides so

530
00:38:43,219 --> 00:38:46,869
oftentimes this decoder nowadays will be
one of these up convolutional networks

531
00:38:46,869 --> 00:38:50,529
that takes your features that are again
are smaller in size than your input data

532
00:38:50,530 --> 00:38:56,880
and kind of blows it back up in size to
reproduce your original data and I'd

533
00:38:56,880 --> 00:39:00,579
like to make the point that these things
are actually pretty easy to train so the

534
00:39:00,579 --> 00:39:04,610
right here is a quick example that I
just cooked up in torch so this is for

535
00:39:04,610 --> 00:39:05,050
larry

536
00:39:05,050 --> 00:39:09,210
code which is accomplished all that work
for their decoder which is up

537
00:39:09,210 --> 00:39:12,420
convolutional network and you can see
that it's actually learns to reconstruct

538
00:39:12,420 --> 00:39:19,159
the data pretty well another thing that
you sometimes see is that these encoder

539
00:39:19,159 --> 00:39:23,799
and decoder networks will sometimes
share weights with just sort of as a

540
00:39:23,800 --> 00:39:27,740
regularization strategy and with this
intuition that these are opposite

541
00:39:27,739 --> 00:39:32,329
operations so maybe I might make sense
to try to use the same waits for both so

542
00:39:32,329 --> 00:39:36,659
just as a concrete example if you're in
if you think about a fully connected

543
00:39:36,659 --> 00:39:39,980
network then maybe your input data has
some dimension d

544
00:39:39,980 --> 00:39:44,070
and then you're late and data the will
have some smaller dimension H and if

545
00:39:44,070 --> 00:39:47,769
this encoder was just a fully connected
network then the weights will just be

546
00:39:47,769 --> 00:39:51,630
this matrix of Dubai age and now when we
want to do the decoding and try to

547
00:39:51,630 --> 00:39:54,470
reconstruct the original data than that

548
00:39:54,469 --> 00:39:59,129
mapping back from each back to D so we
can just reuse the same weights in these

549
00:39:59,130 --> 00:40:06,420
two areas we just take a transpose of a
matrix so when we're training this thing

550
00:40:06,420 --> 00:40:10,300
we need some kind of a loss function
that we can use to compare a

551
00:40:10,300 --> 00:40:15,400
reconstructed data with our original
data and then once and oftentimes will c

552
00:40:15,400 --> 00:40:20,220
L to a simple like hell to Euclidean
loss to train this thing so once we've

553
00:40:20,219 --> 00:40:24,659
chosen our internet work and once we've
chosen rd quarter network and function

554
00:40:24,659 --> 00:40:28,329
then we can train this thing just like
any other normal neural network where we

555
00:40:28,329 --> 00:40:32,420
get some data we pass it through to
encode it we passed through decoded the

556
00:40:32,420 --> 00:40:37,900
computer law sweetback propagate and
everything's good so once we train this

557
00:40:37,900 --> 00:40:41,880
thing then oftentimes will take this
decoder network that we spent so much

558
00:40:41,880 --> 00:40:46,700
time learning and I'll just throw it
away which seems kinda weird but the

559
00:40:46,699 --> 00:40:52,129
reason is that reconstruction on its own
is not such a useful task so instead we

560
00:40:52,130 --> 00:40:56,349
want to apply these networks to some
kind of actually useful task which is

561
00:40:56,349 --> 00:41:01,099
probably a supervised learning task so
here to set up is that we've learned

562
00:41:01,099 --> 00:41:05,179
this encoder network which hopefully
from all this unsupervised data has

563
00:41:05,179 --> 00:41:08,799
emerged to has learned to compress the
data and extract some useful features

564
00:41:08,800 --> 00:41:13,190
and then we're going to use this encoder
network to initialize part of a larger

565
00:41:13,190 --> 00:41:17,650
supervised work and now if we actually
do have access to maybe some smaller

566
00:41:17,650 --> 00:41:18,280
data set

567
00:41:18,280 --> 00:41:22,590
that have some labels then hopefully
this most of the work here could have

568
00:41:22,590 --> 00:41:26,309
been done by this unsupervised training
at the beginning and then we can just

569
00:41:26,309 --> 00:41:29,699
use that to initialize this this bigger
network and then fine tune the whole

570
00:41:29,699 --> 00:41:35,509
thing with hopefully a very small amount
of supervised data so this is kind of a

571
00:41:35,510 --> 00:41:39,380
dream of one of the dreams of
unsupervised feature learning that you

572
00:41:39,380 --> 00:41:43,410
have this really really large datasets
with no labels you can just go on Google

573
00:41:43,409 --> 00:41:46,409
and download images forever and it's
really easy to get a lot of images

574
00:41:46,969 --> 00:41:51,399
the problem is the labels are expensive
to collect so you'd want some system

575
00:41:51,400 --> 00:41:54,960
that could take advantage of both a
large huge amount of unsupervised data

576
00:41:54,960 --> 00:41:59,570
and also just a small amount of
supervised data so automakers are at

577
00:41:59,570 --> 00:42:03,940
least one thing that has been proposed
that has this night property but in

578
00:42:03,940 --> 00:42:07,670
practice I think it tends not to work
too well which is a little bit

579
00:42:07,670 --> 00:42:12,010
unfortunate because it's such a
beautiful idea another thing that I

580
00:42:12,010 --> 00:42:15,890
should point out almost as a side note
that if you go back and read the

581
00:42:15,889 --> 00:42:21,179
literature on these things from the mid
to thousands in the last 10 years than

582
00:42:21,179 --> 00:42:25,129
people have this funny thing called
increase their wives pre-training that

583
00:42:25,130 --> 00:42:30,010
they used for training auto encoders and
share the idea was that at the time in

584
00:42:30,010 --> 00:42:35,410
2006 training very deep networks was was
challenging and if you you can find

585
00:42:35,409 --> 00:42:39,429
quotes and papers like this that say
that even when you have maybe 45 hidden

586
00:42:39,429 --> 00:42:44,359
layers it was extremely challenging per
pupil in those days to train networks so

587
00:42:44,360 --> 00:42:48,760
it to get around that problem with a
instead had this paradigm where they

588
00:42:48,760 --> 00:42:53,560
would try to train just one letter at a
time and they use this this thing but i

589
00:42:53,559 --> 00:42:57,139
dont wanna get too much into called the
Restricted Boltzmann machine which is a

590
00:42:57,139 --> 00:43:01,279
typographical model and they would use
these restricted Boltzmann Machines the

591
00:43:01,280 --> 00:43:05,880
kind of trainees to these little there's
one at a time so first we will have our

592
00:43:05,880 --> 00:43:12,070
input image may be sized up of size W
one and this would be maybe something

593
00:43:12,070 --> 00:43:16,630
like PCA or some other kind of pics
transform and then we would hopefully

594
00:43:16,630 --> 00:43:19,990
learn using a restricted Boltzmann
machine some kind of relationship

595
00:43:19,989 --> 00:43:25,359
between those first their features and
some higher level features when once we

596
00:43:25,360 --> 00:43:27,940
once we learned this layer within reason

597
00:43:27,940 --> 00:43:30,840
and learn another restricted Boltzmann
machine on top of those features

598
00:43:30,840 --> 00:43:36,000
connecting it to the next level features
so by using this type of approach it let

599
00:43:36,000 --> 00:43:40,050
them train just one layer at a time in
this sort of greedy way and that let

600
00:43:40,050 --> 00:43:43,980
them hopefully find a really good
initialization for this larger network

601
00:43:43,980 --> 00:43:48,369
so after this greedy pre-training stage
they would stick the whole thing

602
00:43:48,369 --> 00:43:52,099
together into this giant audio encoder
and then fine tune the audio encoder

603
00:43:52,099 --> 00:44:00,469
jointly so nowadays we don't really need
to do this with things like ray Liu and

604
00:44:00,469 --> 00:44:04,139
proper initialization and bash
normalization and slightly fancier

605
00:44:04,139 --> 00:44:08,730
fancier optimizers this type of thing is
not really necessary anymore so as an

606
00:44:08,730 --> 00:44:12,659
example on the previous slide we saw
this for Larry convolutional

607
00:44:12,659 --> 00:44:16,409
deconvolution audio encoder that I
trained on ceasefire and this is just

608
00:44:16,409 --> 00:44:17,429
trying to do

609
00:44:17,429 --> 00:44:20,149
using all these modern neural network
techniques you don't have to mess around

610
00:44:20,150 --> 00:44:25,039
with US Airways training so this is not
something that really gets done anymore

611
00:44:25,039 --> 00:44:27,800
but I thought we should at least
mentioned it since you're probably

612
00:44:27,800 --> 00:44:35,990
encounter this idea if you read back in
the literature about these things so the

613
00:44:35,989 --> 00:44:39,949
basic idea or an auto in quarters is I
think pretty simple it's this beautiful

614
00:44:39,949 --> 00:44:44,009
idea where we can just use a lot of
unsupervised data to hopefully learn

615
00:44:44,010 --> 00:44:49,710
some nice features unfortunately that
doesn't work but that's ok but there's

616
00:44:49,710 --> 00:44:53,639
maybe some other nice type of task we
would want to do with unsupervised data

617
00:44:53,639 --> 00:44:56,639
question first

618
00:44:59,068 --> 00:45:10,308
yesterday the question is what what's
going on here right so this is this is

619
00:45:10,309 --> 00:45:14,880
this is maybe you could think about a
three-layer neural network so our input

620
00:45:14,880 --> 00:45:18,410
is gonna be the same as the output so
we're just hoping that this is a neural

621
00:45:18,409 --> 00:45:22,788
network that will learn the identity
function but that's a really and in

622
00:45:22,789 --> 00:45:26,099
order to learn the identity function we
have some loss function at the end

623
00:45:26,099 --> 00:45:29,989
something like an adult who lost that is
encouraging our to our input and output

624
00:45:29,989 --> 00:45:35,429
to be the same and learning identity
function is probably really easy thing

625
00:45:35,429 --> 00:45:39,379
to do but instead we're going to force
the network to not take the easy route

626
00:45:39,380 --> 00:45:43,410
and instead hopefully rather than just
regurgitating the data and learning the

627
00:45:43,409 --> 00:45:46,909
identity function in the easy way
instead we're gonna bottlenecks

628
00:45:46,909 --> 00:45:51,268
representation through this hidden layer
in the middle so then it's gonna learn

629
00:45:51,268 --> 00:45:54,798
the identity function but in the middle
of the network is gonna have to squeeze

630
00:45:54,798 --> 00:45:59,829
down and summarize and compress the data
and hopefully that that compression will

631
00:45:59,829 --> 00:46:04,339
give rise to features that are useful
for other tasks as that may be a little

632
00:46:04,338 --> 00:46:14,719
bit more care ok questioned the claim
was that PCA is just the answer for this

633
00:46:14,719 --> 00:46:19,259
problem so it's true that PCA is optimal
in certain senses if you're only allowed

634
00:46:19,259 --> 00:46:25,278
to do one where a wonder if your income
and your decoder are just a single

635
00:46:25,278 --> 00:46:30,259
linear transform then indeed PCA of
optimal in some sense but if you're in

636
00:46:30,259 --> 00:46:34,170
quarter and decoder are potentially
larger more complicated functions that

637
00:46:34,170 --> 00:46:39,059
are more maybe multi-layer neural
networks then then maybe PCA is no

638
00:46:39,059 --> 00:46:43,209
longer the right solution another point
to make is that PCA is only optimal in

639
00:46:43,208 --> 00:46:44,308
certain senses

640
00:46:44,309 --> 00:46:48,670
particularly talking about LG
reconstruction but in practice we don't

641
00:46:48,670 --> 00:46:51,798
actually care about reconstruction we're
just hoping that this thing will learn

642
00:46:51,798 --> 00:46:56,538
useful features for other tasks so in
practice and will see this a bit later

643
00:46:56,539 --> 00:47:00,259
that people don't always use out to
anymore because I'll to is maybe not

644
00:47:00,259 --> 00:47:04,719
quite the right loss for actually
features yeah

645
00:47:04,719 --> 00:47:14,348
the army on larry is this is is this
kind of generative model of the data of

646
00:47:14,349 --> 00:47:18,250
data where you imagine that you have
sort of two sequences of bets and you

647
00:47:18,250 --> 00:47:19,108
want to do this

648
00:47:19,108 --> 00:47:23,579
generative modeling of the of the two
things so then you need to get into

649
00:47:23,579 --> 00:47:26,440
quite a lot of reasons that this text to
figure out exactly what a loss function

650
00:47:26,440 --> 00:47:31,260
is but it ends up being something like
what likelihood of the data with these

651
00:47:31,260 --> 00:47:35,470
latent state that you don't observe and
that's actually a cool idea that we will

652
00:47:35,469 --> 00:47:40,868
sort of revisit in the variational audio
encoder so one of the one of the

653
00:47:40,869 --> 00:47:45,280
problems with this traditional audio
encoder is that it's hoping to learn

654
00:47:45,280 --> 00:47:49,590
features that's that's a cool thing but
there's this other thing that we would

655
00:47:49,590 --> 00:47:54,670
like to not just learned features but
also be able to generate new data a cool

656
00:47:54,670 --> 00:47:59,320
task that we could potentially learned
from unsupervised data is that hopefully

657
00:47:59,320 --> 00:48:03,030
our model could slurp and a bunch of
images and after it does that it sort of

658
00:48:03,030 --> 00:48:06,990
learns what natural images look like and
then after its learn this distribution

659
00:48:06,989 --> 00:48:11,449
then it could hopefully spit out sort of
fake images that look like the original

660
00:48:11,449 --> 00:48:17,949
images but are fake and this is maybe
not address a task which is directly

661
00:48:17,949 --> 00:48:22,319
applicable to things like classification
but it seems like an important thing for

662
00:48:22,320 --> 00:48:26,588
a guy that humans are pretty good at
looking at data and summarizing it and

663
00:48:26,588 --> 00:48:31,199
getting the idea of what it looks like
so hopefully if our models could also do

664
00:48:31,199 --> 00:48:34,969
this sort of task then hopefully they'll
have learned some some useful

665
00:48:34,969 --> 00:48:41,299
summarization or some useful statistics
of the data so the variation audio

666
00:48:41,300 --> 00:48:45,539
encoder is this kind of neat twist on
the original order that lets us

667
00:48:45,539 --> 00:48:50,690
hopefully actually generate novel images
from our learns data so here we need to

668
00:48:50,690 --> 00:48:54,849
dive into a little bit of patience that
this tax so this is something that we

669
00:48:54,849 --> 00:48:58,320
haven't really talked about at all in
this class anymore but up to this point

670
00:48:58,320 --> 00:49:02,420
but there's this whole other side of
machine learning that doesn't do near

671
00:49:02,420 --> 00:49:05,250
networks and deep learning but things
really hard about probability

672
00:49:05,250 --> 00:49:09,260
distributions and how bility
distributions can fit together to

673
00:49:09,260 --> 00:49:13,190
generate data sets and then reason
probabilistically about your data and

674
00:49:13,190 --> 00:49:16,670
this type of paradigm is really nice
because it lets you sort of State

675
00:49:16,670 --> 00:49:17,970
explicit probabilistic

676
00:49:17,969 --> 00:49:22,000
assumptions about how you think your
data was generated and then given those

677
00:49:22,000 --> 00:49:25,858
probabilistic assumptions you try to
figure model to the data that follows

678
00:49:25,858 --> 00:49:30,199
your assumptions so what the variation
alarming quarter we're assuming this

679
00:49:30,199 --> 00:49:35,589
this particular type of method by which
our data was generated so we assume that

680
00:49:35,590 --> 00:49:39,800
we've barely exists out there in the
world some prior distribution which is

681
00:49:39,800 --> 00:49:44,440
generating these latent States Z and
we've been we assume some conditional

682
00:49:44,440 --> 00:49:49,789
distribution that once we have the
leading states we can generate samples

683
00:49:49,789 --> 00:49:54,389
from some other distribution to generate
the data so the variation audio encoder

684
00:49:54,389 --> 00:49:58,170
it really imagine that our data was
generated by this pretty simple process

685
00:49:58,170 --> 00:50:03,639
that first we sample from some prior
distribution to get some to get raz B

686
00:50:03,639 --> 00:50:10,940
sample from this conditional to get our
acts so the intuition is that acts as

687
00:50:10,940 --> 00:50:15,240
something like an image and Z maybe
summarizes some useful stuff about that

688
00:50:15,239 --> 00:50:19,649
image so if these were see far images
then maybe that lay in state she could

689
00:50:19,650 --> 00:50:23,800
be something like the class of the image
whether it's a frog or a deer or cat and

690
00:50:23,800 --> 00:50:27,690
also might contain variables about how
that cat is oriented or what color it is

691
00:50:27,690 --> 00:50:29,269
or something like that

692
00:50:29,269 --> 00:50:33,719
so this is kind of a nice sort of having
a pretty simple some pretty simple idea

693
00:50:33,719 --> 00:50:37,279
but makes a lot of sense for how you
might imagine image images to be

694
00:50:37,280 --> 00:50:43,670
generated so the problem now is that we
want to ask to meet these parameters

695
00:50:43,670 --> 00:50:48,470
data of both the prior and the
conditional without actually having

696
00:50:48,469 --> 00:50:52,598
access to these latest dates and see and
that's that's the that's a challenging

697
00:50:52,599 --> 00:50:57,588
problem so to make a simple we're gonna
do something that you see a lot in

698
00:50:57,588 --> 00:51:00,769
Bayesian statistics and I'll just assume
that the priors got a shampoo that's

699
00:51:00,769 --> 00:51:07,088
easy to handle and the conditional be a
will also be shown but it's gonna be a

700
00:51:07,088 --> 00:51:11,489
little bit fancier so we'll assume that
it's a Gaussian with diagonal mean and

701
00:51:11,489 --> 00:51:16,729
unit with sorry diagonal covariance and
some mean but instead we're just gonna

702
00:51:16,730 --> 00:51:19,650
put but the way that we're going to get
those is we're going to compute them

703
00:51:19,650 --> 00:51:24,800
with a neural network so it suppose that
we had the latest agency for some piece

704
00:51:24,800 --> 00:51:27,579
of data that we assume that that late
instead

705
00:51:27,579 --> 00:51:32,160
will go into some decoder network which
could be some big complicated neural

706
00:51:32,159 --> 00:51:36,078
network and now that neural network is
gonna spit out two things it's gonna

707
00:51:36,079 --> 00:51:40,079
spit out the meaning of the data it's
gonna spit out the meaning of the data

708
00:51:40,079 --> 00:51:45,068
acts and also the the the variance of
the data acts so you should think that

709
00:51:45,068 --> 00:51:48,958
this looks very much like the top half
of a normal audio encoder that we have

710
00:51:48,958 --> 00:51:52,699
this link state we have some known that
that's operating on the latest eight but

711
00:51:52,699 --> 00:51:57,588
now instead of just directly spitting
out the data instead it's spitting out

712
00:51:57,588 --> 00:52:01,690
the mean of the data and the variance of
the data but other than that this looks

713
00:52:01,690 --> 00:52:07,528
very much like the decoder of the normal
audio encoder so this this decoder

714
00:52:07,528 --> 00:52:11,518
network sort of thinking back to the
normal audio encoder might be a simple

715
00:52:11,518 --> 00:52:14,578
fully connected thing or it might be
this very big powerful deconvolution

716
00:52:14,579 --> 00:52:22,269
network and both of those are pretty
common so now the problem is that by

717
00:52:22,268 --> 00:52:26,679
baseball if given the prior and given
the conditional basil tells us the

718
00:52:26,679 --> 00:52:31,578
posterior that given so if we want to
actually use this model we need to be

719
00:52:31,579 --> 00:52:35,209
able to estimate the latent state from
the input data and the way that we

720
00:52:35,208 --> 00:52:38,659
estimate the leading state from the
input data is by writing down this

721
00:52:38,659 --> 00:52:42,899
posterior distribution which is the
probability of the latest easy given are

722
00:52:42,900 --> 00:52:47,519
observed data and using payroll we can
easily flip this around and write it in

723
00:52:47,518 --> 00:52:54,189
terms of our prior oversee and in terms
of our conditional Givenchy and so we

724
00:52:54,190 --> 00:52:57,249
can use by Israel to actually put this
thing around and write it in terms of

725
00:52:57,248 --> 00:53:02,409
these three things so after we look at
these roles we can break down these

726
00:53:02,409 --> 00:53:06,818
three terms and we can see that the
conditional we just use our decoder

727
00:53:06,818 --> 00:53:11,558
network and we easily have access to
that and this prior again we have access

728
00:53:11,559 --> 00:53:15,569
to the prior to be assumed that you
negotiate so that's easy to handle but

729
00:53:15,568 --> 00:53:19,458
this denominator this probability of
acts it turns out if you if you work out

730
00:53:19,458 --> 00:53:22,828
the math and write it out this ends up
being this giant intractable in a row

731
00:53:22,829 --> 00:53:26,579
over the entire leading state space so
that's completely intractable there's no

732
00:53:26,579 --> 00:53:29,479
way you could ever porn that in a girl
and even approximating it would be a

733
00:53:29,478 --> 00:53:33,399
giant disaster so instead we will not
even trying to evaluate that in a girl

734
00:53:33,400 --> 00:53:38,759
instead we're going to introduce some
encoder network that will try to

735
00:53:38,759 --> 00:53:40,179
directly before

736
00:53:40,179 --> 00:53:45,210
in print stuff for us so this encoder
network is going to take in a data point

737
00:53:45,210 --> 00:53:48,599
and it's going to spit out a
distribution over the meeting state

738
00:53:48,599 --> 00:53:53,210
space so again this looks very much
looking back at the original audio

739
00:53:53,210 --> 00:53:57,449
encoder from a few slides ago this looks
very much the same as sort of the bottom

740
00:53:57,449 --> 00:54:01,449
half of a traditional audio encoder
where we're taking in data and now

741
00:54:01,449 --> 00:54:04,789
instead of directly spitting out the
latest eight we're gonna spit out a mean

742
00:54:04,789 --> 00:54:09,519
and variance of the leading state and
again this quarter network might be

743
00:54:09,519 --> 00:54:13,639
something might be somewhat
controversial network or maybe some deep

744
00:54:13,639 --> 00:54:21,159
convolutional network so sort of the
intuition is that this encounter network

745
00:54:21,159 --> 00:54:25,259
will be the separate totally different
destroying function but we're going to

746
00:54:25,260 --> 00:54:29,180
try to train it in a way that it
approximates this posterior distribution

747
00:54:29,179 --> 00:54:35,799
that we don't actually have access to
and so when we probably pieces together

748
00:54:35,800 --> 00:54:40,700
then then we can set up a stitch this
all together and get give rise to this

749
00:54:40,699 --> 00:54:44,808
variation audio encoder so once we put
these things together then we have this

750
00:54:44,809 --> 00:54:49,559
input data point X we're gonna pass it
through our encoder network and the

751
00:54:49,559 --> 00:54:52,819
encoder network will spit out a
distribution over the leading states

752
00:54:52,818 --> 00:54:57,789
once we have this this distribution over
the latest dates you can imagine you

753
00:54:57,789 --> 00:55:01,650
could imagine sampling from that
distribution to get some some highest

754
00:55:01,650 --> 00:55:07,700
let me state of high probability for
that input than once we have been once

755
00:55:07,699 --> 00:55:11,889
we have some concrete example of a
latent state then we can pass it through

756
00:55:11,889 --> 00:55:16,409
this decoder network which will spread
out the probability of which should then

757
00:55:16,409 --> 00:55:20,469
sped out the probability of the data
again and then once we have this

758
00:55:20,469 --> 00:55:24,439
distribution over the data we could
sample from it to actually get something

759
00:55:24,440 --> 00:55:29,950
that hopefully looks like the original
data point so this this ends up looking

760
00:55:29,949 --> 00:55:34,269
very much like a normal audio encoder
where we're taking our input data we're

761
00:55:34,269 --> 00:55:37,829
running it through this encoder to get
some latent state or passing into this

762
00:55:37,829 --> 00:55:42,200
decoder totally reconstruct the original
data and when you go about training this

763
00:55:42,199 --> 00:55:46,149
thing it's actually trained in a very
similar method as normal audio encoder

764
00:55:46,150 --> 00:55:50,230
we have this for past and this backward
pass the only difference is in the loss

765
00:55:50,230 --> 00:55:55,490
function so at the top we have this
reconstruction loss rather than being

766
00:55:55,489 --> 00:56:01,078
displayed by sl2 instead we want this
distribution to be close to the true

767
00:56:01,079 --> 00:56:07,349
input data and we also have this lost
term coming in the middle that we want

768
00:56:07,349 --> 00:56:11,230
this generated distribution over the
Layton States hopefully be very similar

769
00:56:11,230 --> 00:56:16,579
to our stated prior distribution that we
wrote down at the very beginning so once

770
00:56:16,579 --> 00:56:19,200
you put these pieces together you can
just trying this thing like a normal

771
00:56:19,199 --> 00:56:22,969
audio encoder with normal forward
forward forward pass and backward pass

772
00:56:22,969 --> 00:56:29,058
the only difference is where you put the
loss and how you interpret the loss so

773
00:56:29,059 --> 00:56:32,500
any any questions about the setup it's
kind of a when we went through a kind of

774
00:56:32,500 --> 00:56:39,608
ass yeah question is why do you choose a
diagonal covariance and answers cuz it's

775
00:56:39,608 --> 00:56:44,199
really easy to work with theirs but
actually people have tried I think

776
00:56:44,199 --> 00:56:50,210
slightly fancier things too but that's
something you can play around with ok so

777
00:56:50,210 --> 00:56:53,530
once we've actually trained this once
we've actually trained this kind of

778
00:56:53,530 --> 00:56:56,920
variational audio encoder we can
actually use it to generate new data

779
00:56:56,920 --> 00:57:00,510
that looks kind of like original dataset
so here

780
00:57:00,510 --> 00:57:04,430
the idea is that remember we wrote down
this prior that might be a you negotiate

781
00:57:04,429 --> 00:57:07,960
or maybe something a little bit fancier
but at any rate this prior is something

782
00:57:07,960 --> 00:57:12,039
some distribution that we can easily
sample from so you negotiate it's very

783
00:57:12,039 --> 00:57:15,989
easy to draw random samples from that
distribution so to generate new data

784
00:57:15,989 --> 00:57:20,459
will start by just sort of following
this data this data generation process

785
00:57:20,460 --> 00:57:24,849
that we had imagined data so first we'll
sample from our from our prior

786
00:57:24,849 --> 00:57:28,430
distribution over the lake in states and
then we'll pass it through our decoder

787
00:57:28,429 --> 00:57:32,078
network that we have learned during
training and this decoder network will

788
00:57:32,079 --> 00:57:36,190
now spit out a distribution override and
appoints in the turn in in terms of both

789
00:57:36,190 --> 00:57:40,460
I mean and covariance and once we have a
mean and covariance this is just a

790
00:57:40,460 --> 00:57:44,548
diagonal gosh we can easily sample from
this thing again to generate some data

791
00:57:44,548 --> 00:57:50,369
point so now 11 you train this thing
then another thing you can do is sort of

792
00:57:50,369 --> 00:57:54,440
can out the latent space and I'm at and
rather than sampling from a latent

793
00:57:54,440 --> 00:57:58,490
distribution instead you just densely
sample of allegiance from the latest

794
00:57:58,489 --> 00:58:01,979
base to kind of get an idea of what type
of structure structure the network had

795
00:58:01,980 --> 00:58:09,280
learned so this is doing exactly that on
this dataset so here we we trained this

796
00:58:09,280 --> 00:58:12,990
variation audio encoder with where is
the latest eight is just a

797
00:58:12,989 --> 00:58:17,959
two-dimensional thing and now we can
actually scan out this late in space we

798
00:58:17,960 --> 00:58:22,490
can explore densely this two-dimensional
late in space and for each point in the

799
00:58:22,489 --> 00:58:26,519
latent space passes through the decoder
and use it to generate some image you

800
00:58:26,519 --> 00:58:30,599
can see that it's actually discovered
this beautiful structure it's that sort

801
00:58:30,599 --> 00:58:34,618
of smoothly interpolates between the
different digit classes so I'll be up

802
00:58:34,619 --> 00:58:38,530
here at the left you see six is the kind
of morph into zeros as you go down you

803
00:58:38,530 --> 00:58:42,690
see six is that turned into seven into
BB nines and Southern's the aids are

804
00:58:42,690 --> 00:58:46,159
hanging out in the middle somewhere in
the ones are down here so this latent

805
00:58:46,159 --> 00:58:50,049
space actually learned this beautiful
disentanglement of the data in this very

806
00:58:50,050 --> 00:58:55,910
nice unsupervised way we can also turn
this thing on our faces dataset and it's

807
00:58:55,909 --> 00:58:59,199
the same sort of story where we're just
training this two-dimensional variation

808
00:58:59,199 --> 00:59:02,679
audio encoder and then once we train it
we densely sampled from that late in

809
00:59:02,679 --> 00:59:05,679
space to try to see what he has learned
western

810
00:59:13,018 --> 00:59:19,458
yeah so the question is whether people
ever try to force the least specifically

811
00:59:19,458 --> 00:59:23,139
variables to have some some some exact
meaning and yeah there has been some

812
00:59:23,139 --> 00:59:27,058
follow-up work that does exactly that
there is a paper called deep inverse

813
00:59:27,059 --> 00:59:31,890
graphics networks from MIT that has that
does exactly this setup where they try

814
00:59:31,889 --> 00:59:36,199
to force where they want to learn sort
of a renderer in as a neural network so

815
00:59:36,199 --> 00:59:41,568
they want to learn to like render 3d
images of things they want to force some

816
00:59:41,568 --> 00:59:44,619
of the latent space some of the
variables in the latent space to

817
00:59:44,619 --> 00:59:49,289
corresponds to the the 3d angles of the
object and maybe the class and the

818
00:59:49,289 --> 00:59:53,009
repose of the object and the rest of
them it led to learn from whatever it

819
00:59:53,009 --> 00:59:56,099
wants and that she has some cool
experiments were now they can do exactly

820
00:59:56,099 --> 01:00:00,809
as you said and by setting those those
specific values the latent variables

821
01:00:00,809 --> 01:00:03,869
that can render and actually rotate the
object and those are those are pretty

822
01:00:03,869 --> 01:00:09,390
cool but that's that's that's a lot of
fancier than these spaces but these

823
01:00:09,389 --> 01:00:11,908
faces are still pretty cool you can see
it sort of interpolating between

824
01:00:11,909 --> 01:00:16,689
different phases in this very nice way
and I think that there's actually a very

825
01:00:16,688 --> 01:00:21,759
nice motivation here and one of the
reasons we pick a diagonal tension is

826
01:00:21,759 --> 01:00:26,079
that that has the probabilistic
interpretation of having independent but

827
01:00:26,079 --> 01:00:29,179
that the very different variables in our
living space

828
01:00:29,179 --> 01:00:33,918
actually should be independent so I
think that helps to explain why there

829
01:00:33,918 --> 01:00:37,219
actually is this very nice separation
between the accys when you end up

830
01:00:37,219 --> 01:00:40,858
sampling from the lead in space is due
to this probabilistic independence

831
01:00:40,858 --> 01:00:45,630
assumption embedded in a prior so this
idea prior to this very powerful and

832
01:00:45,630 --> 01:00:51,139
lets you sort of big those types of
things directly into a model so I I

833
01:00:51,139 --> 01:00:54,028
wrote down a bunch of math and I don't
think we really have time to go through

834
01:00:54,028 --> 01:00:57,849
it but the idea is that sort of
classically when you're training

835
01:00:57,849 --> 01:01:01,130
generative models there's this thing
called maximum likelihood where you want

836
01:01:01,130 --> 01:01:04,608
to maximize the likelihood of your data
under the model and then pick the model

837
01:01:04,608 --> 01:01:09,018
where that makes your data most likely
but it turns out that if you just try to

838
01:01:09,018 --> 01:01:13,068
run maximum-likelihood using a normal
using this generative process that we

839
01:01:13,068 --> 01:01:17,708
had imagined for the very issues older
than you run into this giant you end up

840
01:01:17,708 --> 01:01:21,009
needing to marginalize this joint
distribution which becomes this giant

841
01:01:21,009 --> 01:01:24,289
intractable in a girl over the entire
meeting state space that's not something

842
01:01:24,289 --> 01:01:25,890
that we can do

843
01:01:25,889 --> 01:01:29,659
so instead the various audio encoder
encoder does this thing called a

844
01:01:29,659 --> 01:01:34,259
variational inference which is a pretty
cool idea and the math is here in case

845
01:01:34,260 --> 01:01:38,150
you want to go through it but the idea
is that instead of maximizing along

846
01:01:38,150 --> 01:01:42,619
probability of the data work on a
cleverly insert this extra content and

847
01:01:42,619 --> 01:01:47,429
break it up into these two different
terms so we're right this is an exact

848
01:01:47,429 --> 01:01:50,419
equivalents that you can maybe work
there on your own but this log

849
01:01:50,420 --> 01:01:54,710
likelihood we can write in terms of this
term that we call an elbow and this

850
01:01:54,710 --> 01:01:58,869
other term which is a Cal divergence
between two distributions and we know

851
01:01:58,869 --> 01:02:03,029
that killed two virgins is always zero
so we know that killed two virgins

852
01:02:03,030 --> 01:02:07,120
between distributions is non-zero so we
know that this term has to be non-zero

853
01:02:07,119 --> 01:02:12,420
which means that this this elbow term
actually is a lower bound on the log

854
01:02:12,420 --> 01:02:16,480
likelihood of our data and notice that
in the process of writing down this

855
01:02:16,480 --> 01:02:20,889
elbow we introduce this additional
parameter feed that we can interpret as

856
01:02:20,889 --> 01:02:25,710
the parameters of this this encoder
network that is sort of approximating

857
01:02:25,710 --> 01:02:30,909
this hard posterior distribution so now
instead of trying to directly maximize

858
01:02:30,909 --> 01:02:34,319
the log likelihood of our data instead
will try to maximize this very issue

859
01:02:34,320 --> 01:02:39,539
lower bound of the data and because the
elbow is as a lower bound of the log

860
01:02:39,539 --> 01:02:43,769
likelihood then maximizing the elbow
will also have the effect of raising up

861
01:02:43,769 --> 01:02:49,059
the log likelihood and stuff and these
these two terms of the elbow actually of

862
01:02:49,059 --> 01:02:53,360
this beautiful interpretation that this
one at the at the front is the

863
01:02:53,360 --> 01:02:57,849
expectation over the Layton States be
over the latent state space of the

864
01:02:57,849 --> 01:03:01,889
probability of X given the latent state
space so you think about that that's

865
01:03:01,889 --> 01:03:05,559
actually a data reconstruction term
that's saying that if we averaged over

866
01:03:05,559 --> 01:03:08,789
all possible eighteen states that we
should end up with something that is

867
01:03:08,789 --> 01:03:13,639
similar to our original data and this is
at this this other term is actually a

868
01:03:13,639 --> 01:03:17,940
regularization term this is the Cal
divergence between are approximate

869
01:03:17,940 --> 01:03:22,059
posterior and between the prior so this
is a regularization of trying to force

870
01:03:22,059 --> 01:03:27,019
those two things together so impact this
this this first term you can approximate

871
01:03:27,019 --> 01:03:31,590
with something called the approximate by
sampling using this trick in the paper

872
01:03:31,590 --> 01:03:35,600
that I won't get into and this other
term again because everything is going

873
01:03:35,599 --> 01:03:38,489
on here you can just about the skilled
emergence explicitly

874
01:03:38,489 --> 01:03:44,509
so I think this is the most map every
slide in the class so that's that's kind

875
01:03:44,510 --> 01:03:50,020
of fun but actually it's so but it's
actually scary but it's actually just

876
01:03:50,019 --> 01:03:54,150
exactly just this one quarter idea we
have a reconstruction and then you have

877
01:03:54,150 --> 01:03:59,050
this penalty penalizing to you to go
backwards the prior to any any questions

878
01:03:59,050 --> 01:04:08,840
on the various quarters as that in
general the idea of an audio encoder is

879
01:04:08,840 --> 01:04:12,180
that we want to force a network to try
to reconstruct our data and hopefully

880
01:04:12,179 --> 01:04:16,089
this will learn sort of useful
representations of the data for Trisha

881
01:04:16,090 --> 01:04:19,470
lot of encoders this is used for Peter
learning but once we move to variation

882
01:04:19,469 --> 01:04:23,569
in quarters we make this thing patients
so we can actually generate samples that

883
01:04:23,570 --> 01:04:29,440
are similar to our data so then this
idea of generating samples from my data

884
01:04:29,440 --> 01:04:32,690
is really cool and everyone loves
looking at these kinds of pictures so

885
01:04:32,690 --> 01:04:37,119
there's another idea that maybe can we
generate really cool samples without all

886
01:04:37,119 --> 01:04:41,100
this scary Bayesian math and it turns
out that there's this idea called a

887
01:04:41,099 --> 01:04:45,219
generative adversarial network that is a
sort of different idea a different twist

888
01:04:45,219 --> 01:04:49,799
that lets you still generate samples
that look like your data but sort of a

889
01:04:49,800 --> 01:04:52,560
little bit more explicitly without
having to worry about divergences

890
01:04:52,559 --> 01:04:54,340
umpires and this sort of stuff

891
01:04:54,340 --> 01:04:58,920
the idea is that we're gonna have a
generator not work that well first we're

892
01:04:58,920 --> 01:05:02,780
gonna start with some random noise that
probably has drawn from you negotiate or

893
01:05:02,780 --> 01:05:07,060
something like that and then we're going
to have a generator network and this

894
01:05:07,059 --> 01:05:11,079
generator network actually looks very
much like the decoder in the variational

895
01:05:11,079 --> 01:05:15,849
audio encoder or like the second half of
a normal audio encoder in that we're

896
01:05:15,849 --> 01:05:20,449
taking this random noise and we're gonna
spend out an image that is going to be

897
01:05:20,449 --> 01:05:26,379
some fake not real image that we're just
generating using this train network then

898
01:05:26,380 --> 01:05:29,410
we're also going to hook up a
discriminator network that is going to

899
01:05:29,409 --> 01:05:32,679
look at this fake image and try to
decide whether it's whether or not that

900
01:05:32,679 --> 01:05:34,769
generated image is real or fake

901
01:05:34,769 --> 01:05:38,679
so this is this so the second network is
just doing this binary classification

902
01:05:38,679 --> 01:05:42,949
task where it receives an input and it
just needs to say whether or not it's

903
01:05:42,949 --> 01:05:46,739
it's true or it's whether or not it's
real image or not that's just sort of a

904
01:05:46,739 --> 01:05:49,739
classification task that you can hook up
like anything else

905
01:05:50,730 --> 01:05:55,349
so then we can train this thing called
all jointly altogether

906
01:05:55,960 --> 01:06:01,179
where r generator network will receive
many batches of random noise and I'll

907
01:06:01,179 --> 01:06:06,629
spit out and it'll take images and our
discriminator network will receive many

908
01:06:06,630 --> 01:06:12,640
batches of partially these images and
partially real images from a dataset and

909
01:06:12,639 --> 01:06:16,039
it will have to do it will try to make
this classification task to say which

910
01:06:16,039 --> 01:06:21,358
are real and which are fake and so this
is sort of now another way that we can

911
01:06:21,358 --> 01:06:25,880
hook up this kind of supervised learning
problem ish without any real data so we

912
01:06:25,880 --> 01:06:30,390
hope this thing up and we train the
hoping jointly so we can look at some

913
01:06:30,389 --> 01:06:34,730
examples from the original general
adversarial networks paper and so these

914
01:06:34,730 --> 01:06:38,840
are fake images that are generated by
the network announced you can see that

915
01:06:38,840 --> 01:06:41,829
it's done a very good job of actually
generating fake tits they look like real

916
01:06:41,829 --> 01:06:46,549
digits and here I'm here this this
middle column is showing actually the

917
01:06:46,550 --> 01:06:50,080
nearest neighbor in the training set of
those digits to hopefully let you know

918
01:06:50,079 --> 01:06:53,599
that it doesn't just memorize the
training set so for example this too has

919
01:06:53,599 --> 01:06:57,389
a little dot and then this guy doesn't
have a dot so it's not just memorizing

920
01:06:57,389 --> 01:07:01,079
training data and it also does a pretty
good job of recognizing pace

921
01:07:01,079 --> 01:07:05,849
generating faces so but you know as
people who worked in machine learning

922
01:07:05,849 --> 01:07:10,440
known these these digits and paste data
sets tend to be pretty easy to generate

923
01:07:10,440 --> 01:07:16,869
samples from and when we apply this this
task to see far than RJR samples don't

924
01:07:16,869 --> 01:07:21,840
quite look as nice and clean so here
it's clearly got some idea about CPR

925
01:07:21,840 --> 01:07:25,108
data worth making blue stock and green
stuff but they don't really look like

926
01:07:25,108 --> 01:07:32,429
real objects so that's that's a problem
so it's a follow-up work actually tried

927
01:07:32,429 --> 01:07:35,599
some follow-up work on generative
adversarial networks has tried to make

928
01:07:35,599 --> 01:07:38,529
these architectures bigger and more
powerful so hopefully be able to

929
01:07:38,530 --> 01:07:44,080
generate better samples on these more
complex datasets so one idea is this

930
01:07:44,079 --> 01:07:48,949
idea is multiscale processing so rather
than generating the image all at once

931
01:07:48,949 --> 01:07:53,919
we're actually gonna generate our image
at multiple scales in this way so first

932
01:07:53,920 --> 01:07:58,170
we're gonna happen generator that feeds
in bed receives noise and then generates

933
01:07:58,170 --> 01:08:03,670
a low resolution and then we'll up
sample that nora skyy and apply a second

934
01:08:03,670 --> 01:08:04,200
generator

935
01:08:04,199 --> 01:08:08,230
ur that receives a new batch of random
noise and compute some Delta on top of

936
01:08:08,230 --> 01:08:12,070
the low res image then what up sample
that again and repeat the process

937
01:08:12,070 --> 01:08:16,810
several times until we've actually
finally generated are generated our

938
01:08:16,810 --> 01:08:22,219
final result so this is again a very
similar ideas the previous as the

939
01:08:22,219 --> 01:08:25,329
original gender diverse area network or
just generating at multiple scales

940
01:08:25,329 --> 01:08:30,199
simultaneously and the training here is
a little bit more complex you actually a

941
01:08:30,199 --> 01:08:35,710
discriminator at each scale and that
hopefully hopefully there's something so

942
01:08:35,710 --> 01:08:39,039
when we look at the train samples from
this guy actually a lot better so here

943
01:08:39,039 --> 01:08:43,869
are actually trained a separate model
per class on C 510 so here they've

944
01:08:43,869 --> 01:08:48,599
trained this adversarial network on just
one just planes from CPR and you can see

945
01:08:48,600 --> 01:08:51,460
that they're starting to look like real
planes so that's that's getting

946
01:08:51,460 --> 01:08:52,210
somewhere

947
01:08:52,210 --> 01:08:56,689
these look almost like real quarters and
these may be looked kinda like real

948
01:08:56,689 --> 01:09:04,278
birds so in in the following year people
actually threw away this multiscale idea

949
01:09:04,279 --> 01:09:09,339
and just used a simple are better more
principled continent so here is the idea

950
01:09:09,338 --> 01:09:14,318
is forget about this multi skilled staff
and just use use batch norm don't use

951
01:09:14,319 --> 01:09:17,739
fully connected layers sort of all these
architectural constraints that we've had

952
01:09:17,738 --> 01:09:22,759
become practice practice and last couple
years just use those and turns out that

953
01:09:22,759 --> 01:09:27,969
your adversary in that span work really
well so here they're generator is this

954
01:09:27,969 --> 01:09:33,088
pretty pretty simple pretty simple
pretty small convolutional network and

955
01:09:33,088 --> 01:09:38,539
the discriminator is again just a simple
network with nationalization and all

956
01:09:38,539 --> 01:09:42,180
these other bells and whistles and once
you hook up this thing they get some

957
01:09:42,180 --> 01:09:47,810
amazing samples in this paper so these
are generated bedrooms from the network

958
01:09:47,810 --> 01:09:53,450
so these actually are pretty impressive
results these look like real data almost

959
01:09:53,449 --> 01:09:57,529
so you can see that it's done a really
good job of capturing

960
01:09:57,529 --> 01:10:00,920
really detailed structure about bedrooms
like there's a bad there's a window

961
01:10:00,920 --> 01:10:07,710
there's a light switch so these are
these are really amazing samples but it

962
01:10:07,710 --> 01:10:12,579
turns out that rather than just
generating samples we can play the same

963
01:10:12,579 --> 01:10:16,260
trick as the very issue lot of encoder
and actually try to exploit try to play

964
01:10:16,260 --> 01:10:16,670
around

965
01:10:16,670 --> 01:10:21,739
meeting space because this cuz these
adversarial networks are receiving this

966
01:10:21,738 --> 01:10:25,579
noise input and we can cleverly try to
move around that noise and put it and

967
01:10:25,579 --> 01:10:29,920
try to change the type of things that
these networks generate so one example

968
01:10:29,920 --> 01:10:36,050
that we can try is interpolating between
bedrooms so here on the left hip so here

969
01:10:36,050 --> 01:10:40,119
the idea is that on the left for these
images on the left hand side we've drawn

970
01:10:40,119 --> 01:10:43,550
a random point from our noise
distribution and then use it to generate

971
01:10:43,550 --> 01:10:47,690
an image and now on the right hand side
we've done the same and we generate

972
01:10:47,689 --> 01:10:51,259
another random point from our noise
distribution and use it to generate an

973
01:10:51,260 --> 01:10:57,710
image so now these these two guys on the
opposite sides are generated are sort of

974
01:10:57,710 --> 01:11:01,760
two points on a line and I we want to
interpolate in the lead in space between

975
01:11:01,760 --> 01:11:08,210
those two lead actors and along that
line we're gonna generate used the use

976
01:11:08,210 --> 01:11:11,859
the generator to generate images and
hopefully this will interpolate between

977
01:11:11,859 --> 01:11:16,439
the latest dates of those two guys and
you can see that this is pretty crazy

978
01:11:16,439 --> 01:11:22,169
that these bedrooms are more fame sort
of in a very nice smooth continuous way

979
01:11:22,170 --> 01:11:28,020
from one bedroom to another and if you
one thing to point out is that this

980
01:11:28,020 --> 01:11:32,300
morning is actually happening in kind of
a nice romantic way if you imagine what

981
01:11:32,300 --> 01:11:35,460
this would look like and pixel space
than it would just be kind of this

982
01:11:35,460 --> 01:11:39,100
fading effect and it would not look very
good at all but here you can see that

983
01:11:39,100 --> 01:11:42,690
actually the shapes of these things and
colors are sort of continuously

984
01:11:42,689 --> 01:11:50,119
deforming from one side to the other
which is quite fun so another experiment

985
01:11:50,119 --> 01:11:53,939
they have in this paper is actually
using vector math to play around the

986
01:11:53,939 --> 01:11:58,069
type of things that these networks
generate so here the idea is that they

987
01:11:58,069 --> 01:12:02,189
generated a whole bunch of random
samples from the noise distribution then

988
01:12:02,189 --> 01:12:05,789
pushed them all through the generator to
generate a whole bunch of samples and

989
01:12:05,789 --> 01:12:09,698
then they as he using their own human
intelligence they tried to make some

990
01:12:09,698 --> 01:12:14,500
semantic judgments about what those
random samples look like and then group

991
01:12:14,500 --> 01:12:18,050
them into a couple of meaningful
semantic categories so here at this

992
01:12:18,050 --> 01:12:21,739
would be three things that three images
that were generated from the network

993
01:12:21,738 --> 01:12:25,529
that all kind of look like a smiling
woman and those are human provided

994
01:12:25,529 --> 01:12:26,819
labels

995
01:12:26,819 --> 01:12:30,309
here in the middle are three samples
from the network of a neutral women that

996
01:12:30,310 --> 01:12:35,010
are that's not smiling and share on the
rate is 300 free samples of a man that

997
01:12:35,010 --> 01:12:40,289
is not smiling so each of these guys was
produced from some latent state vector

998
01:12:40,289 --> 01:12:45,729
so we'll just average those lay in state
vectors to compute this sort of average

999
01:12:45,729 --> 01:12:51,269
average rating state of smiling woman
neutral women and neutral man now once

1000
01:12:51,270 --> 01:12:55,220
we have this latent state vector we can
do some vector math so we can take a

1001
01:12:55,220 --> 01:13:01,050
smiling woman subtract a neutral woman
and at a neutral man so what what would

1002
01:13:01,050 --> 01:13:06,070
that give you so you hope that would
give you a smiling man and this is what

1003
01:13:06,069 --> 01:13:12,649
it generates so this actually it does
kinda look like a smiling man that's

1004
01:13:12,649 --> 01:13:19,199
that's pretty amazing we can do another
experiment we can take a man with

1005
01:13:19,199 --> 01:13:25,099
glasses and a man without glasses and a
man with glasses subtract the man with

1006
01:13:25,100 --> 01:13:31,140
glasses and add a woman with glasses
with no glasses this this is confusing

1007
01:13:31,140 --> 01:13:38,630
stuff so that and what was this what
would this little equation give us a

1008
01:13:38,630 --> 01:13:47,369
look at that so that's that's pretty
crazy so it def assault even though

1009
01:13:47,369 --> 01:13:51,279
we're not sort of forcing an explicit
prior on the sleeping space space these

1010
01:13:51,279 --> 01:13:54,869
adversarial networks have somehow still
managed to learn some really nice useful

1011
01:13:54,869 --> 01:13:59,960
representation there so i also very
quickly I think there's a pretty cool

1012
01:13:59,960 --> 01:14:04,220
paper that just came out a week or two
ago that puts all of these ideas

1013
01:14:04,220 --> 01:14:07,820
together like we covered a lot of
different ideas in this lecture and

1014
01:14:07,819 --> 01:14:11,239
let's just stick them all together so
first we're gonna take a variation on

1015
01:14:11,239 --> 01:14:15,659
quarter as as our starting point and
this will have sort of the normal its

1016
01:14:15,659 --> 01:14:20,130
allies loss from various audio encoder
but we saw that these adversarial

1017
01:14:20,130 --> 01:14:24,220
networks give really amazing samples so
why don't we had an adversarial network

1018
01:14:24,220 --> 01:14:29,630
to the variation autumn quarter so we do
that so now in addition to having our

1019
01:14:29,630 --> 01:14:33,710
variation ottoman quarter we also have
this this discriminator network that's

1020
01:14:33,710 --> 01:14:35,949
trying to tell the difference between
the

1021
01:14:35,949 --> 01:14:40,689
no data and between the samples from the
variational audio encoder but that's not

1022
01:14:40,689 --> 01:14:47,099
cool enough so why don't we also
download Alex NAT and then pass these

1023
01:14:47,100 --> 01:14:47,930
two images

1024
01:14:47,930 --> 01:14:53,730
Alex net and extract Alex net features
for both the original image and four are

1025
01:14:53,729 --> 01:14:59,079
generated image and now in addition to
having a similar pics loss and hair and

1026
01:14:59,079 --> 01:15:02,340
pulling the discriminator we're also
hoping to generate samples that have

1027
01:15:02,340 --> 01:15:06,900
similar Alex net features as measured by
all too and once you stick all these

1028
01:15:06,899 --> 01:15:10,859
things together hopefully you'll get
some really beautiful samples right so

1029
01:15:10,859 --> 01:15:17,069
here are the examples from the paper so
these are paid just train the entire

1030
01:15:17,069 --> 01:15:21,109
thing on image that so we should I think
this is these are actually quite nice

1031
01:15:21,109 --> 01:15:26,029
samples and if you contrast this with
the multiscale samples on CPR that we

1032
01:15:26,029 --> 01:15:29,609
saw before for those samples remember
they were actually training a separate

1033
01:15:29,609 --> 01:15:34,380
model per class and see fire and these
those beautiful bedroom samples that you

1034
01:15:34,380 --> 01:15:35,760
saw was again

1035
01:15:35,760 --> 01:15:40,270
training one model that's specific to
bedrooms but here they actually trained

1036
01:15:40,270 --> 01:15:45,050
one model on all of internet and still
like these are real images but they're

1037
01:15:45,050 --> 01:15:50,489
definitely getting towards real issue
looking images so that's i think these

1038
01:15:50,489 --> 01:15:54,170
are pretty cool I also think it's kind
of fun to just take all these things and

1039
01:15:54,170 --> 01:16:00,020
stick them together and hopefully get
some really nice samples thats I think

1040
01:16:00,020 --> 01:16:02,460
that's pretty much all we have to say
about unsupervised learning so if

1041
01:16:02,460 --> 01:16:05,460
there's any any questions

1042
01:16:07,100 --> 01:16:17,110
what does what is going on here

1043
01:16:18,680 --> 01:16:23,500
yeah so the question is are you may be
literate linear rising the bedroom space

1044
01:16:23,500 --> 01:16:28,079
and that's maybe one way to think about
it that here we remember we're just

1045
01:16:28,079 --> 01:16:30,729
sampling program just sampling from
noise and passing them through the

1046
01:16:30,729 --> 01:16:35,319
discriminator rather through the
generator and then the generator has

1047
01:16:35,319 --> 01:16:40,630
just decided to use these different
noises channels in nice ways such that

1048
01:16:40,630 --> 01:16:44,510
if you interplay between the noise you
end up interpolating between the images

1049
01:16:44,510 --> 01:16:49,110
in sort of a nice smooth way so
hopefully that lets you know that it's

1050
01:16:49,109 --> 01:16:51,799
not just sort of memorizing training
examples it's actually wanting to

1051
01:16:51,800 --> 01:17:00,310
generalize from him in a nice way right
so just to recap everything we talked

1052
01:17:00,310 --> 01:17:04,430
about today we gave you a lot of really
useful practical tips for working with

1053
01:17:04,430 --> 01:17:08,470
videos and then I give you a lot of very
non practical tips for generating

1054
01:17:08,470 --> 01:17:16,119
beautiful images so I think this stuff
is really cool but I'm not sure what the

1055
01:17:16,119 --> 01:17:19,840
uses other than generating images but
its cool so it's fun and definitely

1056
01:17:19,840 --> 01:17:24,640
stick around next time because we'll
have a guest lecture from jap teen so if

1057
01:17:24,640 --> 01:17:27,310
you're watching on the internet maybe
you might wanna come to class for that

1058
01:17:27,310 --> 01:17:31,500
one so I think that's everything we have
today and see you guys later

