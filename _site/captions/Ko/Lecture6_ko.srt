1
00:00:00,000 --> 00:00:07,009
 확인 그래서 우리는 다시 신경망을 훈련에 대해 얘기하자 오늘은 이제 첫 무엇과 

2
00:00:07,009 --> 00:00:10,449
 나는 우리가 다이빙을하기 전에 작동 쇼에 오는 당신에게 인터뷰의 비트를 줄 것이다 

3
00:00:10,449 --> 00:00:15,489
 그 소재 단지 일부 관리 것을 먼저 첫 번째 I로 

4
00:00:15,490 --> 00:00:18,618
 기회를하지 않았다 실제로 인터뷰 저스틴 마지막 강의 저스틴입니다하기 

5
00:00:18,618 --> 00:00:21,579
 이 클래스 또한 강사 그는 처음 2 주 동안 실종됐다 

6
00:00:21,579 --> 00:00:28,409
 그들은 그가 어쩌면 매우 지식의 나에게 아무것도에 대해 아무것도 요청할 수 있습니다 

7
00:00:28,410 --> 00:00:29,428
 즉, 삼가의 

8
00:00:29,428 --> 00:00:37,960
 확인하고 72 그렇게 꽤 오랫동안의 알림 내가 시작하는 것이 좋습니다으로 밖으로 

9
00:00:37,960 --> 00:00:43,850
 여기에 구축하고는 기본적으로 다음 주 금요일은 그래서 가능한 한 빨리 그에 시작 할 수있어합니다 

10
00:00:43,850 --> 00:00:47,679
 가능하면 앞으로의 적절한 API와 함께 작동 노하우를 구현 

11
00:00:47,679 --> 00:00:50,429
 뒤로 클래스와 당신은 경쟁의 추상화 사로 잡고 볼 수 있습니다 

12
00:00:50,429 --> 00:00:54,820
 다시 내 세션으로 이동 중퇴하고 실제로 구현합니다 

13
00:00:54,820 --> 00:00:57,770
 상업 네트워크 실제로이이 과제의 말 때문에 

14
00:00:57,770 --> 00:01:00,770
 강한에 오는 방법의 모든 낮은 수준의 세부 사항을 매우 잘 이해하고 

15
00:01:00,770 --> 00:01:06,530
 네트워크 분류 난 그냥 확인 해요 그래서 우리는 단지 신호로이 클래스에 위치 

16
00:01:06,530 --> 00:01:10,140
 다시 우리는 네트워크에서 훈련을한다 밖으로 신경망을 훈련하고 회전하는 

17
00:01:10,140 --> 00:01:15,590
 정말 4 단계 프로세스는 전체 데이터 세트의 이미지와 라벨 우리가 

18
00:01:15,590 --> 00:01:18,920
 우리가 네트워크를 통해 전파 생각했다 데이터 세트에서 작은 백을 샘플링 

19
00:01:18,920 --> 00:01:23,060
 우리는 현재 분류​​하고 얼마나 잘 우리에게 말하고있는 손실에 도착합니다 

20
00:01:23,060 --> 00:01:26,390
 데이터의 파견 그리고 우리는 모두의 기울기를 완료하기 위해 전파 

21
00:01:26,390 --> 00:01:29,969
 무게와이 그라데이션이 우리에게 말하고 우리가 어떻게 매일 대기 확실하지해야 

22
00:01:29,969 --> 00:01:33,789
 네트워크에 우리는 더 나은 다음 번에이 이미지를 분류하고 있도록 

23
00:01:33,790 --> 00:01:36,700
 우리가 실제로 그렇게 할 경우 우리는 그라데이션 우리가 차 업데이트를 사용할 수있다 

24
00:01:36,700 --> 00:01:38,930
 작은 홈 

25
00:01:38,930 --> 00:01:42,659
 지난 시간 우리는 활성화 기능으로 보면서 나는 활성화 피곤 해요 

26
00:01:42,659 --> 00:01:45,368
 기능과 어떤 장점과 이러한 내부자 신경 중 하나를 사용의 단점 

27
00:01:45,368 --> 00:01:49,060
 물었을 때 좋은 질문이 너무 광장에서 들어오는 네트워크 이유도 당신 것 

28
00:01:49,060 --> 00:01:53,939
 정품 인증 기능을 사용하는 이유는 그냥 건너 뛰고 질문을 제기했다하지 

29
00:01:53,938 --> 00:01:57,618
 난 정말 기본적으로 마지막 강의에 매우 능숙하게이 문제를 해결하는 데있어 

30
00:01:57,618 --> 00:02:00,790
 전체 신경망이 끝나는 경우보다 활성화 함수를 사용하지 않는다면 

31
00:02:00,790 --> 00:02:05,500
 당신의 샌드위치 하나 하나가되는 등 용량 단지의 그것과 동일하다 

32
00:02:05,500 --> 00:02:10,080
 그 활성화 기능이 정말 중요하다, 그래서 선형 분류 

33
00:02:10,080 --> 00:02:13,880
 사이에 그들은 그들은 당신에게 당신이 사용할 수있는 모든 방법을 제공 것들입니다 

34
00:02:13,879 --> 00:02:17,490
 실제로 데이터를 넣어 우리는 전처리에 대해 간단히 이야기 

35
00:02:17,490 --> 00:02:21,860
 기술하지만, 아주 간단히 우리는 또한 활성화 기능을 보았고, 

36
00:02:21,860 --> 00:02:24,830
 신경망 여기 그래서 문제 전반에 걸쳐 자신의 분포 I 

37
00:02:24,830 --> 00:02:31,370
 우리는 이러한 초기 가중치를 선택해야하고 특히 전화가 참조 

38
00:02:31,370 --> 00:02:34,930
 기다리는 사람들을 방법을 큰 규모는 처음에하고 우리는 보았다 

39
00:02:34,930 --> 00:02:38,260
 이 경우 그 그 무게는 신경에​​ 활성화 너무 작은 경우 

40
00:02:38,259 --> 00:02:41,909
 네트워크는 깊은 네트워크가 0으로 이동이 있고 당신이 설정 한 경우 그 기술은 그대로 

41
00:02:41,909 --> 00:02:45,129
 그들 모두보다 높은에 가능성이 대신 폭발하고 그래서 당신은 끝낼 

42
00:02:45,129 --> 00:02:48,939
 다른 네트워크 슈퍼 포화 또는 해당 단지에 대한 모든 네트워크와 끝까지 

43
00:02:48,939 --> 00:02:54,189
 0과 1 그래서 그 규모는 우리가 들여다 설정하는 매우 매우 까다로운 일이다 

44
00:02:54,189 --> 00:02:59,579
 당신이에 사용하는 것은 합리적인 종류를 제공 초기화 

45
00:02:59,580 --> 00:03:03,290
 형성하고는 기본적으로 대략 좋은 활동 활성화 또는를 제공합니다 

46
00:03:03,289 --> 00:03:06,459
 훈련의 시작 부분에서 네트워크를 통해 활성화의 분포 

47
00:03:06,459 --> 00:03:10,959
 그리고, 우리는 많이 경감이 일에 가장 정상화에 들어갔다 

48
00:03:10,959 --> 00:03:14,120
 실제로 제대로 그 기술을 설정하고 세바스찬 이러한 두통의 

49
00:03:14,120 --> 00:03:16,689
 법안이에게 그들이 필요 없어 훨씬 더 강력한 선택한다 

50
00:03:16,689 --> 00:03:20,550
 정확하게 맞 초기 규모를 얻고 우리는 현재의 모든 호출에 갔다 

51
00:03:20,550 --> 00:03:23,620
 우리는 잠시 동안 그것에 대해 이야기하고 우리는 학습에 대해 이야기 

52
00:03:23,620 --> 00:03:26,920
 당신이 실제로 할 방법에 대한 팁과 트릭의 종류를 표시하려고에 의해 처리 

53
00:03:26,919 --> 00:03:29,809
 말했다 당신이 그들을 어떻게 또한 제대로 훈련받을 방법이 신경망 

54
00:03:29,810 --> 00:03:34,860
 위반에 걸쳐 실행 방법 천천히 시간이 지남에 너무 렌더링 일어나 

55
00:03:34,860 --> 00:03:37,769
 우리는 몇 가지로 갈거야 그래서이 시간에 대한 모든 것을 지난 시간에 이야기 

56
00:03:37,769 --> 00:03:41,060
 위 특정 매개 변수에 훈련 신경 네트워크의 나머지 항목 

57
00:03:41,060 --> 00:03:44,989
 계획은 나는 대부분의 부분을 생각하고 우리는 내 난 앙상블 드롭 아웃에 대해 조금 얘기하자 

58
00:03:44,989 --> 00:03:49,480
 나는 그 어떤 행정 일에 난 내 길을 뛰어 등등 전에 있도록 

59
00:03:49,479 --> 00:03:53,509
 잊고 반드시 그렇게 

60
00:03:53,509 --> 00:03:58,030
 차 업데이트 신경망을 훈련에 프로세스가 거기에 있기 때문에 

61
00:03:58,030 --> 00:04:01,199
 이것은 정말 당신이 위반에 대해는 그 모습에 의사입니다 

62
00:04:01,199 --> 00:04:04,419
 법에 심각한 그라데이션 내가 얘기 공연 차 업데이트 

63
00:04:04,419 --> 00:04:08,030
 매개 변수 업데이트는 특히 여기 어디에서이 마지막 줄보고 있었다 

64
00:04:08,030 --> 00:04:12,129
 우리가 만들려고하는보다 복잡한 그 어디 그래서 지금 우리가 무슨 일을하는지 

65
00:04:12,129 --> 00:04:17,129
 학교는 단지 일을 읽고. 우리는 내 컴퓨터 및 우리에 그 휴식을 취할 곳 

66
00:04:17,129 --> 00:04:21,639
 그냥 우리의 주요 요인의 학습 속도에 의해 확장 및 곱셈 우리는 할 수 있습니다 

67
00:04:21,639 --> 00:04:23,159
 훨씬 더 정교한 방법으로 우리 

68
00:04:23,160 --> 00:04:27,960
 해당 날짜 등등에 나는 지난 몇 강의 곳에서 간단히 이미지를 플래시 

69
00:04:27,959 --> 00:04:30,759
 서로 다른 매개 변수를 업데이트 방식을 볼 수 있습니다 얼마나 빨리 그들은 실제로 

70
00:04:30,759 --> 00:04:35,129
 여기에 간단한 손실 함수를 최적화 그래서 특히 것을 볼 수 있습니다 STD 

71
00:04:35,129 --> 00:04:38,550
 우리가 여기에 네 번째 줄에 현재 사용하고 그 발 빠르게 그리고 무엇 인 

72
00:04:38,550 --> 00:04:41,710
 그 사실 때문에 그들 모두의 가장 느린 하나입니다 것을 볼 수 있습니다 당신에게 책을 읽어 

73
00:04:41,709 --> 00:04:45,139
 당신은 거의 이제까지 단지 기본 양육권을 사용하지 연습하고 더 나은 방식이다 것을 우리 

74
00:04:45,139 --> 00:04:48,979
 우리가 이제 무엇을 살펴 보자 구조에서 이들에 갈거야 사용할 수 있습니다 

75
00:04:48,980 --> 00:04:54,810
 문제는 너무 느려 약간이 특정을 고려하는 이유 하사관 함께 

76
00:04:54,810 --> 00:04:58,589
 우리는 손실 함수 액면 세트가 여기에 인위적 예 우리 

77
00:04:58,589 --> 00:05:02,099
 손실은 다른 것보다 훨씬 더 높은 긴 한 방향에 반대 

78
00:05:02,100 --> 00:05:05,500
 여기 방향 때문에 기본적으로이 손실 함수는 매우 얕은입니다 

79
00:05:05,500 --> 00:05:10,199
 수평으로하지만, 매우 수직으로 가파른 물론이을 최소화하기 위해 우리가 할 

80
00:05:10,199 --> 00:05:13,469
 우리가 렉스 볼티모어에있어 지금이 가리키는 최소려고 

81
00:05:13,470 --> 00:05:19,240
 우리가 행복 만의 궤도 무엇에 대해 생각 어디 웃는 얼굴 

82
00:05:19,240 --> 00:05:22,980
 이 모두 X 및 Y 방향이다 

83
00:05:22,980 --> 00:05:30,650
 주디 우리가 같은 그 표정이 풍경을 최적화하려고하면 그래서 뭐 

84
00:05:30,649 --> 00:05:35,729
 그것은 수평과 같이 수직으로 난 그렇게 누군가의 엉덩이를 볼 것입니다 무슨 

85
00:05:35,730 --> 00:05:43,540
 당신은 거기 계획하는 이유는 그래서 최대 반송 가서 아래처럼 있어요된다 

86
00:05:43,540 --> 00:05:52,030
 그 이유는 많은 진전를 잘 기본적으로이가되게하지 않습니다 

87
00:05:52,029 --> 00:05:56,969
 우리가 그라데이션 볼 포럼 수평 우리는 복사가 있음을 볼 수 

88
00:05:56,970 --> 00:06:00,680
 이 수평 얕은 기능을하지만 우리가이 있기 때문에 매우 작은 

89
00:06:00,680 --> 00:06:03,439
 큰 평가는 무슨 일이 일어날에 관해서는 매우 가파른 기능이기 때문에 

90
00:06:03,439 --> 00:06:06,389
 당신은 이들 종류의 경우에서 거리를 출시하고이 끝낼 때 

91
00:06:06,389 --> 00:06:10,250
 당신이 수평 방향으로 너무 느린거야 패턴의 종류 만 

92
00:06:10,250 --> 00:06:13,300
 이에 결국 때문에 당신은 너무 빠르고 수직 방향을거야 

93
00:06:13,300 --> 00:06:17,918
 올해 하나 이런 상황 또는 치료의 방법을 우리는 기억으로 모멘텀 그래서 

94
00:06:17,918 --> 00:06:22,189
 기세 업데이트에 대한 업데이트는 다음과 같은 방법으로 우리의 업데이 트를 변경됩니다 

95
00:06:22,189 --> 00:06:25,319
 그래서 지금 우리는 단지 그라데이션을 구현하고 

96
00:06:25,319 --> 00:06:28,409
 그라데이션을 복용하고 우리는에 의해 우리의 현재 위치를 통합하고 

97
00:06:28,410 --> 00:06:34,220
 날짜에 등급 대신 우리는 우리가 계산 된 그라데이션을거야 및 

98
00:06:34,220 --> 00:06:36,449
 대신 직접 위치를 통합 

99
00:06:36,449 --> 00:06:40,840
 우리는 내가 너무 속도로 떠날 수있는이 변수 V를 증가거야 

100
00:06:40,839 --> 00:06:44,049
 우리는 우리가 증가 그래서 약간의 이유를 보게 될 것입니다 

101
00:06:44,050 --> 00:06:48,020
 속도의 변수가 될 대신 대신에 우리는 기본적으로 가입이 구축하고 

102
00:06:48,019 --> 00:06:53,278
 과거에 일부 신빙성을 지수 및 그 위치를 통합하는거야 

103
00:06:53,278 --> 00:06:58,610
 여기에이 새로운는 0과 1 사이의 숫자의 종류로 행복 프라이머 및 음소거입니다 

104
00:06:58,610 --> 00:07:03,629
 그리고 이전 BE되었다 하 등 화면 구배에 첨가 하였다 

105
00:07:03,629 --> 00:07:07,180
 당신은 매우 물리적으로 해석 할 수있는 업데이트 모멘텀에 대한 좋은 데요 

106
00:07:07,180 --> 00:07:14,310
 조건 및 다음과 같은 방법으로 기본적으로 모멘텀 업데이트에 해당하는 사용 

107
00:07:14,310 --> 00:07:18,899
 할인 목록을 해석하는 정말 대담한 구름이 라운드가 허용하는 

108
00:07:18,899 --> 00:07:22,459
 프리이 경우 그래디언트가 숲이라는 입자 

109
00:07:22,459 --> 00:07:26,408
 느낌 그래서이 문서는 대신 그라데이션 약간의 힘을 느끼고있다 

110
00:07:26,408 --> 00:07:31,158
 힘이 상당하므로 직접 위치를 물리학이 힘을 통합 

111
00:07:31,158 --> 00:07:36,019
 이 때문에 가속에 가속이 우리가 경쟁하고있는 것입니다 

112
00:07:36,019 --> 00:07:39,938
 그래서 속도는 여기에 다음 새 배의 가속도에 의해 통합됩니다 

113
00:07:39,939 --> 00:07:43,039
 그 경우에, 마찰의 해석을 가지고 그 때문에 매 

114
00:07:43,038 --> 00:07:47,759
 반복은 약간 둔화이 새로운 시간이 될 직관적 경우 아니었다했다 

115
00:07:47,759 --> 00:07:51,550
 그냥 법 주위에 있었기 때문에 휴식을 오지로 다음 굵게가 않습니다 

116
00:07:51,550 --> 00:07:54,509
 영원히 표면과가에 정착 할 에너지의 손실이 없을 것 

117
00:07:54,509 --> 00:07:58,158
 손실 기능 등 최종 운동량 업데이트는이 중임 

118
00:07:58,158 --> 00:08:01,810
 최적화의 물리적 해석 그러나 우리는 볼이 약 롤링이 

119
00:08:01,810 --> 00:08:08,249
 그리고 시간이 지남에 따라 둔화 것 등이 작동하는 방식은 아주 좋은 무엇이다 

120
00:08:08,249 --> 00:08:11,669
 이 업데이트에 대한 당신은 특히이 속도와를 구축 끝으로 

121
00:08:11,668 --> 00:08:14,959
 얕은 방향을보고 매우 쉽게 당신이 얕은이있는 경우 만 

122
00:08:14,959 --> 00:08:18,449
 일관된 방향은 다음 모멘텀 업데이트는 천천히 속도를 구축 할 것입니다 

123
00:08:18,449 --> 00:08:21,360
 당신이 얕은에서 위로 가속화 결국 방향 벡터 

124
00:08:21,360 --> 00:08:24,999
 방향하지만 무슨 일이 일어날 매우 가파른 방향으로 당신의 시작입니다 

125
00:08:24,999 --> 00:08:28,919
 과정은 일반적으로 약하지만 당신은 항상 다른 사람을 뽑아되고있어 

126
00:08:28,918 --> 00:08:32,429
 중심을 향해 및 감쇠 및 진동의 종류와 방향 

127
00:08:32,429 --> 00:08:36,338
 그래서 그것은 종류의 가파른 방향이 진동을 찍힌 것 중간 및 

128
00:08:36,339 --> 00:08:41,139
 종류의이 과정을 장려하고 일관성이있어 고무적 

129
00:08:41,139 --> 00:08:44,889
 얕은 방향과는 컨버전스의 개선 끝나는 이유입니다 

130
00:08:44,889 --> 00:08:49,600
 대부분의 경우는 그래서 여기 시각화, 예를 들어 우리는 SED 업데이트에서 참조 

131
00:08:49,600 --> 00:08:53,459
 모멘텀 업데이트는 녹색 아니고, 그래서 당신은 녹색 하나를 어떻게 볼 수 있습니다 

132
00:08:53,458 --> 00:08:57,008
 신발을 통해 공격하면이 모든 홍보를 구축하기 때문에 

133
00:08:57,009 --> 00:09:00,909
 최소 오버 슈트하지만 그것은 결국 갤런 변환 끝과 

134
00:09:00,909 --> 00:09:04,169
 물론 그것은 촬영 끝났어하지만이 나온다 일단 당신은 그것의 것을 볼 수있다 

135
00:09:04,169 --> 00:09:07,879
 가 결국 업데이트처럼 그냥 기본보다 훨씬 더 빨리 수렴 

136
00:09:07,879 --> 00:09:11,230
 문을 너무 많이 구축하면 결국 경우보다가 빨리 얻을 것보다 

137
00:09:11,230 --> 00:09:17,110
 당신은 속도가 모멘텀 업데이트는 가고있다있어하지 않았다 

138
00:09:17,110 --> 00:09:20,430
 운동량의 특정 변이 난 그냥 물어보고 싶은게 조금 등장 

139
00:09:20,429 --> 00:09:34,289
 나는 프라이머와 같은 단일있어 언제 모멘텀에 대한 질문은 업데이트 

140
00:09:34,289 --> 00:09:40,078
 보통 때때로 어떤 약 8.5 4.9의 값과 보통 사람들 소요 

141
00:09:40,078 --> 00:09:43,219
 그것은 슈퍼 혜성은 아니지만 사람들이 때때로 리드 (25) 2.99에서 

142
00:09:43,220 --> 00:09:54,200
 천천히 시간이 지남에 있지만, 그것은 단지 하나의 숫자입니다 

143
00:09:54,200 --> 00:09:57,180
 네 그래서 당신은 작은 학습 속도하지만 문제가있는 사람을 방지 할 수 있습니다 

144
00:09:57,179 --> 00:10:03,000
 당신이 있다면 느린 학습 속도는 모든 방향에 전 세계적으로 적용된다 

145
00:10:03,000 --> 00:10:06,070
 그라데이션 등은 당신이에 진전을하지 않는다 기본적 것이다 

146
00:10:06,070 --> 00:10:09,390
 수평 방향으로 오른쪽 당신은 많은 것을 얻을 수 없겠죠하지만 그것은 당신을 데려 갈 것이다 

147
00:10:09,389 --> 00:10:12,710
 영원히 갈 수평으로 몇 가지 작은 학습은 떨어져 무역의이 종류는 말한다 

148
00:10:12,710 --> 00:10:25,350
 자신의 질문에 수정을 설명하는 선택 방법을 초기화하는 방법입니다 

149
00:10:25,350 --> 00:10:29,050
 일반적으로 10을 상실하고 결국 있기 때문에 문제가 너무 많이하지 않습니다 

150
00:10:29,049 --> 00:10:32,490
 처음 몇 단계를 구축하고 당신은 당신이 경우 다음과 같이 끝 

151
00:10:32,490 --> 00:10:35,480
 이 기하 급수적으로의 당신은 기본적으로 그 볼이 재발을 지출 

152
00:10:35,480 --> 00:10:39,330
 이전 인사의 일부를 부패 그래서 당신은 당신이 당신에게 그것을 가지고 한 번 

153
00:10:39,330 --> 00:10:46,020
 모멘텀의 특정 열 때문에 특히 변화라는 것을 가지고있다 

154
00:10:46,019 --> 00:10:53,449
 모멘텀과 그라데이션 하강 여기에 생각에 아저씨는 우리가이입니다 

155
00:10:53,450 --> 00:10:57,550
 보통 운동량 여기 방정식 그것에 대해 생각하는 방법이다 당신의 

156
00:10:57,549 --> 00:10:59,789
 초과 정말 두 부분으로 추천 

157
00:10:59,789 --> 00:11:03,279
 특정 방향으로 약간의 힘을 너무 구축하는 것이의 한 부분이있다 

158
00:11:03,279 --> 00:11:06,799
 즉, 새로운 시대를 그린의 모멘텀 단계이고 그 곳이다 

159
00:11:06,799 --> 00:11:09,959
 모멘텀은 현재를 수행하기 위해 노력하고 두 번째가 

160
00:11:09,960 --> 00:11:12,610
 그라디언트에서 기여 기울기는이 방법으로 당기는 

161
00:11:12,610 --> 00:11:17,450
 손실 함수의 감소와 실제 단계는 벡터 합인 끝낸다 

162
00:11:17,450 --> 00:11:21,350
 그래서 블루만큼 당신이 결국 두 사람은 그냥 녹색 더하기 빨간색의 

163
00:11:21,350 --> 00:11:24,840
 생각하지만 필요한 모멘텀이 실제로 더 나은 작업 끝과 

164
00:11:24,840 --> 00:11:29,629
 다음과 같이 우리는 관계없이 현재의 입력이 무엇의이 시점에서 알 

165
00:11:29,629 --> 00:11:33,439
 우리에게 그래서 우리는 최대 아직 대해 경쟁하지 않은 그러나 우리는 우리가 어떤을 구축 한 것을 알고있다 

166
00:11:33,440 --> 00:11:37,240
 모멘텀과 우리는 우리가 확실히 확인 그래서이 녹색 방향을거야 알고 

167
00:11:37,240 --> 00:11:41,220
 우리는 확실히 여기이 그린 밸리 성분을거야 우리 

168
00:11:41,220 --> 00:11:45,310
 현재의 자리 네 스테 로프 모멘텀을 수행 앞서 대신보고 싶어 

169
00:11:45,309 --> 00:11:49,379
 화살표의 상단이 시점에서이 시점 기울기를 평가하므로 

170
00:11:49,379 --> 00:11:53,679
 당신이와 끝까지 우리가 우리가가는거야 알고 여기에 다음과 같은 차이 

171
00:11:53,679 --> 00:11:57,089
 왜 그냥 같은 것은 그 부분에 도착하기 앞서 살펴 어쨌든이 길을 갈 

172
00:11:57,090 --> 00:12:00,420
 객관적이고 그 시점에서 녹색을 평가하고 그것은 물론 당신이있어하지 않습니다 

173
00:12:00,419 --> 00:12:02,309
 다른에이기 때문에 독서는 다소 차이가있을 것입니다 

174
00:12:02,309 --> 00:12:05,669
 로스 함수의 위치와이 한 단계 앞서 당신에게 약간 더 나은를 제공 

175
00:12:05,669 --> 00:12:06,259
 방향 

176
00:12:06,259 --> 00:12:11,109
 저기 수 있습니다 당신은 당신이 할 수있는 지금 그것을 약간 다른 업데이 트를 얻을 

177
00:12:11,109 --> 00:12:14,379
 이론적으로이 사실에 더 나은 이론 보장을 즐기는 것을 보여 

178
00:12:14,379 --> 00:12:18,069
 수렴 속도뿐만 아니라이 이론뿐만 아니라 실제의 사실과 

179
00:12:18,068 --> 00:12:23,068
 거의 항상 차이가 너무 좋아 그냥 순간보다 더 잘 작동 약 

180
00:12:23,068 --> 00:12:28,358
 다음 해에 그 코드를하지만 여전히 우리의 표기법처럼 같은 작성한된다 

181
00:12:28,359 --> 00:12:29,589
 시간이 

182
00:12:29,589 --> 00:12:33,089
 당신이 현재하고있는 이전의 속도 벡터 및 구배를 돌연변이 

183
00:12:33,089 --> 00:12:37,629
 평가하고 우리는 여기에 업데이트를하고 있으므로 필요한 업데이트 만을 

184
00:12:37,629 --> 00:12:41,720
 차이는이 새로운 더한 새로운 BTW 시간을 뺀 11의 뜻 여기 보류했다 

185
00:12:41,720 --> 00:12:44,949
 우리는이에 약간 다른 위치에서 평가 한 그라데이션을 평가 

186
00:12:44,948 --> 00:12:48,278
 위치를 미리보고 그래서 강한 모멘텀에 정말 그것은 거의 

187
00:12:48,278 --> 00:12:51,698
 항상 지금 약간의 기술은 내가 안되는 여기 거기되는 작품 

188
00:12:51,698 --> 00:12:57,068
 너무 많이 들어갈 것 같네요하지만 사실 그 불편할 약간 있어요 

189
00:12:57,068 --> 00:13:00,418
 일반적으로 우리는 향후에 대해 생각하고 뒤로 우리는 결국 무엇 때문에 통과 

190
00:13:00,418 --> 00:13:04,288
 으로는 최대 프라이 머리 승리 데이터와 그 때의 기울기를 갖지만 

191
00:13:04,288 --> 00:13:09,088
 당신은 떨어져에서 사육 매개 변수 및 그라데이션을 가지고 우리를 원하는 경우는 없습니다 

192
00:13:09,089 --> 00:13:12,600
 다른 점은 그래서 꽤 단지 사이의 간단한 API처럼에 맞지 않는 

193
00:13:12,600 --> 00:13:16,019
 코드를 갖는 그래서 방법이 밝혀 내가 정말하고 싶지 않아 

194
00:13:16,019 --> 00:13:19,899
 아마이에 너무 많은 시간을 소비하지만, 기본적으로 변수를 할 수있는 방법이 

195
00:13:19,899 --> 00:13:23,379
 변압기는 통지 일부 재배치를 수행 살이 찐를 얻을 당신은 얻을 

196
00:13:23,379 --> 00:13:26,079
 더욱 새로 업데이트의처럼 보이는 뭔가 그냥 수 

197
00:13:26,078 --> 00:13:29,538
 당신이 결국 때문에 감동 에드 교환 아만다 마틴에서 스 와이프 

198
00:13:29,538 --> 00:13:34,119
 만 그라디언트 위축을 필요로하고 당신을 무언가를 업데이트하고이 기​​능은 

199
00:13:34,119 --> 00:13:35,209
 정말 앞서 보여요 

200
00:13:35,208 --> 00:13:38,159
 매개 변수의 버전들은 그냥 원시 매개 변수 벡터에 있기 때문에 

201
00:13:38,159 --> 00:13:40,608
 당신이 노트에 갈 수있는 단지 전문적이 체크 아웃하기 

202
00:13:40,609 --> 00:13:46,709
 확인 그래서 여기에 네 스테 로프 가속 독서는 마젠타에 당신은 볼 수 있습니다 

203
00:13:46,708 --> 00:13:50,208
 원래 가게를 통해 여기 모멘텀하지만 많은하지만 가속 때문에 아저씨 

204
00:13:50,208 --> 00:13:53,958
 모멘텀은 당신이 주위에 더 많은 곱슬 있다고 볼 수 있습니다 앞서이 한 단계가 

205
00:13:53,958 --> 00:13:57,738
 신속하고 그 때문에 모든이 작은 기여 약간 더 낫다 

206
00:13:57,739 --> 00:14:01,619
 당신이하려고합니다 어디에서 그라데이션 합산 결국하고 거의 항상합니다 

207
00:14:01,619 --> 00:14:08,600
 UD 모멘텀이이었다 최근까지 수 있도록 빠른 그래서 필요의 수렴 

208
00:14:08,600 --> 00:14:11,329
 훈련 상용 네트워크와 많은 사람들의 표준 기본 방법 

209
00:14:11,328 --> 00:14:14,658
 아직이에서 볼 수있는 일반적인 일 업데이트하기 위해 잠시를 사용하여 훈련 

210
00:14:14,658 --> 00:14:17,610
 연습과 필요한 경우 더 나은 

211
00:14:17,610 --> 00:14:20,990
 그래서 잡지는 여기에 일주일을 의미합니다 

212
00:14:20,990 --> 00:14:44,350
 당신이 그것에 대해 생각하는지 질문은 그래서 나는 그것이 약간 잘못된 생각 

213
00:14:44,350 --> 00:14:46,990
 만 일반적으로 생각 신경 네트워크에 대한 옵션을 많이 생각 

214
00:14:46,990 --> 00:14:50,350
 이 미친 계곡과 지역 최소값을 많이 사방 실제로는 아니다 

215
00:14:50,350 --> 00:14:53,670
 그것은 그 보는 올바른 방법은 개념이 할 수있는 올바른 접근이다 

216
00:14:53,669 --> 00:14:56,278
 당신의 마음에 당신은 아주 작은 신경 네트워크와 사람들이 생각하는 데 사용 때 

217
00:14:56,278 --> 00:14:59,769
 지역 최소값 것을 문제 및 최적화 네트워크 그러나 실제로집니다 

218
00:14:59,769 --> 00:15:04,269
 당신이 당신의 모델을 확장으로 최근의 이론적 작업의 많은 아웃 

219
00:15:04,269 --> 00:15:10,740
 이 지역의 최소 갈수록 문제의 사진에 있도록되어 있습니다 

220
00:15:10,740 --> 00:15:14,389
 생각하고있는 것은 지역의 최소값 많이있다하지만 그들은 같은에 대한 모든 것 

221
00:15:14,389 --> 00:15:18,958
 실제로이 때문에 이러한 기능의 신경을보고 더 나은 방법 손실 

222
00:15:18,958 --> 00:15:22,078
 실제로 연습 네트워크와 나는 그릇 등 같은 훨씬 더 찾고 있어요 

223
00:15:22,078 --> 00:15:25,599
 대신 미친 계곡 풍경과 당신은 여전히​​ 당신으로 그것을 표시 할 수 있습니다 

224
00:15:25,600 --> 00:15:28,360
 신경망 최선보다는 최악의 등의 차이 

225
00:15:28,360 --> 00:15:29,259
 지역 최소값 

226
00:15:29,259 --> 00:15:32,448
 실제로 좀 좋아도 일부 연구자와 시간이 지남에 따라 아래로 축소 

227
00:15:32,448 --> 00:15:36,120
 기본적으로이 매우 소규모 네트워크에서 일어나는 나쁜 지역 최소값가 없습니다 

228
00:15:36,120 --> 00:15:41,409
 당신이 다른과 초기화하면 그렇게 연습에서 실제로 당신이 찾는 것은 

229
00:15:41,409 --> 00:15:44,610
 임의의 초기화는 거의 항상 같은처럼 같은 대답을 받고 결국 

230
00:15:44,610 --> 00:15:48,009
 결국 손실은 그래서 당신은 같은 나쁜 지방의 최소값은 없습니다 결국하지 마십시오 

231
00:15:48,009 --> 00:15:57,429
 때로는 특히 당신이 질문을 네트워크 질문을 시작했다 때 

232
00:15:57,429 --> 00:16:10,849
 네 스테 로프 진동 기능을하는 부분으로 

233
00:16:10,850 --> 00:16:14,819
 확인 당신이 여러 슬라이드로 이동하려고했다가에 의해 아마했다 점프 있다고 생각 

234
00:16:14,818 --> 00:16:19,849
 약간의 두 번째 또는 두 가지 방법이 괜찮 날 정말 또 다른 업데이트에 뛰어 보자 

235
00:16:19,850 --> 00:16:23,069
 이 접지라고하고 원래 개발 된 사례에서 볼 것이 일반적 

236
00:16:23,068 --> 00:16:25,969
 다음 볼록 최적화 문학과는 가지에 포팅되었다 

237
00:16:25,970 --> 00:16:30,019
 다른 큰 업데이트로 보이는 있도록 신경망 사람들은 가끔 사용 

238
00:16:30,019 --> 00:16:30,560
 다음 

239
00:16:30,559 --> 00:16:35,619
 우리가 일반적으로 몇 가지 기본적인 확률 그라데이션 하강을 참조로 우리는이 업데이트가 

240
00:16:35,620 --> 00:16:37,500
 여기에 여기에 큰 시간을 학습 

241
00:16:37,500 --> 00:16:42,259
 그라데이션하지만 지금 우리는이 그라데이션 있지만이 추가 변수를 확장하고 

242
00:16:42,259 --> 00:16:47,589
 우리는 있었다이 현금 구축하고 있음을 여기에 메모를 축적 유지하는 것이 

243
00:16:47,589 --> 00:16:52,199
 그라데이션 사각형의 합이 캐시는 양수 만 포함 

244
00:16:52,198 --> 00:16:55,599
 여기 캐시 변수가 같은 크기의 합작 투자 참고하여 

245
00:16:55,600 --> 00:17:00,730
 개인 차원에서 구축 요인 등이 현금과 최대이었다 

246
00:17:00,730 --> 00:17:03,839
 그라디언트 또는 제곱의 합을 추적하는 데 우리는 때때로을에 좋아 

247
00:17:03,839 --> 00:17:07,679
 이들의 두 번째 순간이라는 Oncenter은 잠시 시간을내어 그래서 우리는 계속 

248
00:17:07,679 --> 00:17:12,409
 이 현금을 구축하고 우리가 요소를 분할하는 이유에 의해이 단계 기능입니다 

249
00:17:12,409 --> 00:17:21,709
 그 이유는 그래서 광장 현금의 루트 그래서 무슨 일이 일어나고 끝이 

250
00:17:21,709 --> 00:17:26,189
 사람들은 그것을 푸르르의 푸르르 매개 변수 적응 학습 율법 때문에 호출 

251
00:17:26,189 --> 00:17:31,090
 모든 단일 제품 이제 매개 변수 공간의 모든 단일 차원 

252
00:17:31,089 --> 00:17:34,569
 동적으로 내용에 따라 조정됩니다 같은 학습 속도의 자신의 종류가 

253
00:17:34,569 --> 00:17:39,079
 재료의 종류이 너무 그 규모면에서 볼 수있다 

254
00:17:39,079 --> 00:17:42,859
 우리의 경우 특히이 경우 사인으로 발생하는 해석 

255
00:17:42,859 --> 00:17:47,019
 이 어떤 수평 및 수직 방향으로 발생하지만,이 종류의 작업을 수행 

256
00:17:47,019 --> 00:17:51,359
 역학 

257
00:17:51,359 --> 00:18:03,789
 우리가 수직으로 큰 것을 큰 경사를 가지고 당신은 무엇을 볼 수 있습니다 

258
00:18:03,789 --> 00:18:07,259
 그라데이션은 현금까지 추가되고 우리는 더 크고로 나누어 결국 

259
00:18:07,259 --> 00:18:11,359
 큰 숫자는 너무 너무 수직 단계에서 더 작은 업데이트를 얻을 것이다 

260
00:18:11,359 --> 00:18:14,798
 우리는 매우 깨끗 큰 영역을 많이보고있는 때문에이 학습을 부패한다 

261
00:18:14,798 --> 00:18:18,859
 속도가 수직 방향뿐만에서 더 작은 단계들을 만들 

262
00:18:18,859 --> 00:18:22,009
 우리가 끝낼 수 있도록 수평 방향으로는 매우 얕은 방향의 

263
00:18:22,009 --> 00:18:25,750
 분모 작은 숫자는 당신이 볼 수 있다는 Y에 대한 상대 

264
00:18:25,750 --> 00:18:29,058
 치수는 우리가이 성능 조정이 있도록 빠른 진행을 끝낼거야 

265
00:18:29,058 --> 00:18:35,058
 이 회계의 효과는 기울기와 알라 신의 뜻 방향을 당신에게 

266
00:18:35,058 --> 00:18:40,319
 실제로 수직 대신 바로 그때 훨씬 더 큰 학습을 할 수 있습니다 

267
00:18:40,319 --> 00:18:48,048
 방향 및하지만 그래서는 대학원이없는 한 문제이다는 생각이 무엇인지 

268
00:18:48,048 --> 00:18:53,009
 우리가 원한다면 우리는이 위치를 업데이트하고, 상기 공정 크기로 발생 

269
00:18:53,009 --> 00:18:55,900
 오랜 시간 동안 전체 깊은 신경망에게 지분을 훈련하고 우리는있어 

270
00:18:55,900 --> 00:19:01,970
 그래서 물론 정도에 무슨 일이 일어날 이번 여름에 오랜 시간 훈련 

271
00:19:01,970 --> 00:19:05,169
 현금은 이러한 모든 긍정적 인 번호를 추가 모든 시간을 구축 결국 

272
00:19:05,169 --> 00:19:09,100
 분모에 들어가는 당신은 말 그대로 단지의 경우 20이고 당신은 중지 끝 

273
00:19:09,099 --> 00:19:14,579
 완전히 같은 학습 및 그래서 그래서 아니에요 확인 소득세 문제입니다 

274
00:19:14,579 --> 00:19:17,970
 아마도 우리는 그냥 가지 볼링을 최적의 아래로 붕괴 당신이있어 

275
00:19:17,970 --> 00:19:21,919
 수행하지만 신경 네트워크에서 물건 그건 좀 다음 주위에 왕복 같다 

276
00:19:21,919 --> 00:19:24,549
 그에 따라 그림을 시도하는 것은 그래서이 그것을 생각하고 더 좋은 방법처럼 

277
00:19:24,548 --> 00:19:28,329
 것은 당신의 데이터를 얻을 에너지의 지속적인 종류를 필요로하고 그래서 당신은 싶지 않아 

278
00:19:28,329 --> 00:19:33,009
 이었다 사인에 매우 간단한 변화가 그래서 그냥 중단 붕괴 

279
00:19:33,009 --> 00:19:37,829
 최근 제프 힌튼에 의해 제안 여기 아이디어는 대신 유지하는 것입니다 

280
00:19:37,829 --> 00:19:42,289
 완전히 그냥 제곱의 합과 나는 우리가 있는지 확인 주말을 언급 할 수 있었다 

281
00:19:42,289 --> 00:19:46,250
 새는 카운터 카운터 그래서 대신에 우리는 하이킹이 붕괴 속도와 끝까지 

282
00:19:46,250 --> 00:19:52,500
 주 우리는 0.99 % 사각형과 같은 설정 만 제곱의 합이다 

283
00:19:52,500 --> 00:19:57,750
 천천히 누출하지만 괜찮 것은 그래서 우리는 여전히 좋은 동점을 유지하는 우리 

284
00:19:57,750 --> 00:20:01,569
 가파른 또는 포격 방향으로 스텝 크기를 등화 효과 

285
00:20:01,569 --> 00:20:05,869
 우리는 단지 무기를 판매 완전히 20 업데이트를 변환하지 않을거야 

286
00:20:05,869 --> 00:20:10,299
 19 법안 무기 적절한 방법에 대한 역사적 접촉하는 방식이었다입니다 

287
00:20:10,299 --> 00:20:11,430
 우리에게 소개 

288
00:20:11,430 --> 00:20:14,340
 당신은이 방법을 제안 종이 될 것이라고 생각하지만 사실 그것은이었다 

289
00:20:14,339 --> 00:20:18,789
 슬라이드 저스틴 스콧 사라 클래스 불과 몇 년 전 그래서 저스틴 단지 

290
00:20:18,789 --> 00:20:22,240
 삶의 슬라이드이되어 번쩍이 해적 클래스를 제공 하였다 

291
00:20:22,240 --> 00:20:25,630
 게시되지 않은 그러나 이것은 일반적으로 실제로 잘 작동하고 이렇게하고 있어요 

292
00:20:25,630 --> 00:20:29,920
 기본적으로 우리의 수학 문제는 그래서 나는 그 다음 내가 더 잘 같은 본 구현 

293
00:20:29,920 --> 00:20:34,060
 바로 내 최적화 결과와 나는 그 정말 재미라고 생각하고 

294
00:20:34,059 --> 00:20:37,769
 논문뿐만 아니라 내 논문하지만 많은 사람들 다른 논문에서 사실 마이크에 너무 

295
00:20:37,769 --> 00:20:44,559
 코 세라에서 슬라이드를 인용 한 바로 강의 6 슬라이드 그냥 밀어 

296
00:20:44,559 --> 00:20:48,389
 이후 문제는 다음이 지금 실제로 실제 용지이며 더 많은 결과가있다 

297
00:20:48,390 --> 00:20:52,300
 정확히 그가하고있어 및 등등하지만 잠시 동안이 정말 우스웠다에 

298
00:20:52,299 --> 00:20:57,609
 그래서이까지 내 관점에서 우리는 여기 땅이 파란색과 아라미스입니다 볼 수 있습니다 

299
00:20:57,609 --> 00:20:58,579
 소품이입니다 

300
00:20:58,579 --> 00:21:02,490
 블랙 우리는 둘 다 아래로 여기 아주 빨리 덮여 있음을 알 수 

301
00:21:02,490 --> 00:21:07,519
 보다 약간 빠른 변환이 대학원에서이 특정한 경우에 방법과 

302
00:21:07,519 --> 00:21:11,589
 무기 문제 그러나 그것은 항상 당신이 볼 일반적으로 어떤 경우 뭔가 아니다 

303
00:21:11,589 --> 00:21:15,839
 대학원 너무 일찍 중지하고 그대로 실천하면 펜 Jillette에 훈련 작품 

304
00:21:15,839 --> 00:21:21,329
 비참 말까지 일반적으로 이러한 이러한 방법 및 질문에서 승리 

305
00:21:21,329 --> 00:21:24,509
 우리의 가장 확률값은 진행에 대해 

306
00:21:24,509 --> 00:21:55,150
 이 방법은에 문제가 매우 가파른 길 당신은 아마하지 않으려한다 

307
00:21:55,150 --> 00:21:58,800
 자신 다운 그래서 어쩌면에서 그 방향으로 매우 빠르게 업데이트 할 말 

308
00:21:58,799 --> 00:22:02,220
 당신이 좋아하는 것 특히이 경우 빠른 이동하지만 당신은 가지에 읽고 

309
00:22:02,220 --> 00:22:05,019
 이 특정 예 그것은 일반적으로 이들의 진정한 종류 아니다 

310
00:22:05,019 --> 00:22:09,940
 어떤 네트워크가 좋은 전략의 구성되지 않은 최적화 풍경 적용 

311
00:22:09,940 --> 00:22:22,930
 처음에 이러한 경우에 

312
00:22:22,930 --> 00:22:25,730
 오 그런데 나는 17이 탐사를 통해 건너하지만 너희들은 할 수 

313
00:22:25,730 --> 00:22:30,380
 희망 (127)가 움직이는 0으로 나누기를 방지하기 위해 단지가 있음을 볼 수 

314
00:22:30,380 --> 00:22:34,550
 다시 높은 소유주에 일반적으로 우리는이 1 ~ 5 또는 6 ~ 7 개에 앉아 

315
00:22:34,549 --> 00:22:39,139
 시작하여 현금처럼 뭔가 그래서 다음에 올 수 0 

316
00:22:39,140 --> 00:22:46,540
 당신이 무엇을 얻을 당신의 생활 학습 속도 (22)이 적응 행동하지만 스케일입니다 

317
00:22:46,539 --> 00:22:50,420
 이 증류 그것의 절대 규모가 컨트롤에 아직도의 또는 

318
00:22:50,420 --> 00:22:57,370
 컨트롤은 여전히​​이 이야기는 단지 물건의 종류를 방해 속도를 배우고 

319
00:22:57,369 --> 00:23:00,989
 다른 프라이머 방법에 대해 상대적인 것 같은 더 볼 수 있습니다 

320
00:23:00,990 --> 00:23:12,190
 당신은 단계 동점 골을하지만 절대 글로벌 단계는 최대 아직있다 

321
00:23:12,190 --> 00:23:18,710
 아주 당신이 바로 설명하는 일을 매우 효율적으로부터의 

322
00:23:18,710 --> 00:23:23,038
 이 전 아주 긴 시간에서 재료의 종류를 얻기 위해 끝 때문에 

323
00:23:23,038 --> 00:23:27,750
 정말 시간 t에서의 발현은 지난 몇의 기능 만있어 

324
00:23:27,750 --> 00:23:36,480
 재료는하지만, 지수 함수 적으로 감쇠 가중 합에 우리가 갈거야 

325
00:23:36,480 --> 00:23:43,819
 다행 마지막 업데이트로 이동 

326
00:23:43,819 --> 00:24:03,039
 기하 급수적으로 가중 방식과 유사하고 그래서 당신은이 할 것 

327
00:24:03,039 --> 00:24:09,789
 나는 사람들을 생각하지 않습니다 또는이에 유한 창 정말 당신에게 나중에 할 수 있습니다 시도 

328
00:24:09,789 --> 00:24:19,889
 당신이 10 최적화 네트워크있을 때를 위해 그 X를 볼 것이다 너무 많은 메모리를 필요 

329
00:24:19,890 --> 00:24:23,560
 예되도록 240,000,000 매개 변수의 메모리가 꽤 많이 복용하고 그래서 

330
00:24:23,559 --> 00:24:29,659
 당신은 우리가있어 다음도 좋아 (10) 이전의 불만을 추적하고 싶지 않아 

331
00:24:29,660 --> 00:24:37,540
 거하면 성능이 저하 된 모멘텀을 결합하면 20 있는지에 가서 주셔서 감사합니다 

332
00:24:37,539 --> 00:24:45,269
 질문이 너무 너무 대충 무슨 일이 일어나고 있는지 슬라이드의 아담이을이다 

333
00:24:45,269 --> 00:24:49,119
 마지막 업데이트는 감옥 실제로 최근에 제안되었다 그리고있다 

334
00:24:49,119 --> 00:24:52,959
 당신이 기세를 알 수 있습니다로 모두의 요소는 가지의 트랙을 유지하고있다 

335
00:24:52,960 --> 00:24:57,190
 잘못된 그라디언트를 요약하여 독서의의 첫 번째 순서의 순간 

336
00:24:57,190 --> 00:25:02,350
 이 지수 일부와 손자를 유지하는 두 번째의 트랙을 유지하고 있습니다 

337
00:25:02,349 --> 00:25:07,869
 순간 기울기와 당신이 종료 아담 아담 업데이트 당신이와 끝까지이다 

338
00:25:07,869 --> 00:25:13,389
 기본적으로의 단계와 그것의 같은 종류의 것이 네 같은 종류의 수행 

339
00:25:13,390 --> 00:25:16,980
 조금 그래서 당신처럼 보이는이 일을 끝낼 가장 아마 모멘텀 

340
00:25:16,980 --> 00:25:21,650
 그것은 기본적으로 부패 방법이 속도를 추적 그리고 그건 

341
00:25:21,650 --> 00:25:25,420
 당신의 단계하지만 당신은이 기하 급수적까지 추가하여 아래로 확장 

342
00:25:25,420 --> 00:25:29,490
 새는 당신의 광장 그라디언트의 카운터 등 동일한에서 모두 끝 

343
00:25:29,490 --> 00:25:36,009
 공식과 사람들은 그래서 당신이 모두 힘을 다하고 않는 조합 그게 업데이트 및 

344
00:25:36,009 --> 00:25:41,759
 당신은 또한이 적응 스케일링을하고있는 그래서 여기에있는 군대의 확률값하자 

345
00:25:41,759 --> 00:25:44,789
 이를 비교했을 때 실제로 정말 심지어이 이전 버전을 번쩍해야 

346
00:25:44,789 --> 00:25:46,339
 기본적으로 가장 확률값 

347
00:25:46,339 --> 00:25:52,079
 빨간색은 여기에 우리가 대체 한 것을 제외하고는 동일한 것입니다 단지가 있었다 TX 

348
00:25:52,079 --> 00:25:56,220
 이전 단지 그라데이션 현재 지금 우리는이 그라데이션 TX를 교체하고 

349
00:25:56,220 --> 00:25:56,630
 그것으로 

350
00:25:56,630 --> 00:26:01,170
 예를 한 가지 방법에 대한 상상 그래서 만약 RDX이 실행 카운터 인 

351
00:26:01,170 --> 00:26:04,090
 또한 샘플링 많은 배치를 설정하여 불쾌한 kasich입니다 그것을 보면 

352
00:26:04,089 --> 00:26:07,359
 야이 나쁜 패스 난수의 많은 수 그리고 당신은이 모든 잡음을 얻을 수있어 

353
00:26:07,359 --> 00:26:10,990
 그라디언트 그래서 대신에 우리가있어 매번 단계를 어떤 큰 영향을 사용하여 

354
00:26:10,990 --> 00:26:14,309
 실제로 이전 인사의 일부가되었고, 그것을 할 수있는 사용하는 것 

355
00:26:14,309 --> 00:26:19,139
 그것의 그라디언트 방향을 안정시키고 그 기세의 기능입니다 

356
00:26:19,140 --> 00:26:23,720
 여기와 여기에 스케일링이 있는지 확인하는 것입니다 스텝 크기의 운동에 대하여 

357
00:26:23,720 --> 00:26:29,940
 서로 스티븐 L 방향이 감사에 당신은 당신이 것을 싶지 않아 

358
00:26:29,940 --> 00:26:31,269
 하이퍼 매개 변수 

359
00:26:31,269 --> 00:26:36,119
 (801)는 일반적으로 보통 9802 포인트 995 가리 

360
00:26:36,119 --> 00:26:42,869
 내 자신의 일에 선두에 걸쳐 높은 프리미엄을의 어딘가에있을 정도로 나는 발견 

361
00:26:42,869 --> 00:26:45,719
 내가 실제로 일반적으로하지 않습니다에 걸쳐이 상대적으로 강력한 설정입니다 

362
00:26:45,720 --> 00:26:50,690
 이러한 난 그냥 보통 스마일을 넣어으로 설정 떠나 결국하지만 당신은 재생할 수 있습니다 

363
00:26:50,690 --> 00:27:04,259
 당신이 추진력을 얻을 수 있습니다 그것의 사람들과 때때로 우리는 보았다 

364
00:27:04,259 --> 00:27:08,789
 그래 당신은 실제로 단지 용지를 읽을 수 않는 것이 레스토랑 작동 더 나은 청소 

365
00:27:08,789 --> 00:27:12,849
 실제로 어제는 종이 아니었다 대해이 229에서 프로젝트 보​​고서이었다 

366
00:27:12,849 --> 00:27:17,149
 나는 그것에 대해 용지가 있는지 모르겠어요하지만 당신이 할 수있는 것을 실제로 사람 

367
00:27:17,150 --> 00:27:20,250
 즉 단순히 여기에 수행되지 않습니다 놀이 

368
00:27:20,250 --> 00:27:25,759
 확인 나는 내가 여기에 아담이 약간 더 복잡하게 할 한 가지 더 

369
00:27:25,759 --> 00:27:30,849
 그것은 불완전 당신이 볼 정도로 나를 그냥 아담의 완전한 몰입에 넣어 보자 

370
00:27:30,849 --> 00:27:33,949
 당신이이 거기에 참조 할 때 혼동 될 수 있습니다 한가지 더있다 

371
00:27:33,950 --> 00:27:38,220
 바이어스 보정이라는 것은 자신의 삽입 및 수정을하는 방식을 경멸하는 

372
00:27:38,220 --> 00:27:40,920
 I는 루프의 확대 야하는 이유는 바이어스 보정가에 달려 있다는 

373
00:27:40,920 --> 00:27:46,940
 절대 시간 단계 00 T T 여기에서 사용되며, 그 이유는 이것이 무엇 

374
00:27:46,940 --> 00:27:49,730
 의 작은 점 같은 종류의 일을하고 나는 이것에 대해 혼동하지 않으 

375
00:27:49,730 --> 00:27:54,049
 너무하지만 기본적으로 그 MMV 사실을 보상하기위한 보상있어 

376
00:27:54,049 --> 00:27:58,659
 오니 쉬 (500) 통계는 처음에 잘못 그래서 그가 무엇을하고 있는지입니다 

377
00:27:58,660 --> 00:28:01,269
 정말 메가를 확장에서 

378
00:28:01,269 --> 00:28:04,250
 당신이 편견의 매우 친절와 끝까지하지 않도록 처음 몇 반복 

379
00:28:04,250 --> 00:28:07,359
 제 1 및 제 2 순간의 추정은 그래서 그것에 대해 걱정하지 마십시오 

380
00:28:07,359 --> 00:28:11,279
 너무 많은 이것은 단지이 매우 먼저 귀하의 업데이트를 변화한다 

381
00:28:11,279 --> 00:28:15,190
 항목 등으로의 몇 번 예열되고, 그래서는 적절한에서 이루어집니다 

382
00:28:15,190 --> 00:28:18,210
 통계 메가 측면에서 방법 

383
00:28:18,210 --> 00:28:23,380
 나는 우리가 여러 가지 업데이트에 대한 이야기​​ 그 확인으로 너무 많이 가지 않는다 

384
00:28:23,380 --> 00:28:26,710
 우리는 이러한 모든 업데이트가 여전히이 배우는 좋은 프라이머를 보았다 

385
00:28:26,710 --> 00:28:31,279
 그래서 난 그냥 여전히 필요하지만 것을 간략하게 사실에 대해 얘기하고 싶지 

386
00:28:31,279 --> 00:28:34,369
 학습과 우리 모두를위한 전면 인종 차별주의 학습 속도로 일어나는 보았다 

387
00:28:34,369 --> 00:28:37,639
 이러한 방법과 내가 제기하고자하는 질문을 다음의 어느 하나 

388
00:28:37,640 --> 00:28:47,290
 속도를 학습 사용하는 것이 가장 좋습니다 

389
00:28:47,289 --> 00:28:55,509
 당신이 신경 네트워크를 실행하는 경우 그래서 이것은 레이트 학습에 대한 슬라이드입니다 

390
00:28:55,509 --> 00:28:59,819
 트릭 답을 구분하는 것은 그 중에 무엇을 사용하는 좋은 학습 레이스가 없다는 것입니다 

391
00:28:59,819 --> 00:29:04,259
 이 최적화 때문에 당신은 당신이 먼저 높은 학습 속도를 사용해야한다해야 

392
00:29:04,259 --> 00:29:07,869
 좋은 학습 속도보다 더 빨리 당신이 매우 빠른 진전을 볼 수 있지만, 

393
00:29:07,869 --> 00:29:10,779
 어떤 점에서 두 확률 될거야 당신은에 수렴 할 수 없습니다 

394
00:29:10,779 --> 00:29:13,829
 주 내 아주 잘 당신이 시스템에 너무 많은 에너지를 가지고 있기 때문에 

395
00:29:13,829 --> 00:29:17,869
 당신은 당신의 손실 함수의 검은 좋은 부품 등 무엇으로 정착 할 수 없습니다 

396
00:29:17,869 --> 00:29:21,399
 당신은 당신이 속도 배우고 UDK는 다음 종류의이 탈 수 할 

397
00:29:21,400 --> 00:29:26,269
 감소 학습 속도의 드래곤과 그들 모두에 최선을 다할가 많다 

398
00:29:26,269 --> 00:29:28,670
 사람들이 시작하는 다른 방법은 시간이 지남에 따라 요금을 배울 당신은해야 

399
00:29:28,670 --> 00:29:32,400
 또한 같은 종류의 그들의 물건 붕괴의 과제가되었다 

400
00:29:32,400 --> 00:29:36,810
 당신이했습니다에 간단한 하나는 아마도 훈련 데이터의 한 시대는 참조 후 

401
00:29:36,809 --> 00:29:41,619
 파키스탄 새끼가 부패 무슨 말을 한 후 한 번에 너무 매 훈련 샘플을 볼 수 

402
00:29:41,619 --> 00:29:45,219
 내 포인트 9 또는 당신은 또한 사용할 수있는 뭔가에 요금을 학습 

403
00:29:45,220 --> 00:29:49,600
 지수 붕괴하거나 여러 거기 TDK 중 하나 여러가는거야 

404
00:29:49,599 --> 00:29:54,379
 그것은 가능성이 향상 이론적 특성의 일부에 확대하고있어 알고 

405
00:29:54,380 --> 00:29:58,260
 내가 생각하기 때문에 서로 다른 경우에 대한 그들의 불행하게도 많은하지 적용 

406
00:29:58,259 --> 00:30:01,150
 그들은 볼록 최적화 문학에서 대부분이고 우리는 매우 상대하고 

407
00:30:01,150 --> 00:30:05,160
 목표 다르지만 일반적으로 실제로 나는 뭔가에 사용되는 

408
00:30:05,160 --> 00:30:12,330
 질문이었다 

409
00:30:12,329 --> 00:30:25,259
 훈련 동안 이들 사이의 어느 하나의 커밋되지 

410
00:30:25,259 --> 00:30:28,470
 그래, 난 그 모든 표준 생각하지 않습니다 

411
00:30:28,470 --> 00:30:32,990
 흥미로운 점 나는 당신이 그래 사용할 줄 때 확실하지 않다 확실하지 않다 

412
00:30:32,990 --> 00:30:37,839
 그것은 나에게 분명하지 않다 당신이 시도하고 I가 좋아 연습 뭔가를 시도 할 수 있습니다 

413
00:30:37,839 --> 00:30:42,079
 적어도 영향은 바로 지금이다 당신은 거의 항상 내가 발견 지점을 

414
00:30:42,079 --> 00:30:46,189
 일반적으로 좋은 기본값은 지금 모든 것을 위해 시간을 사용하므로 함께 갈 장미 

415
00:30:46,190 --> 00:30:49,840
 아주 잘 우리의 대부분의 문제는 모멘텀보다 더 나은 또는 작동하는 것 같다 

416
00:30:49,839 --> 00:30:56,638
 그들 때문에 우리가 그들에게 전화로 그런 아무것도 그래서 키가 큰 주문 방법이다 

417
00:30:56,638 --> 00:31:00,579
 우리가 평가 한 있도록 만 손실 함수에 그라디언트 정보를 사용하여 

418
00:31:00,579 --> 00:31:03,720
 그라데이션은 우리가 기본적으로 기울기와 모든 단일 방향을 알고 

419
00:31:03,720 --> 00:31:05,710
 즉, 우리가 사용하는 유일한 것이다 

420
00:31:05,710 --> 00:31:09,600
 이 최적화를위한 2 차 방법의 전체 세트입니다하지만 당신은해야 

421
00:31:09,599 --> 00:31:13,168
 내가 너무 많은 세부 사항에 가고 싶지 않는 2 차 반대의 인식 

422
00:31:13,169 --> 00:31:17,919
 그러나 결국 최대 그래서 당신의 손실 함수에 더 큰 근사치를 형성 

423
00:31:17,919 --> 00:31:20,820
 그들 만이 기본적으로 초평면에 근사하지 않는 방법 I 등 

424
00:31:20,819 --> 00:31:26,069
 희망하지만 당신도 토론에 의해 근사 한을 알리는 방법입니다 

425
00:31:26,069 --> 00:31:29,710
 그래서 당신은 그가 또한 독일인 필요한 그라데이션이 필요하지 않습니다 억제 서비스 

426
00:31:29,710 --> 00:31:36,808
 뿐만 아니라 그 계산해야하고 당신에게 내가 말할 것 오늘 밤에 볼지도 모른다 

427
00:31:36,808 --> 00:31:38,500
 229 예 

428
00:31:38,500 --> 00:31:44,190
 뉴턴의 방법은 기본적으로 당신이 그릇을 형성 업데이 트를주고 

429
00:31:44,190 --> 00:31:47,259
 당신의 목적에 같은 패션 근사이 업데이트 사용할 수 있습니다 

430
00:31:47,259 --> 00:31:54,259
 수는 그래서 그 근사 방식의 최소로 직접 이동합니다 

431
00:31:54,259 --> 00:31:58,490
 어떤이 그들을 사용된다 사람을 왜 2 차 방법에 대한 좋은 데요 

432
00:31:58,490 --> 00:32:02,099
 특히 뉴턴 방법은 이것에 대해 좋은 무엇을 여기에 제시 

433
00:32:02,099 --> 00:32:05,399
 컨버전스에 대한 업데이트 

434
00:32:05,400 --> 00:32:13,410
 당신은 학습 속도가 확인이 업데이트의 방법 차 알지 알 수 있습니다 그리고 그건 

435
00:32:13,410 --> 00:32:17,220
 이 손실 기능이 손실 함수에 그라데이션을 보는 경우에 있기 때문에 

436
00:32:17,220 --> 00:32:20,480
 당신은 또한 곡률과 그 장소를 알고 당신은 근사 그렇다면 

437
00:32:20,480 --> 00:32:23,920
 정확히 알고있는이 황소는 어디에 때문에 최소 주문 근사치로 이동합니다 

438
00:32:23,920 --> 00:32:26,900
 그의 최소로 직접 이동할 수 있습니다 당신 학습을위한 필요가 없습니다 

439
00:32:26,900 --> 00:32:30,610
 그게 내가 그 생각 아주 좋은 기능 그래서 그릇에 근접하면 두 가지가 I 

440
00:32:30,609 --> 00:32:32,969
 당신은 두 번째 순서를 사용하고 있기 때문에 생각했던 당신은 빠른 수렴을 

441
00:32:32,970 --> 00:32:38,839
 뿐만 아니라 정보가 왜이 단계 업데이트를 사용하도록 종류의 불가능하다 

442
00:32:38,839 --> 00:32:47,069
 과정의 문제에 대한 작품을 모든되는 교육 열정은 백을 말한다 

443
00:32:47,069 --> 00:32:48,500
 만 기본 네트워크 

444
00:32:48,500 --> 00:32:52,299
 백 만 백 만 행렬 그리고 당신은 그것을 변환 할 

445
00:32:52,299 --> 00:32:59,259
 그이 너무 행운 그래서 몇 가지가 발생하지 않을 

446
00:32:59,259 --> 00:33:02,480
 알고리즘과 난 그냥 당신이 당신이 그들을 사용하지 않을 알고 싶습니다 

447
00:33:02,480 --> 00:33:05,650
 기본적으로 뭔가 불리는 곳 DHS하는 아래 클래스 

448
00:33:05,650 --> 00:33:08,360
 수 있습니다 당신은 패션을 변환하지 멀리 얻을 구축 

449
00:33:08,359 --> 00:33:11,819
 모든 순위 연속 업데이트를 통해 헤센의 근사 

450
00:33:11,819 --> 00:33:15,000
 하나는 그것의 종류의 세션을 구축하지만 당신은 여전히​​ 헤 시안을 저장해야 

451
00:33:15,000 --> 00:33:18,279
 대규모 네트워크에 대한 다음 거기에 뭔가 더 좋은 때문에 여전히 메모리에 

452
00:33:18,279 --> 00:33:22,710
 제한 제레미 BFGS의 약자라는 파운드 실제로 가을에 저장되지 않았습니다 

453
00:33:22,710 --> 00:33:26,980
 패션 아니면 근사 회원 그리고 그 사람들이 실제로 사용하는 무엇을 

454
00:33:26,980 --> 00:33:33,549
 때로는 지금 당신은 때때로 최적화 문헌에 언급 참조합니다 LBS 

455
00:33:33,549 --> 00:33:37,769
 그것은 우리를 위해 정말 정말 잘 작동 특히 당신은 작은 하나가있는 경우 

456
00:33:37,769 --> 00:33:42,450
 이처럼 상자 같은 결정 기능에는 확률 적 노이즈가 없습니다 

457
00:33:42,450 --> 00:33:47,920
 과 모든 것을 더 도시는 일반적으로 손실을 분쇄 할 수 있습니다 메모리 주소에 맞는 없다 

458
00:33:47,920 --> 00:33:53,200
 기능을 아주 쉽게 그러나 아주 아주 기본적 파운드 GS2을 연장으로 까다로운 

459
00:33:53,200 --> 00:33:56,539
 대규모 데이터 세트 및 이유는이 많은 의사를 서브 샘플링 하였다된다 

460
00:33:56,539 --> 00:33:59,730
 우리는 많은 그래서 WASSUP에 간단한 메모리에 모든 훈련 데이터를 맞지 않을 수 있기 때문에 

461
00:33:59,730 --> 00:34:02,930
 배치는 다음 나는이 많은 경기와에 작품의 위험이있을거야 그 

462
00:34:02,930 --> 00:34:06,810
 근사는 서로 다른 여러 배치를 교환하고 같이있는 잘못에 

463
00:34:06,809 --> 00:34:10,449
 또한 당신이 조심해야 할 능력을 가지고 당신은 확인해야합니다 

464
00:34:10,449 --> 00:34:12,539
 당신이 드롭 아웃을 수정해야 

465
00:34:12,539 --> 00:34:17,690
 당신이 있는지 확인해야하므로 내부적으로 불량배이기는하지만 함수 당신의 

466
00:34:17,690 --> 00:34:20,679
 기능 많은 많은 다른 시간이 모든 근사하고 거짓말을하고있다 

467
00:34:20,679 --> 00:34:24,480
 검색 물건이 매우 무거운 함수의 같은 것을 그래서 당신은 확인해야합니다 

468
00:34:24,480 --> 00:34:26,668
 당신이 사용할 때 사용하지 않거나 출처 확인 

469
00:34:26,668 --> 00:34:29,889
 랜덤 정말 연습 우리에 그래서 기본적으로 그것을 좋아하지 않을 때문에 

470
00:34:29,889 --> 00:34:33,779
 큰 잘 못했습니다 정말 일을하지하지 않는 것 때문에 모든 BHS를 사용하지 않는 

471
00:34:33,780 --> 00:34:36,970
 지금은 다른 방법에 비해 너무 많은 재료가 갖는 기본적 

472
00:34:36,969 --> 00:34:41,529
 일이 당신이 더 나은 것은 바로이 우리의 물건을 잡음을하지만 이상을 수행합니다 

473
00:34:41,530 --> 00:34:47,880
 당신이 할 수있는 경우 그 거래는 좋은 선택으로 사용 요약 그렇게 꺼져과 

474
00:34:47,880 --> 00:34:51,570
 그렇지 않은으로 당신이 아마 하루에 은행 감당할 수있는 여유 

475
00:34:51,570 --> 00:34:55,419
 2009 메모리와 앞으로 매우 큰 소득과 그들에 패스를 얻을 

476
00:34:55,418 --> 00:35:00,460
 메모리 당신은 파운드로 볼 수 있지만에서 사용 관행에 표시되지 않습니다 

477
00:35:00,460 --> 00:35:05,220
 현재 연구 방향 비록 지금 바로 대규모 설정 

478
00:35:05,219 --> 00:35:10,009
 당신이이기 때문에 그래서 다른 개인 업데이트의 제 논의를 결론 

479
00:35:10,010 --> 00:35:14,830
 학습 속도는 우리가 거​​기에이 클래스의 모든 베아트리체 조사하지 않을거야 

480
00:35:14,829 --> 00:35:24,739
 바로 다시 질문 

481
00:35:24,739 --> 00:35:34,609
 당신에 대한 요구하는지 너무 좋은 자동으로 당신이있어 구분 예를 들어 

482
00:35:34,610 --> 00:35:38,510
 그래서 시간이 지남에 속도를 학습 당신은 또한 당신이 있다면 사건을 깰 학습 사용합니다 

483
00:35:38,510 --> 00:35:41,930
 그래서 일반적으로 그랜드 이상을 사용하면 때를 매우 일반적인 영기를 배우는 참조 

484
00:35:41,929 --> 00:35:55,379
 실제로 나는 당신이 대학원 또는 그러나 그것을 사용하는 경우 확실하지 않다 또는 아담 그래 그것은 아닙니다입니다 

485
00:35:55,380 --> 00:36:04,900
 하지 아니 아주 좋은 대답 당신은 그것을 할 확실히 할 수 있지만 어쩌면 항목이 아니라고 

486
00:36:04,900 --> 00:36:08,910
 아담처럼 그냥 방자 안드로이드 때문에에서 학습 (30)를하지 않습니다 

487
00:36:08,909 --> 00:36:12,339
 이 새는 그라데이션입니다하지만 그는 학습 속도가 된 큰 우려했다 

488
00:36:12,340 --> 00:36:15,170
 그것은 인도 자동으로 20을 부패 있기 때문에 아마 이해가되지 않습니다 

489
00:36:15,170 --> 00:36:22,710
 괜찮아 괜찮아 우리는 매우 간단하게 같은 모델 앙상블 I에 갈거야 

490
00:36:22,710 --> 00:36:24,829
 그것은 아주 간단하기 때문에 그것에 대해 얘기 

491
00:36:24,829 --> 00:36:28,750
 당신이 당신의 훈련 데이터에 여러 개의 독립적 인 모델을 훈련하면 밝혀 

492
00:36:28,750 --> 00:36:32,949
 대신 다음 단 하나의 하나의 당신은 당신이했습니다이 시간에 결과를 평균 

493
00:36:32,949 --> 00:36:39,929
 항상 22 % 추가 성능 확인 지금이 정말 이론적하지있어 

494
00:36:39,929 --> 00:36:43,289
 그 결과 같은 종류의하지만 그냥 연습처럼 여기 결과 

495
00:36:43,289 --> 00:36:46,570
 기본적으로이 거의 항상 더 잘 작동 할 좋은 것 같다 

496
00:36:46,570 --> 00:36:48,850
 물론 단점은 모든 다른 독립이 필요하지 않습니다 

497
00:36:48,849 --> 00:36:52,259
 모델과 앞으로해야 할 필요와 그들과 여러분의 뒤로 클래스 

498
00:36:52,260 --> 00:36:56,850
 그 적합하지 그래서 그들 모두를 훈련 아마 당신은 아래로 느려했다 

499
00:36:56,849 --> 00:37:00,989
 당신의 앙상블 모델의 수와 단지 시간 등 몇 가지 팁이있다 

500
00:37:00,989 --> 00:37:05,689
 및 유용한 정보 비트를위한 그래서 하나의 접근 방식을 따기 어떤 종류의에 사용 

501
00:37:05,690 --> 00:37:08,619
 예를 들어 당신이 가진 당신이 당신의 신경망을 훈련으로 모든 서로 다른를 

502
00:37:08,619 --> 00:37:11,680
 체크 포인트는 일반적으로 체크 포인트를 저장 그들에게 하나 하나 하키를 저장하는 

503
00:37:11,679 --> 00:37:14,750
 당신은 당신이 당신의 검증 성능 그래서 한 가지 당신이 무엇인지 알아낼 

504
00:37:14,750 --> 00:37:18,119
 실제로 판명 예를 위해 할 수있는 것은 때로는 같은 얻을 당신입니다 

505
00:37:18,119 --> 00:37:23,420
 당신의 모델에 대한 몇 가지 체크 포인트를 가지고 당신은 그했다 그 

506
00:37:23,420 --> 00:37:26,349
 실제로 때때로에서 사물과 그렇지 그래서 방법을 개선하기 위해 밝혀 

507
00:37:26,349 --> 00:37:29,730
 한 미국 훈련 칠 독립적 인 모델을 훈련해야하지만 당신은 어떤 앙상블 

508
00:37:29,730 --> 00:37:34,809
 그와 관련된 다른 체크 포인트의 트릭있다 

509
00:37:34,809 --> 00:37:39,739
 이것은 우리가 전에 본 적이 당신의 네 단계를 여기에 무슨 일이 일어나고 있는지에 항의 

510
00:37:39,739 --> 00:37:44,709
 나는 실행으로 여기에 예비 선거 X 테스트의 또 다른 세트와이 텍스트를 유지하고있어 

511
00:37:44,710 --> 00:37:49,590
 일부 기하 급수적으로 내 실제 매개 변수 벡터 X를 썩 때 내가 사용하는 

512
00:37:49,590 --> 00:37:52,750
 텍스트 테스트 및 검증이나 테스트 데이터는 거의 항상이 밝혀 

513
00:37:52,750 --> 00:37:57,199
 이 때문에 종류의 같이하고있는 단독 확인 X를 사용하는 것보다 약간 더 나은 수행 

514
00:37:57,199 --> 00:38:00,919
 마지막으로 이전 몇 주 요인 작은 같은 가중 앙상블 그것은 종류의 

515
00:38:00,920 --> 00:38:05,309
 어려운 종류의 한 가지 방법으로 실제로는하지만, 기본적으로 해석하는 

516
00:38:05,309 --> 00:38:08,329
 그것을 나는이 실제로 할 수있는 좋은 일이 이유에 대해 처리 할 수​​있는 하나의 방법을 해석 

517
00:38:08,329 --> 00:38:12,900
 당신의 공 기능을 최적화에 대해 생각하고, 당신은 너무 많은 스테핑있어 

518
00:38:12,900 --> 00:38:16,849
 실제로 모든 단계의 평균을 복용 최소 당신을 얻을 수 주위에 

519
00:38:16,849 --> 00:38:20,980
 I가 할 수있는 최소한의 확인에 가까운이 실제로 약간 중요한 이유 

520
00:38:20,980 --> 00:38:25,639
 더 나은 우리가 가고 있기 때문에 내가 가진 작은 앙상블은 내 인생을 논의하기 위해 수 있도록 

521
00:38:25,639 --> 00:38:29,759
 드롭 아웃으로 보면 이것은 당신이 될 것입니다 매우 중요한 기술이다 

522
00:38:29,760 --> 00:38:34,590
 드롭 아웃에 대한 생각은 매우 흥미로운 그래서 등등 구현 및 사용 

523
00:38:34,590 --> 00:38:38,620
 당신의 전체 목적을하고있는 것처럼 당신이 강하와 함께 할 당신입니다 

524
00:38:38,619 --> 00:38:45,429
 신경 네트워크는 무작위 그래서 그냥 통과 공원에서 일부 뉴런 (20)을 설정합니다 

525
00:38:45,429 --> 00:38:49,839
 당신이 당신의 데이터 X의 전진 패스를하고있는 당신이 어떤 작업을 수행하는지 명확히하는 것은 당신의 

526
00:38:49,840 --> 00:38:52,670
 이 기능에 발언권을 계산 

527
00:38:52,670 --> 00:38:57,010
 첫 번째 숨겨진 층 W의 비선형 하나 배 XP SP1 그래서 

528
00:38:57,010 --> 00:39:02,830
 그건 좀 이상이고 다음 여기 이진수의 마스크를 계산합니다 

529
00:39:02,829 --> 00:39:05,230
 여부에 기초하여 0 또는 1 중 

530
00:39:05,230 --> 00:39:09,469
 0과 1 사이 숫자는 우리가 심각한 펌프를 듣고있는 P보다 작은 

531
00:39:09,469 --> 00:39:13,469
 당신이 원하는이 우리는 0과 1의 절반과 절반의 바이너리 마스크입니다 

532
00:39:13,469 --> 00:39:17,469
 다중 정품 인증 적극적으로 우리가 그들의 절반을 포기 숨겨진되는 

533
00:39:17,469 --> 00:39:21,349
 모든 정품 인증 각 하나의 숨겨진 레이어를 계산 한 다음 우리는 두 가지가 드롭 

534
00:39:21,349 --> 00:39:25,730
 무작위로 유닛, 그리고, 우리는 두 번째, 그리고, 우리는 무작위로 그 중 절반을 드롭 할 

535
00:39:25,730 --> 00:39:30,699
 확인 물론 이것은 단지 전방이 후방 패스이어야 합격입니다 

536
00:39:30,699 --> 00:39:35,719
 적절하게이 방울도 다시 전파 할 수 있도록뿐만 아니라 조정 

537
00:39:35,719 --> 00:39:39,309
 그것에서뿐만 아니라, 그래서 그렇게 통해 구현할 때 중퇴 그렇게 기억 

538
00:39:39,309 --> 00:39:41,980
 전진은 드롭을 통과하지만, 역 전파는 경우 후방 패스 

539
00:39:41,980 --> 00:39:45,829
 U2에 의해 곱하면 하나는 그래서 당신이 장소에서 기본적으로 생기를 죽인를 구입 

540
00:39:45,829 --> 00:39:46,559
 당신은 떨어 곳 

541
00:39:46,559 --> 00:39:52,179
 나는이 방법을 처음으로 당신이를 보였다 때 확인 그래서 당신은 생각 될 수 있습니다 

542
00:39:52,179 --> 00:39:56,799
 이 전혀 이해가 않습니다이 좋은 생각은 왜에 어떻게 원하는 것이되었다 

543
00:39:56,800 --> 00:40:00,390
 당신의 신경증을 계산하고 (20)이 어떠한 의미를에 다음 그들에게 경향을 설정 

544
00:40:00,389 --> 00:40:12,369
 그래서 나도 몰라 그럼 이제 너희들은 앞서 생각에 과열을 방지 할 수 있도록하자 

545
00:40:12,369 --> 00:40:23,880
 어떤 의미 

546
00:40:23,880 --> 00:40:27,170
 당신은 정말 당신이 그것을 할 말을하는지 있도록 올바른 정보를 얻고 

547
00:40:27,170 --> 00:40:31,240
 난 단지 그때 내 네트워크의 절반을 거​​의 사용하고있는 경우 때문에 overfitting을 방지 

548
00:40:31,239 --> 00:40:34,500
 난 단지 내 네트워크를 한 번의 절반을 사용하고 작은 용량의 같은이 

549
00:40:34,500 --> 00:40:37,739
 하나의 작은 네트워크 I 기본적으로 만 너무 거기에있어 단지처럼 거기 

550
00:40:37,739 --> 00:40:40,209
 이 종류의 그래서 나는 다음 전체 네트워크 거기에 직장에서 무슨 일이 있었는지 수행 할 수 있습니다 

551
00:40:40,210 --> 00:40:44,798
 당신이 대표 할 수 있는지의 관점에서 당신의 분산 제어 등 

552
00:40:44,798 --> 00:40:55,619
 그래 나는 종종 내가하지 않은 다양한 무역에 의해 등의 조건을 충족하고 싶습니다 

553
00:40:55,619 --> 00:40:59,480
 정말 우리는 너무 많이하지 않을거야하지만 힘들다는 더 작은 모델을 

554
00:40:59,480 --> 00:41:08,579
 그 이상하지만 서로 다른 신경 네트워크의 여러 앙상블을 갖는 것은 가고 있었다 

555
00:41:08,579 --> 00:41:34,289
 즉 사용 된 하나의 경우 때문에 조금에 그 시점으로 이동 

556
00:41:34,289 --> 00:41:38,119
 위층 확인 내 다음 인생에서 가리 말씨의 더 나은 방법이 

557
00:41:38,119 --> 00:41:43,028
 의 그 괜찮아 우리가하려고하는 것을 가정하는 특정 예를 살펴 보자 

558
00:41:43,028 --> 00:41:47,130
 신경 네트워크의 고양이 점수를 계산하고 여기에 아이디어는 것입니다 

559
00:41:47,130 --> 00:41:51,380
 이러한 모든 다른 단위를 가지고 강하하고있는 스포츠는 많은 노래 

560
00:41:51,380 --> 00:41:54,920
 방법은 드롭 아웃을보고 있지만 그 중 하나는 당신의 코드 당신의 강요 것입니다 

561
00:41:54,920 --> 00:41:59,608
 어떤 이미지의 표현은 당신이 필요로하기 때문에 중복하고 있었다 

562
00:41:59,608 --> 00:42:03,318
 그 중복 당신은 당신이 절반을받을 제어 할 수있는 방법에 대해이기 때문에 

563
00:42:03,318 --> 00:42:06,710
 네트워크의 내려 그래서 당신은 더 많은 당신의 고양이 점수를 확인해야합니다 

564
00:42:06,710 --> 00:42:09,900
 기능은 제대로 요리 고양이 점수 때문에를 계산하기 위하여려고하는 경우 

565
00:42:09,900 --> 00:42:14,000
 어떤 어떤이 삭제 될 수도 있기 때문에 당신이 그것에 의존 할 수 그들 중 하나 등등 

566
00:42:14,000 --> 00:42:17,068
 이 경우 우리는 여전히 캐츠 킬을 분류 할 수 있도록 그게 보는 하나의 방법입니다 

567
00:42:17,068 --> 00:42:22,639
 우리는 매우 중요 그래서 여부에 대한 액세스 권한이없는 경우에도 적절 

568
00:42:22,639 --> 00:42:24,768
 즉, 드롭 아웃의 하나의 해석이다 

569
00:42:24,768 --> 00:42:29,088
 드롭 아웃의 또 다른 해석은 다음과 같이 근육의 관점에서 언급되어, 

570
00:42:29,088 --> 00:42:33,358
 드롭 아웃 효과적으로 모델의 큰 앙상블 훈련으로 바라 보았다 될 수있다 

571
00:42:33,358 --> 00:42:36,420
 기본적으로 서브되는 

572
00:42:36,420 --> 00:42:43,099
 하나의 큰 네트워크는하지만, 그들은 당신이 그렇게 좋은 방식으로 예비 선거를 공유 할 수 없습니다 

573
00:42:43,099 --> 00:42:46,650
 이것을 이해하면 우리는 우리와 우리를 위해 그것을 할 경우 다음 사항을주의해야 

574
00:42:46,650 --> 00:42:49,970
 무작위로 무엇을 생각 뒤로 패스에 비해 단위의 일부를 내려 

575
00:42:49,969 --> 00:42:53,669
 나는 우리가 임의의이 내려 가지고 가정 오른쪽도록 그라데이션 발생 

576
00:42:53,670 --> 00:42:57,409
 후방 패스에서 이러한 단위는 우리가 다시 최대를 통해 전파하고 그 

577
00:42:57,409 --> 00:43:01,879
 했다 특히 만 뉴런의 수 있도록 드롭 아웃에 의해 유도 된 

578
00:43:01,880 --> 00:43:05,349
 전진 패스에 사용 실제로 업데이트 또는 불만이 흐르는이됩니다 

579
00:43:05,349 --> 00:43:09,599
 차단 된 모든 신경 세포가 20 아니 그라디언트 흐름 없기 때문에 그들을 통해 

580
00:43:09,599 --> 00:43:13,650
 그것과 이전 계층의 무게를 너무 업데이트되지 않습니다 

581
00:43:13,650 --> 00:43:18,550
 적극적으로 더 이상 그에 이전 계층으로의 연결을 중퇴했다 

582
00:43:18,550 --> 00:43:22,750
 업데이트 그냥했다 그렇게 정말 무엇을이없는 것처럼 그건되지 않습니다 

583
00:43:22,750 --> 00:43:27,230
 당신의 신경 네트워크의 일부를 샘플링 마스크 하위 오프 삭제하고 만있어 

584
00:43:27,230 --> 00:43:30,789
 교육 당신이 일이 발생할 것이 그 하나의 예에 신경 네트워크 

585
00:43:30,789 --> 00:43:44,980
 시간의 점은 하나의 모델은 하나의 데이터 포인트에 비가 가져옵니다 있도록 

586
00:43:44,980 --> 00:43:51,250
 확인을 나는 것을 반복 시도 할 수 있습니다 

587
00:43:51,250 --> 00:44:04,239
 여기 어딘가에에서 온 너희들이 아닌지를 이해하려면 

588
00:44:04,239 --> 00:44:10,789
 당신이 당신의 자신의 드롭 드롭을 삭제할 때 확인 그래서 내가이의 예 있었으면 좋겠다 

589
00:44:10,789 --> 00:44:14,429
 내가 곱 값에 드롭하면 신경 세포의 오른쪽하지만 최대 09 그 효과를 구입 

590
00:44:14,429 --> 00:44:17,918
 손실의 기능에 영향은 경사 (10)가 있기 때문에 바로 그래서이 없다 

591
00:44:17,918 --> 00:44:21,668
 그는 손실을 계산에 사용하고 그래서 안되었다에 대한 가중치는을받지 않습니다 

592
00:44:21,668 --> 00:44:25,679
 업데이트 우리는 네트워크의 일부를 표본했는데 것처럼 그래서 우리의 단지 열차 

593
00:44:25,679 --> 00:44:28,959
 현재 만에 훈련과 네트워크 나니 하나의 데이터 포인트 

594
00:44:28,958 --> 00:44:32,348
 모든 시간 우리의 가능성 표본이 다른 부분을 위해 그것을 할 당신의 

595
00:44:32,349 --> 00:44:35,899
 신경망하지만 이상한 같은 종류의 그래서 그들은 모두 공유 매개 변수 

596
00:44:35,898 --> 00:44:39,778
 다른 모델의 많은 모든 교육의 앙상블 월요일이 점하지만 그들은 모두 

597
00:44:39,778 --> 00:44:48,458
 공유 매개 변수 즉 이해가되지 않습니다 여기 종류의 약 아이디어 그래서 

598
00:44:48,458 --> 00:45:07,108
 일반적으로 50 %이이 그렇게 동일한 크기를 발생하는 매우 거친 방법 저장 

599
00:45:07,108 --> 00:45:09,798
 세계의 힘은 우리가 실제로 컴퓨터 H 알 

600
00:45:09,798 --> 00:45:14,009
 우리는 우리가했던 것처럼 컴퓨터의 모든 전에를 계산하는 것이 더의 절반 이상 

601
00:45:14,009 --> 00:45:17,119
 값은 20 떨어졌다 얻을 것이다 

602
00:45:17,119 --> 00:45:29,250
 아무것도 그들이 좋은거야 변경되지 않습니다 

603
00:45:29,250 --> 00:45:38,349
 대신 문제에 대한 경쟁 역은 도로에서 경쟁 할 

604
00:45:38,349 --> 00:45:42,150
 당신은 당신이 할 수 있도록 스포츠 업데이트를 수행 할 경우에 삭제되지 않습니다 

605
00:45:42,150 --> 00:45:44,950
 하지만 이론적으로 나는 실제로 우리가 걱정하지 않는 이상한 생각하지 않습니다 

606
00:45:44,949 --> 00:46:12,369
 너무 많이하고 그래서 항상 돼 작업 훈련 그래서 매일 반복 우리를 

607
00:46:12,369 --> 00:46:15,469
 우리가 거​​ 드롭하는지에 대해 우리가 샘플 분 경기 또는 노이즈 패턴을 얻을 

608
00:46:15,469 --> 00:46:19,359
 앞으로 가고, 뒤로 패스와 그라데이션 우리는이 이상을 선회 계속 

609
00:46:19,360 --> 00:46:31,360
 또 다시 그래서 당신의 질문에 어떻게 든 영리 사실 바이너리 마스크처럼 

610
00:46:31,360 --> 00:46:35,829
 최고의 정말 안되지 않은 모델 또는 뭔가를 최적화하는 방법 등 

611
00:46:35,829 --> 00:46:44,769
 이루어집니다 또는 누군가가 내가 그래 내가 갈거야 너무 미안 들여다했다고 생각 

612
00:46:44,769 --> 00:46:47,389
 하나의 슬라이드 다음 슬라이드에 해당 들어가 

613
00:46:47,389 --> 00:46:57,618
 우리는이 시점에서 볼거야 나는 마지막 질문을 할게요 

614
00:46:57,619 --> 00:47:04,519
 질문 하나 다른 레이어에 다른 양에게 드롭을 수행 할 수 있습니다 

615
00:47:04,518 --> 00:47:05,459
 당신을 중지 아무것도 없다 

616
00:47:05,460 --> 00:47:09,338
 그 직관적으로 당신은 당신이 더 필요하면 밖으로 강한 드롭을 적용 할 

617
00:47:09,338 --> 00:47:12,690
 정규화 그렇게 볼 수 Primaris의 엄청난 금액을 갖는 층 거기 

618
00:47:12,690 --> 00:47:16,349
 하나의 예에있어 소득 당신은 거기에 강한 하락에 의해 명중 할 

619
00:47:16,349 --> 00:47:20,269
 반대로 우리가 어떤 네트워크의 초기에 볼 수 있습니다 몇 가지 레이어가있을 수 있습니다 

620
00:47:20,268 --> 00:47:24,248
 코미디 쇼 층은 그가 정말 많은 드롭을 연주하지 않는 매우 작은 

621
00:47:24,248 --> 00:47:27,368
 거기에 조금이가는 컬러 네트워킹은 예를 들어 아주 흔한 일 

622
00:47:27,369 --> 00:47:30,740
 당신은 그 대답은 그래서 낮은 드롭 아웃 시간이 지남에 끝나는로 시작 

623
00:47:30,739 --> 00:47:38,848
 예 내가 두 번째 질문은 당신이 대신 단위 그냥 드롭 아웃 할 수 잊었다 

624
00:47:38,849 --> 00:47:41,880
 당신이 할 수 있고 그 뭔가라고 각각의 가중치는 우리가 원하는 연결 삭제 

625
00:47:41,880 --> 00:47:46,349
 이 클래스에서 너무 많이 들어가 있지만,뿐만 아니라 내가 가진 것을 할 수있는 방법이있다합니다 

626
00:47:46,349 --> 00:47:52,829
 지금은 내가 당신을 우리는이 모든 것을 도입했습니다되어 수행 할 작업을 이상적으로 신뢰하는 시간이야 

627
00:47:52,829 --> 00:47:56,940
 바로 공원으로 노이즈가 통과하고 그래서 당신은 단지 시간과 지금 좋아하면 

628
00:47:56,940 --> 00:48:00,349
 우리는 모든 소음을 통합하고 근사를 좋아 하죠하려는 싶습니다 

629
00:48:00,349 --> 00:48:03,318
 그 뭔가를 것에 당신은 당신이 분류하려면 테스트 이미지를 가지고있는 것처럼 

630
00:48:03,318 --> 00:48:06,909
 당신이 할 수있는 많은 전진은 바이너리 마스크의 다양한 설정으로 전달 

631
00:48:06,909 --> 00:48:10,558
 당신은 단지 서브 네트워크를 사용하고 모든 걸쳐 평균 수 

632
00:48:10,559 --> 00:48:14,329
 그래서 그 아마 배포판은 중대하지만 불행히도 아닌 것 

633
00:48:14,329 --> 00:48:17,818
 매우 효율적 그래서 당신이 실제로이 과정을 근사 할 수 있습니다 밝혀 

634
00:48:17,818 --> 00:48:22,338
 첫 번째 드롭 아웃과 방법을 도입 할 때 어느 정도는 지적 주신 

635
00:48:22,338 --> 00:48:26,170
 당신이 당신의 신경 세포 모두 당신을 활용하고자 직관적으로이 작업을 수행합니다 

636
00:48:26,170 --> 00:48:29,509
 내 무작위 우리가 길을 복사하려고거야 떨어지고 싶지 않아 우리 

637
00:48:29,509 --> 00:48:33,548
 몰라 A의 전진 패스에서 드롭 그래서 온 모든 신경을 남길 수 있습니다 

638
00:48:33,548 --> 00:48:39,920
 테스트 이미지 그러나 우리는 실제로 우리가 이것을 어떻게 우리가 그렇게 할 수 조심해야 

639
00:48:39,920 --> 00:48:43,480
 가난한 우리가 어떤 단위를 드롭하지 않을거야 테스트 이미지를 전달하지만 우리는이 

640
00:48:43,480 --> 00:48:48,028
 얻을 것을 기본적으로 하나의 방법에주의하는 그 무엇 

641
00:48:48,028 --> 00:48:54,880
 문제는 이것이이란과의있어 두 개의 입력이었다고 생각 나는 생각한다 

642
00:48:54,880 --> 00:48:59,079
 이 시간에 존재하는 모든 입력을 그래서 우리는 그렇게 단위를 포기하지 않을 것을 

643
00:48:59,079 --> 00:49:02,630
 이들 두 사람은 가까운 일부 활성화 및 다른 의사가 시간이야 

644
00:49:02,630 --> 00:49:06,400
 컴퓨터는이 비교 아직 어떤 값 세금이 될 수 있습니다 

645
00:49:06,400 --> 00:49:12,608
 훈련 시간 동안 것 뉴런 밖으로 무엇을하지만 X이 값 

646
00:49:12,608 --> 00:49:18,440
 이 때문에 드롭 아웃 마스크 매우 무작위 등 교육 시간에 확인 기대 

647
00:49:18,440 --> 00:49:21,170
 어떤 다른 일어날 수있는 여러 가지 경우가있다 

648
00:49:21,170 --> 00:49:27,068
 이들 경우 다른 규모가 될이하자에 대해 걱정해야 할 것 

649
00:49:27,068 --> 00:49:32,259
 날이 내가이 생각을 의미 정확히 무엇을 보여 

650
00:49:32,260 --> 00:49:35,539
 더 비선형 만 남아있는이란에가보고되지 않았다이야 말할 계산해서 

651
00:49:35,539 --> 00:49:39,990
 스트레스 테스트 중에이 활성화되는 (가) 여기에 10 대기 0 W된다 

652
00:49:39,989 --> 00:49:44,848
 자루 + 한 번 W 이유를 확인 그것이 내가에 테스트를 계산하기 위해 원하고 무엇 때문에 

653
00:49:44,849 --> 00:49:48,420
 내가 조심해야 이유는 교육 시간 예상 출력 중입니다 

654
00:49:48,420 --> 00:49:51,528
 이 특정한 경우에 아주 달라졌을 것의 우리는 네가 

655
00:49:51,528 --> 00:49:55,619
 우리는 그 4에 하나 또는 다른 또는 둘 모두 또는 없음을, 그래서 드롭 수있는 가능성 

656
00:49:55,619 --> 00:49:56,720
 가능성 

657
00:49:56,719 --> 00:50:00,750
 컴퓨터에 다른 계곡은 실제로 당신이 때를 볼 수 있습니다이 수학을 위기했다 

658
00:50:00,750 --> 00:50:01,659
 당신은 그것을 감소 

659
00:50:01,659 --> 00:50:07,548
 당신은 왜 그렇게 훈련에서 기대에 WRX + W 하나 끄기 시간을 절반으로 끝낼 

660
00:50:07,548 --> 00:50:15,630
 시간이 신경 세포의 갱신은 실제로 단지 시간이었고, 그래서 당신은 할 때 

661
00:50:15,630 --> 00:50:19,640
 이것과 이것 저것을 보상하기 위해 당신이 가진 모든 시간을 사용하는 

662
00:50:19,639 --> 00:50:22,730
 우리는 아마와 단위를 삭제 한 사실에서 오는 멀리 일 

663
00:50:22,730 --> 00:50:29,219
 이를 최대 절반 그래서 아마 포인트 인 이유 절반은 그래서이다 

664
00:50:29,219 --> 00:50:35,358
 다섯 올림픽 싱가포르는 우리가 결국 다음 그래서 기본적으로 우리는이 작업을 수행하지 않은 경우 통과 

665
00:50:35,358 --> 00:50:39,019
 우리는 동안 기대 한 것에 비해 충분히 크지 만에 갖는 

666
00:50:39,019 --> 00:50:42,960
 분포가 기본적으로 변경됩니다에서 교육 시간과 당신이있어 

667
00:50:42,960 --> 00:50:45,639
 그들은 이러한보고에 사용하지이기 때문에 휴식 것이 세계의 것 

668
00:50:45,639 --> 00:50:49,368
 큰 고온 열 중성자 그리고 그녀는 그 보상해야하고 그럴 필요 

669
00:50:49,369 --> 00:50:53,798
 그냥 일을 일의 대신 모든 물건을 사용하지 않도록 아래로 뭉개 버려 

670
00:50:53,798 --> 00:50:57,480
 하지만 당신은 복구를 다시 얻기 위해 매일 활성화에 스크래치가 당신의 

671
00:50:57,480 --> 00:51:03,099
 예상 출력 확인이 실제로 어려운 점이지만 내가 한 번 들었다 생각 

672
00:51:03,099 --> 00:51:06,559
 제프 힌튼은 처음에 밖으로 드롭 함께 왔을 때 이야기하는 것이 그 

673
00:51:06,559 --> 00:51:10,710
 어떤하지 않았다 밖으로 우리가 드롭을 시도 그래서 실제로 완벽하게이 부분을 마련하지 않았다 

674
00:51:10,710 --> 00:51:16,088
 일을하고 실제로 이유는 그가이 까다로운 놓쳤다 그가대로 작동하지 않았다 

675
00:51:16,088 --> 00:51:19,340
 실제로 인정 하듯이 지적 그래서 우리는 당신의 활성화를 확장해야 

676
00:51:19,340 --> 00:51:24,070
 아래 때문에이 효과의 시스템 다음 모든 것이 훨씬 더 그렇게 작동 I 

677
00:51:24,070 --> 00:51:28,500
 그냥 우리가 기본적으로 이러한 계산처럼이는 모습을 보여 그냥 해요 

678
00:51:28,500 --> 00:51:33,449
 정상적으로 신경망은 그래서 우리는 첫 번째 또는 두 번째하지만 지금은 그냥 시간이 우리가 될 수 있습니다 

679
00:51:33,449 --> 00:51:38,869
 평화의 예를 들어 하하 확률 규모를 삭제하도록 P를 곱해야 

680
00:51:38,869 --> 00:51:43,139
 되도록 활성화 아래로 기대 밖으로 예상하지만 지금은이 

681
00:51:43,139 --> 00:51:46,969
 이 때 실제로 당신의 교육 시간 등의 예상 출력과 동일 

682
00:51:46,969 --> 00:51:52,449
 드롭 아웃에 대한 복구 및 예상 출력이 일치하고이 실제로 작동 

683
00:51:52,449 --> 00:52:18,069
 정말 잘 나는이에서 떨어지는거야, 그래서 기차와 사이에 단지 차이입니다 

684
00:52:18,070 --> 00:52:20,780
 모든 신경 세포를 사용하여 모든 같은 테스트를 불일치가있어 떨어집니다 

685
00:52:20,780 --> 00:52:24,580
 그래서 어느 당신은이 시점에서이를 수정하거나 우리가 부르는 당신은 사용할 수 있습니다 

686
00:52:24,579 --> 00:52:29,469
 내가 조금 당신을 보여주지 벌리 드롭 아웃은 그래서 우리는 비트에 그에게거야 

687
00:52:29,469 --> 00:52:34,319
 드롭 아웃 요약 당신은 아마 해제와 함께 드롭 당신의 단위를 삭제하려면 

688
00:52:34,320 --> 00:52:38,210
 오줌의 확률을 유지하고 그것은 단지 당신이 경우에 그렇게를 확장하는 것을 잊지 

689
00:52:38,210 --> 00:52:40,820
 이 네트워크는 잘 작동 할 것 

690
00:52:40,820 --> 00:52:44,190
 확인도 다시 아니에요 마스크를 전파하는 것을 잊지 마세요 

691
00:52:44,190 --> 00:52:49,710
 할 수있는 방법으로 반전 드롭 아웃을 보여주는 것은이 알아서하는 것입니다 

692
00:52:49,710 --> 00:52:53,349
 기차 및 시험 용액 약간 다른 방식 간의 불일치 

693
00:52:53,349 --> 00:52:57,710
 당신 일이었다 전에, 그래서 특히 우리가 할 거 야하는 것은 우리는 올해를 변경하고 

694
00:52:57,710 --> 00:53:01,250
 우리가하지 않을거야 바이오 매스 컵 냉동 것들은 우리가 할 거 야한다 

695
00:53:01,250 --> 00:53:04,980
 우리가 정품 인증 a를 아래로 확장 할거야, 그래서 교육 시간에 여기에 확장 

696
00:53:04,980 --> 00:53:07,960
 그는 다섯은 우리가있어 소비 때문에 경우 다른 스킬을 시간을 노력 

697
00:53:07,960 --> 00:53:12,079
 비난에게 뜨거운하여 기차 시간을 강화하고 우리가 우리의 코드를 떠날 수있는 시간이야 

698
00:53:12,079 --> 00:53:16,029
 바로 그래서 우리는 기차 시간 활성화의 증폭을하고있는 만진 

699
00:53:16,030 --> 00:53:20,880
 우리는이 행위에 의해 인위적으로 더 큰 모든 것을 만들고있어 후 시간이야 

700
00:53:20,880 --> 00:53:24,450
 우리는이 거 야하지만 지금 우리는 단지 청소를 복구하는거야 

701
00:53:24,449 --> 00:53:27,819
 우리가 지금 스케일링하려고 시간을 수행 한 표현 때문에 당신은 수 있습니다 

702
00:53:27,820 --> 00:53:31,010
 당신은 제대로 기차와 시험 사이의 기대를 보정 할 수 있습니다 

703
00:53:31,010 --> 00:53:39,290
 가장 많이 찾는이의 모든에 년과 오른쪽 그래서 드롭 아웃을 사용하고 작업 

704
00:53:39,289 --> 00:53:42,779
 그래서 정말 감염 실제로 사용하는 것은 다음 몇 줄과 아래로 온다 

705
00:53:42,780 --> 00:53:47,300
 뒤로 패스 조금 변경하지만 네트워크는 거의 항상 함께 잘 작동 

706
00:53:47,300 --> 00:54:15,070
 이 당신은 실제 정확한에 피팅에서 심각 아니라면 그이다 

707
00:54:15,070 --> 00:54:17,230
 내가 여기에 언급 한 이유는 

708
00:54:17,230 --> 00:54:22,039
 근사는 조립 근사하고 이유 중 하나 인 

709
00:54:22,039 --> 00:54:25,029
 실제로 다음 사진에서 일어난 일단 때문에 근사값입니다 

710
00:54:25,030 --> 00:54:27,769
 이러한 예상 출력은 모든 종류의 때문에 비선형의 망쳐된다 

711
00:54:27,769 --> 00:54:37,500
 이러한 질문의 상단에 효과 내가 가서 것을 가리키는 주셔서 감사합니다 

712
00:54:37,500 --> 00:54:44,769
 내가없는 당신은 그들이 드롭 인 (drop-in)과 드롭 아웃 반전 말을하는지 참조 

713
00:54:44,769 --> 00:54:49,039
 동등한 그렇게 여부 때문에 상기의 문제가 아니다 그녀의 일을하고 

714
00:54:49,039 --> 00:54:59,309
 내가 가진 것 구십 어쩌면 당신이 바로 당신이 될 수있는 아마 그것에 대해 생각합니다 

715
00:54:59,309 --> 00:55:37,949
 여기 나는이 모든 단지 기대에 기대에 대한 생각 

716
00:55:37,949 --> 00:55:41,349
 당신은 절반을 삭제하고 있고 그래서 거기에 불구하고도 사용할 올바른 일이 

717
00:55:41,349 --> 00:55:44,049
 실제로 결국 정확히 양에 약간의 임의성이 삭제되고 

718
00:55:44,050 --> 00:55:47,370
 큰 괜찮아 

719
00:55:47,369 --> 00:55:51,869
 이 오, 그래의 그래서이 있었다 밖으로 떨어질 것이다 재미있는 이야기로 당신에게 좋아 

720
00:55:51,869 --> 00:55:55,509
 2012 년 제프 힌튼에 깊은 학습 여름 학교는 처음으로 나 있었다 

721
00:55:55,510 --> 00:55:56,590
 적어도 처음 봤어 

722
00:55:56,590 --> 00:56:00,930
 드롭 아웃을 제시하고 그래서 그는 기본적으로 그냥 괜찮 말하는 것을 당신의 뉴런 (20)에서 

723
00:56:00,929 --> 00:56:04,589
 랜덤 그냥 난 그냥 바쁜 활성화를 해요이 항상 잘 작동 

724
00:56:04,590 --> 00:56:07,750
 더 나은 우리는 내 친구가 앉아으로 그 흥미로운 와우 같은거야 

725
00:56:07,750 --> 00:56:10,469
 내 옆에 그는 단지 바로 그 역이 있음 자신의 노트북을 뽑아 

726
00:56:10,469 --> 00:56:13,959
 대학 기계와 이야기하는 동안과가 바로 그것을 구현 

727
00:56:13,960 --> 00:56:17,340
 시간 제프 힌튼 마무리는 그가 더 나은 결과를 얻고지고 있다고 얘기 

728
00:56:17,340 --> 00:56:18,950
 실제로 미술 기자의 상태 등 

729
00:56:18,949 --> 00:56:25,189
 그는 빠른 작업 한 자신의 데이터에 나는 누군가가 내려면 같이 가서 봤어요 

730
00:56:25,190 --> 00:56:30,490
 일본은 너무 많이 나는 이야기를하려고하면서 추가로 5 %가 바로 다음이었다 

731
00:56:30,489 --> 00:56:33,589
 즉, 무언가가 실제로 매우 몇 번 거기에 정말 재미라고 생각했다 

732
00:56:33,590 --> 00:56:36,590
 이런처럼 그것이 그 중 하나이기 때문에 드롭 아웃은 훌륭한 일이다 

733
00:56:36,590 --> 00:56:42,390
 소수의 투자자는 매우 간단하고 항상 그냥 잘 작동하고있다 

734
00:56:42,389 --> 00:56:45,579
 내가 생각 우리가 주운 팁과 트릭의 이러한 종류의 거의 

735
00:56:45,579 --> 00:56:49,659
 문제는 얼마나 더 많은 간단한 일 드롭 아웃 등을들 수있다 거기입니다 

736
00:56:49,659 --> 00:56:50,879
 당신에게 2 %의 활력을 불어 

737
00:56:50,880 --> 00:56:54,140
 항상 우리는 모른다 

738
00:56:54,139 --> 00:57:01,199
 확인은 그래서 그라데이션 검사로이 시점에서 갈 거라고하지만 난을 생각한다 

739
00:57:01,199 --> 00:57:04,588
 실제로 나는 모든 신경의 피곤 때문에이 작업을 건너 내가거야 결정 

740
00:57:04,588 --> 00:57:07,130
 우리와 같은 네트워크는 모든 훈련의 세부 정보를 많이 얘기했습니다 그 

741
00:57:07,130 --> 00:57:10,180
 작품과 내가 너희들뿐만 아니라 피곤하고 그래서 그라데이션을 건너 뛸 것 같네요 

742
00:57:10,179 --> 00:57:13,469
 그것은 아주 잘 노트 여기에 설명되어 있기 때문에 체크 나는 보시기 바랍니다 

743
00:57:13,469 --> 00:57:19,028
 그것은 까다로운 과정의 종류를 통해 이동하는 시간의 비트에 소요 

744
00:57:19,028 --> 00:57:23,190
 프로세스의 모든 어려움을 감사하고 그래서 그냥 내가 읽어 

745
00:57:23,190 --> 00:57:27,250
 에 더 흥미 수 있도록 내가 주위에 드라이브 수있는 일이 생각하지 않습니다 

746
00:57:27,250 --> 00:57:29,469
 당신은 그래서 난 그냥 그것을 확인하는 것이 좋습니다 것 

747
00:57:29,469 --> 00:57:33,118
 한편 우리는 오른손을 뛰어거야하고 ​​그 작동 올 것와 

748
00:57:33,119 --> 00:57:42,358
 사진을보고 너무 1980년에서이 다섯에서 아일린입니다 같이 

749
00:57:42,358 --> 00:57:46,538
 대략 우리는 어떻게 상용 네트워크 마크의 세부 사항에 갈거야 

750
00:57:46,539 --> 00:57:49,609
 이 클래스에서 우리는 실제로 낮은 수준의 세부 사항을 수행하지 않을거야 

751
00:57:49,608 --> 00:57:52,768
 내가 얼마나이 분야에 대한 수에 대한 당신의 직관을 제공하기 위해 노력하겠습니다 

752
00:57:52,768 --> 00:57:56,868
 어떤 일 전체 상황과 그냥 그에서 오는 일반적으로 작동 그렇다면 

753
00:57:56,869 --> 00:57:59,559
 당신은 당신이 돌아 가야 상업 네트워크의 역사에 대해 이야기하고 싶습니다 

754
00:57:59,559 --> 00:58:04,910
 특히 이렇게 대략 아홉 육십 실험 승인 및 족제비에 

755
00:58:04,909 --> 00:58:10,449
 그들은 차 시각 피질 고양이를 공부하고, 그들은은을 전송했다 

756
00:58:10,449 --> 00:58:14,710
 초기 시각 영역과 고양이와 고양이의 뇌는에 패턴을 찾고 있었다 

757
00:58:14,710 --> 00:58:19,500
 그들은 끝내었고, 화면은 실제로이 언젠가 노벨상을 수상 

758
00:58:19,500 --> 00:58:23,449
 이후이 실험을 위해 우리는이 실험이 보는 무엇을 게재 할로 

759
00:58:23,449 --> 00:58:27,518
 그냥 그렇게처럼 그들은 내가 여기 여든 비디오를 뽑아 그렇게 보면 정말 재미있어 

760
00:58:27,518 --> 00:58:32,258
 여기에 무슨 고양이가 위치에 고정되고, 우리가 기록을하는지 참조 

761
00:58:32,259 --> 00:58:35,900
 뒷면에 처리 영역의 어딘가의 피질에서 

762
00:58:35,900 --> 00:58:39,809
 뇌가 하나가 될 수 있고, 지금 우리가 고양이에 다른 빛의 패턴을 표시하고 있고 

763
00:58:39,809 --> 00:58:43,519
 우리는 이제 살펴 보자 기록과 다른 자극에 대한 신경 세포의 불을 공유하고 

764
00:58:43,518 --> 00:58:48,039
 어떻게 경험과 같이 표시됩니다 

765
00:58:48,039 --> 00:59:14,050
 이리 

766
00:59:14,050 --> 00:59:27,410
 이러한 세포와​​ 같은 실험 그들은 모두 네 모서리를 설정하는 것 

767
00:59:27,409 --> 00:59:30,279
 특정 방향 그리고 그들은 가장자리와 일에 대한 흥분 

768
00:59:30,280 --> 00:59:36,360
 방향과 북쪽 방향은 다음과 같이 그래서 그들을 자극하지 않습니다 

769
00:59:36,360 --> 00:59:42,150
 10 분 비디오와 같은 긴 과정을 통해 우리는이 작업을 수행하지 않을거야 

770
00:59:42,150 --> 00:59:45,450
 오랜 시간 그들은 분방하고 어떻게 시각 피질의 모델로 등장 

771
00:59:45,449 --> 00:59:52,349
 공정 뇌의 정보 및 그래서 그들은 몇 가지 결국 수 있습니다 

772
00:59:52,349 --> 00:59:56,059
 예를 들어 노벨상을 선도 그들은 피질가 있음을 알아 냈다 

773
00:59:56,059 --> 00:59:56,759
 배치 

774
00:59:56,760 --> 01:00:02,570
 국소 적 시각 피질 어떤 것을 의미하는 것은 그녀가 내 프린터라고이다 

775
01:00:02,570 --> 01:00:06,920
 피질에서 기본적으로 근처의 세포 그래서이있다 대뇌 피질의 조직 인근 전개 

776
01:00:06,920 --> 01:00:11,389
 소금 공기 피질은 실제로 그래서 당신의 시야 인근 지역을 처리하는 

777
01:00:11,389 --> 01:00:15,049
 당신은 인근 처리 인식되지 않는 및이를 가지고 어떤 것 

778
01:00:15,050 --> 01:00:20,510
 지역은 당신의 처리에 보존되고 그들도 있다는 것을 알아 냈 

779
01:00:20,510 --> 01:00:23,790
 간단한 세포와​​ 그들이라고 무슨 이러한 역할의 전체 년 

780
01:00:23,789 --> 01:00:27,659
 가장자리의 특정 방향으로 반응하고 이러한 모든 있었다 

781
01:00:27,659 --> 01:00:31,809
 일부 셀 예를 들어 더 복잡한 응답 있도록했다 다른 세포 

782
01:00:31,809 --> 01:00:34,949
 제공하는 특정 방향을 선회하지만 약간 있었다 것 

783
01:00:34,949 --> 01:00:38,159
 그들은 가장자리의 특정 위치에 대한 번역 불변 걱정하지 않도록 

784
01:00:38,159 --> 01:00:41,839
 하지만 그들은 단지 방향에 대해 걱정하고 그래서 그들은 가설 

785
01:00:41,840 --> 01:00:44,120
 시각 피질은 이런 종류의이 실험의 모든 통해 

786
01:00:44,119 --> 01:00:48,269
 당신이 다른 단순한 판매 그들의 독서를 종료 계층 적 조직 

787
01:00:48,269 --> 01:00:52,679
 복잡한 세포 등 이러한 세포라는 세포는 각각의 상단에 내장되어 있습니다 

788
01:00:52,679 --> 01:00:56,369
 특히 다른과 간단한 노래는 수용이 상대적으로 지방이 

789
01:00:56,369 --> 01:01:00,019
 필드 이들은 표현의 더 복잡한 유형을 구축했다 

790
01:01:00,019 --> 01:01:04,320
 그래서이는 연속적인 표현의 층과를 통해 뇌의 

791
01:01:04,320 --> 01:01:09,240
 어떤 사람들은이 재현하려고하는 과정을 많이 경험 

792
01:01:09,239 --> 01:01:14,649
 컴퓨터는 상기 제 때문에 하나의 코드와 시각 피질 모델링하려는 및 

793
01:01:14,650 --> 01:01:19,389
 이 예는 후쿠시마에서 거 드롭이었다 그는 기본적으로 결국 

794
01:01:19,389 --> 01:01:20,429
 설정 

795
01:01:20,429 --> 01:01:26,710
 기본적으로 작은 보면이 지역의 수용 세포 구조 

796
01:01:26,710 --> 01:01:31,760
 충격의 영역은 그 층과이 층 그래서 그는을 강화 

797
01:01:31,760 --> 01:01:34,750
 또한 상기 복잡한 간단한을 해결해 단지에 이러한 간단한 공격했다 

798
01:01:34,750 --> 01:01:39,000
 단순 및 복합도 그때 지금 이라크에 구축의 샌드위치 

799
01:01:39,000 --> 01:01:41,849
 하지만에서 아홉 년대 다시 전파 정말 주위에 아직하지 않습니다 

800
01:01:41,849 --> 01:01:45,380
 그래서 이러한 교육에 대한 내 머리와 자율 학습 절차를 추진 

801
01:01:45,380 --> 01:01:49,599
 클러스터링 방식 등으로 네트워크 그러나 이것은 다시되지 않습니다에 전파 

802
01:01:49,599 --> 01:01:54,150
 시간 그러나 그것은 상단에 건물 연속 층 작은 세포의 이런 생각을했다 

803
01:01:54,150 --> 01:02:00,039
 서로 다음이 실험 또한 그는 가지 위에 구축 

804
01:02:00,039 --> 01:02:04,739
 일을하고 그는 건축 레이아웃을 유지하지만 그가했던 것은 사실이었다 

805
01:02:04,739 --> 01:02:09,009
 연수생은 다시 전파 네트워크 그래서 예를 들어 그는 다른 훈련 

806
01:02:09,010 --> 01:02:12,770
 분류 등 등 네 자리 숫자 또는 문자와 그것의 모든 훈련 

807
01:02:12,769 --> 01:02:16,769
 배경 및 그들은 실제로 읽어 복잡한 시스템이를 사용하여 종료 

808
01:02:16,769 --> 01:02:23,469
 등 등 우편 서비스의 숫자와 같은 레이더를 확인합니다 

809
01:02:23,469 --> 01:02:27,239
 즉 실제로 아홉 구십에 전 꽤 오랜 시간으로 돌아가 그리고 

810
01:02:27,239 --> 01:02:33,199
 사람이 2012 년에 이렇게 다시 그들을 사용하지만 괜찮 아주 작은했고, 누가 

811
01:02:33,199 --> 01:02:37,559
 는이 용지에서했을 정도로 꽤 큰 얻을 시작하는 올 때 

812
01:02:37,559 --> 01:02:43,549
 나는 그들이 그 모든했다으로 탈출 참조 유지하고는 같은 아니에요 

813
01:02:43,550 --> 01:02:48,200
 이 천으로 만 이미지, 그래서 우리의 실험실에서 실제로 제공 데이터 세트 

814
01:02:48,199 --> 01:02:51,339
 클래스는 대략 6 천만 인이 모델을 데이터의 엄청난 금액을 

815
01:02:51,340 --> 01:02:56,380
 알렉스 Kozinski 이들의 이름을 기준으로 알렉스 그물에서 매개 변수 차가운 

816
01:02:56,380 --> 01:02:59,260
 네트워크는이 알렉스 냅이있다 그래서 그들은 이름을 가지고 있는지 가고 있었다 

817
01:02:59,260 --> 01:03:05,560
 이 일이 그렇게처럼 자신의 몇 분에서 구글을 가지고 지역 

818
01:03:05,559 --> 01:03:09,630
 한계는 그리고 우리는 그들에게이 알렉스의 순이었다 그래서 이름을 부여하고 그것은 하나 

819
01:03:09,630 --> 01:03:13,090
 이 실제로 무슨 일이있어 다른 알고리즘을 꽤하여보다 실적 

820
01:03:13,090 --> 01:03:17,530
 역사적으로주의하는 것이 흥미 알렉스 아무것도 2012 년 사이의 차이 

821
01:03:17,530 --> 01:03:21,850
 열 아홉 90 년대 한도는 기본적으로 아주 아주 약간의 차이가있다 

822
01:03:21,849 --> 01:03:25,940
 이러한 두 개의 서로 다른 네트워크에서 볼 때이 사람은 내가 신호를 생각 사​​용 

823
01:03:25,940 --> 01:03:31,789
 10 H의 아마 동전이 하나는 진짜하고 더 깊은이었고, 

824
01:03:31,789 --> 01:03:33,460
 GPU를 훈련하고 더 많은 데이터를 가지고 있었다 

825
01:03:33,460 --> 01:03:38,889
 그리고 기본적입니다 그것은 단지 그 같은 대략의 차이이다있어 그와 

826
01:03:38,889 --> 01:03:41,098
 그래서 정말 우리가했던 것은 우리는 물론 더 나은 방법을 알아 냈어요된다 

827
01:03:41,099 --> 01:03:45,000
 를 초기화하고 국가 군대와 더 잘 작동과 반군이 많은 작업 

828
01:03:45,000 --> 01:03:49,480
 그것보다 더 있지만, 다른는 모두 데이터와 계산을 살해했다 

829
01:03:49,480 --> 01:03:53,740
 하지만 대부분의 배우가 매우 유사했다 그리고 우리는 몇 가지 더 많은 일을했습니다 

830
01:03:53,739 --> 01:03:56,719
 그들은 큰 필터를 사용하는 예를 들어 같은 트릭은 우리가 많이 사용하는 것을 볼 수 

831
01:03:56,719 --> 01:04:01,379
 작은 필터 우리 또한 지금이 우리가 지금이 선수의 수십입니다 

832
01:04:01,380 --> 01:04:05,059
 백 오십이 나중에 와서는 그래서 우리는 정말 스킬에 꽤 최대입니다 

833
01:04:05,059 --> 01:04:08,150
 어떤면하지만, 그렇지 않으면 당신은 정보를 처리하는 방법의 기본 개념 

834
01:04:08,150 --> 01:04:09,789
 유사하다 

835
01:04:09,789 --> 01:04:15,150
 확인을 그래서 그들은 모든 종류의 작업을 수행 할 수 있도록 기본적으로 모든 곳에서 지금이다 

836
01:04:15,150 --> 01:04:19,280
 물론 분류 것 같은 것들을 그들은 검색에 아주 좋은 경우 그래서 당신 

837
01:04:19,280 --> 01:04:24,119
 그들은 그것과 같은 다른 이미지를 검색 할 수 있습니다 그들에게 이미지를 보여 그들도 할 수있다 

838
01:04:24,119 --> 01:04:29,809
 검출 그래서 여기 저기 개와 말 등등 사람들과 검출 

839
01:04:29,809 --> 01:04:33,230
 이 일부 독일 차, 예를 들어 사용될 수있는 모든 다음이가 

840
01:04:33,230 --> 01:04:36,588
 선 그들도 그렇게 하나 하나의 화소가 몇 가지 실험을 수행 할 수 있습니다 

841
01:04:36,588 --> 01:04:41,409
 예를 들어 표시된 사람이나 분할을 재건 도로 나 나무 나 하늘 

842
01:04:41,409 --> 01:04:47,529
 예를 들어 자동차에서의 사용을 위해 여기에 포함 된 작은 엔비디아 테그 라이야 

843
01:04:47,530 --> 01:04:51,480
 우리가 올 실행할 수 있습니다 GPU는 예를 들어 하나의 이유는 이것이 유용 할 수 있어요 

844
01:04:51,480 --> 01:04:55,480
 당신이 식별 할 수있는 자동차는 모든 당신은 라운딩의 왜곡 된 인식 될 수 있습니다 

845
01:04:55,480 --> 01:04:57,219
 당신의 주위에 물건 

846
01:04:57,219 --> 01:05:02,039
 친구의 당신 일부는 식은 경우 의견은 아마 얼굴을 식별하는 

847
01:05:02,039 --> 01:05:04,909
 페이스 북에 자동으로 내가이 시점에서 추측 것이 거의 확실입니다 

848
01:05:04,909 --> 01:05:10,069
 YouTube에서 해당 동영상 분류 YouTube 동영상 안에 무엇을 식별 

849
01:05:10,070 --> 01:05:14,900
 그들은이에 사용하는 매우 성공적 Google의 프로젝트입니다 

850
01:05:14,900 --> 01:05:17,900
 기본적으로 구글이 스트리트 뷰 이미지를 복용에 정말 관심과 

851
01:05:17,900 --> 01:05:20,809
 자동에서 바깥 번호를 읽고 

852
01:05:20,809 --> 01:05:25,019
 확인을 밝혀이 그래서 그들은 인간을 많이했다 완벽한 아스트라한입니다 

853
01:05:25,019 --> 01:05:30,289
 노동의 데이터 팔 엄청난 양에 있고, 다음에 거대한 코멘트를 넣어 

854
01:05:30,289 --> 01:05:33,429
 그것은 인간으로 거의 잘 작동 결국 그는 일이 우리가 거 

855
01:05:33,429 --> 01:05:37,710
 이 물건 정말 정말 잘 추정을 작동 전반에 걸쳐 참조 

856
01:05:37,710 --> 01:05:41,730
 그들은 컴퓨터 게임을 재생할 수 있습니다 포즈 

857
01:05:41,730 --> 01:05:46,559
 그들은 그렇게 암 또는 무언가의 모든 종류를 감지하고 안녕히 가세요 

858
01:05:46,559 --> 01:05:53,519
 이미지는이 내가 생각입니다 거리 표지판을 인식 한자를 읽을 수 있습니다 

859
01:05:53,519 --> 01:05:57,690
 신경 조직의 분할은 또한 이렇게 시각적없는 일을 할 수있다 

860
01:05:57,690 --> 01:06:02,510
 예를 들어, 그들이 사용했던 음성 처리를위한 음성을 인식 할 수있다 

861
01:06:02,510 --> 01:06:07,780
 또한 텍스트 문서에 대해 당신은뿐만 아니라 그들이했습니다 코멘트로 텍스트를 볼 수 있도록 

862
01:06:07,780 --> 01:06:11,400
 이들이 사용되어 한 은하의 종류를 인식하기 위해 사용 된 

863
01:06:11,400 --> 01:06:15,570
 다른 웨일즈 인식하는 최근의 가축 대회에서 이것은이다 

864
01:06:15,570 --> 01:06:18,420
 특히 잘 거기 백마일 같았다 또는 같은 그이다 

865
01:06:18,420 --> 01:06:24,409
 그냥 내 특정 개인 그래서이 자사의 하얀 반점의 패턴을 살 것이다 

866
01:06:24,409 --> 01:06:28,179
 머리는 그 놀라운 그래서 나는이 인식 될 수 있습니다 특정 방법입니다 

867
01:06:28,179 --> 01:06:32,618
 모든 그들이 사용하는 위성 사진에서 작동 꽤 지금이 있기 때문에 

868
01:06:32,619 --> 01:06:35,280
 이 모든 분석 있도록 위성 많은 데이터를 가지고 여러 회사 

869
01:06:35,280 --> 01:06:39,530
 이 경우 큰 의견으로는 도로를 권선 있어요 그러나 당신은 또한 볼 수 있습니다 

870
01:06:39,530 --> 01:06:43,850
 농업 응용 프로그램 또는 그들은 또한 이미지를 할 수있는 사람은 당신에게 수도 캡처 

871
01:06:43,849 --> 01:06:48,829
 내 작품이 포함 된 결과뿐만 아니라 우리가 이미지를 가지고의 일부를 보았다 

872
01:06:48,829 --> 01:06:53,369
 자막 대신 단일 카테고리의 더 문장이 그들은 수도 있습니다 

873
01:06:53,369 --> 01:06:56,150
 다양한 예술적 노력 사용될 

874
01:06:56,150 --> 01:06:59,800
 그래서 이것은 무엇인가라는 깊은 꿈이며 우리는 어떻게 들어갈거야 

875
01:06:59,800 --> 01:07:00,350
 공장 

876
01:07:00,349 --> 01:07:04,440
 실제로 세 번째 과제를 구현하는 것은 어쩌면 당신은 것입니다 확인 할 수있다 

877
01:07:04,440 --> 01:07:08,099
 세 번째 과제를 구현하는 당신은 그것을 이미지를 제공하고 사용 할 수있는 그 

878
01:07:08,099 --> 01:07:11,349
 이 이상한 물건을 할 수 있도록 

879
01:07:11,349 --> 01:07:17,380
 특히 개 환각을 많이하고 우리는 왜 개에 갈거야 

880
01:07:17,380 --> 01:07:20,349
 그것이 사실 여기서 이러한 네트워크하다 화상 순을 수행하는 표시 

881
01:07:20,349 --> 01:07:25,579
 최대 끝으로 훈련을받을 그들은 개 많은 등이 이러한 네트워크를 

882
01:07:25,579 --> 01:07:28,259
 사과 주스와 먹는 개는 그들이 일부를 사용하는의 같은 종류의 

883
01:07:28,260 --> 01:07:32,440
 패턴 및 당신은 다른 이미지를 당신이 그 (것)들을 넣을 수 있어야한다 

884
01:07:32,440 --> 01:07:36,710
 이미지와 루프에서 그들과 우리가 어떻게를 볼 수 있도록 환각 일을 나눠 

885
01:07:36,710 --> 01:07:42,769
 나는 슬라이드를 설명하지 않을거야 비트에서 작동하지만 당신이 할 수 있도록 멋진 모습 

886
01:07:42,769 --> 01:07:47,559
 내가 또한 지적 아마 어딘가에 포함 할 것 상상 

887
01:07:47,559 --> 01:07:51,579
 흥미로운 것은 네트워크 라이벌 표현 불리는이 종이있다 

888
01:07:51,579 --> 01:07:55,420
 개인의 나는 그들이 무슨 짓을했는지 인식의 분기 피질 호출을 생각한다 

889
01:07:55,420 --> 01:08:00,250
 나는 이것이 원숭이 원숭이라고 생각하고 여기 기본적으로 찾고 

890
01:08:00,250 --> 01:08:05,280
 여기 피질에서 ITV에서 기록과 신경이 기록 

891
01:08:05,280 --> 01:08:09,030
 정품 인증 원숭이 이미지를보고 그들은 동일한 이미지를 공급 

892
01:08:09,030 --> 01:08:12,660
 네트워크에서 수행하는 것과 그들이하려는 것은 인기에서입니다 

893
01:08:12,659 --> 01:08:16,960
 상업 네트워크 코드 또는 전용 희소 뉴런 집단으로부터 무도회 

894
01:08:16,960 --> 01:08:21,560
 문맥의 인구는 몇 가지 개념 분류를 수행하기 위해 노력하고 

895
01:08:21,560 --> 01:08:25,820
 무엇 당신이 보는 것은 그 아이디어 피질과 분류의 코팅 

896
01:08:25,819 --> 01:08:30,519
 이미지는 측면에서 2013이 신경 네트워크를 사용하는 것과 거의 같은 좋은 

897
01:08:30,520 --> 01:08:35,400
 정보는 이미지에 대한 걸 당신은 성능이 거의 동일 할 수있다 

898
01:08:35,399 --> 01:08:40,279
 여기에 분류 아마 더 눈에 띄는 결과를 우리가 비교하는 

899
01:08:40,279 --> 01:08:43,759
 일의 경쟁을 통해 이미지를 많이 공급 그들은이있어 

900
01:08:43,760 --> 01:08:46,720
 달 그는 이미지를 많이했다 다음은 이러한 이미지는 방법에 대해 알아 

901
01:08:46,720 --> 01:08:48,789
 뇌 또는 의견 표현 

902
01:08:48,789 --> 01:08:53,019
 그래서이 두 공간은 공간에 배치되는 방식의 이미지 표현이다 

903
01:08:53,020 --> 01:08:57,520
 주석에 의해 당신은 유사성 행렬 및 통계를 비교할 수 있습니다 

904
01:08:57,520 --> 01:09:00,450
 당신이 볼 수 있다는 IT 피질과 코멘트 

905
01:09:00,449 --> 01:09:04,099
 의 매우 매우 유사 표현 기본적 것을 매핑 사이가있다 

906
01:09:04,100 --> 01:09:08,440
 비슷한 물건들이 배치 방법을 계산하고있다처럼 거의 보인다 

907
01:09:08,439 --> 01:09:12,399
 서로 다른 개념과 내용을 시각적으로 공간이 폐쇄 무엇을 훨씬 것은 매우가요 

908
01:09:12,399 --> 01:09:16,809
 당신이 뇌에서에서 볼 무엇 때문에 어떤 사람들은 매우 매우 유사 

909
01:09:16,810 --> 01:09:20,780
 이 회사는 뭔가 뇌를하고 있다는 것을 그냥 몇 가지 증거가 있다고 생각 

910
01:09:20,779 --> 01:09:23,769
 같은 그것은 매우 흥미로운 점에서 다음 남아있는 유일한 문제 때문에 

911
01:09:23,770 --> 01:09:24,330
 케이스 

912
01:09:24,329 --> 01:09:27,210
 이 작품은 

913
01:09:27,210 --> 01:09:28,609
 우리는 다음 수업을 찾을 수 있습니다 

